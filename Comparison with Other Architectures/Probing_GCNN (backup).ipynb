{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d2f0719",
   "metadata": {},
   "source": [
    "#### Training GCN\n",
    "\n",
    "Model using the graph dataset extracted from the csv file. TO generate csv file, please run the parsing notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52bbdb56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Dataset Overview:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60882 entries, 0 to 60881\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   circuit_name            60882 non-null  object \n",
      " 1   node                    60882 non-null  object \n",
      " 2   gate_type               60882 non-null  object \n",
      " 3   fan_in                  60882 non-null  int64  \n",
      " 4   fan_out                 60882 non-null  int64  \n",
      " 5   depth                   60882 non-null  object \n",
      " 6   dist_to_output          60882 non-null  int64  \n",
      " 7   is_primary_input        60882 non-null  int64  \n",
      " 8   is_primary_output       60882 non-null  int64  \n",
      " 9   is_internal             60882 non-null  int64  \n",
      " 10  is_key_gate             60882 non-null  int64  \n",
      " 11  key_dependency          122 non-null    object \n",
      " 12  degree_centrality       60882 non-null  float64\n",
      " 13  betweenness_centrality  60882 non-null  float64\n",
      " 14  closeness_centrality    60882 non-null  float64\n",
      " 15  clustering_coefficient  60882 non-null  float64\n",
      " 16  avg_fan_in_neighbors    60882 non-null  float64\n",
      " 17  avg_fan_out_neighbors   60882 non-null  float64\n",
      "dtypes: float64(6), int64(7), object(5)\n",
      "memory usage: 8.4+ MB\n",
      "None\n",
      "\n",
      "ðŸ” Extracted 6172 edges.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rrk307\\Anaconda3\\lib\\site-packages\\dgl\\backend\\pytorch\\tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/50, Loss: 2.4010\n",
      "Epoch 10/50, Loss: 1.1221\n",
      "Epoch 20/50, Loss: 0.5066\n",
      "Epoch 30/50, Loss: 0.3615\n",
      "Epoch 40/50, Loss: 0.2943\n",
      "\n",
      "âœ… Test Accuracy on Original Graph: 92.31%\n",
      "\n",
      "ðŸ“ Confusion Matrix (Original Graph):\n",
      "[[5555    0   29   53    0    0    0    0]\n",
      " [   0  472    3    0    0    0    0    0]\n",
      " [ 439    0   31   57    0    0    0    0]\n",
      " [ 151    0    4  412    0    0    0    0]\n",
      " [   0    0    0    4 4474    0    0    0]\n",
      " [ 195    0    2    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  266    0]\n",
      " [   0    0    0    0    0    0    0   30]]\n",
      "\n",
      "Classification Report (Original Graph):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         and       0.88      0.99      0.93      5637\n",
      "       input       1.00      0.99      1.00       475\n",
      "        nand       0.45      0.06      0.10       527\n",
      "         nor       0.78      0.73      0.75       567\n",
      "         not       1.00      1.00      1.00      4478\n",
      "          or       0.00      0.00      0.00       197\n",
      "      output       1.00      1.00      1.00       266\n",
      "         xor       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.92     12177\n",
      "   macro avg       0.76      0.72      0.72     12177\n",
      "weighted avg       0.89      0.92      0.90     12177\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rrk307\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\rrk307\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\rrk307\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Load Dataset and Prepare Data\n",
    "# ------------------------------\n",
    "df = pd.read_csv(\"all_circuits_features.csv\")\n",
    "print(\"\\nðŸ“Œ Dataset Overview:\")\n",
    "print(df.info())\n",
    "\n",
    "gate_types = ['and', 'or', 'nand', 'nor', 'xor', 'xnor', 'buf', 'not']\n",
    "\n",
    "# Convert 'gate_type' to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"gate_label\"] = label_encoder.fit_transform(df[\"gate_type\"])\n",
    "\n",
    "# Feature columns\n",
    "feature_columns = [\n",
    "    \"fan_in\", \"fan_out\", \"dist_to_output\", \"is_primary_input\", \"is_primary_output\",\n",
    "    \"is_internal\", \"is_key_gate\", \"degree_centrality\", \"betweenness_centrality\",\n",
    "    \"closeness_centrality\", \"clustering_coefficient\", \"avg_fan_in_neighbors\", \"avg_fan_out_neighbors\"\n",
    "]\n",
    "\n",
    "# Drop NaN values and convert features to float\n",
    "df = df.dropna(subset=feature_columns)\n",
    "df[feature_columns] = df[feature_columns].astype(float)\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "df[feature_columns] = scaler.fit_transform(df[feature_columns])\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Build Node and Edge Lists\n",
    "# ---------------------------\n",
    "nodes = df[\"node\"].tolist()\n",
    "node_to_id = {node: i for i, node in enumerate(nodes)}\n",
    "\n",
    "# Build edge list based on fan-in relationships (directed: from source to current node)\n",
    "edges = []\n",
    "for idx, row in df.iterrows():\n",
    "    node_id = node_to_id[row[\"node\"]]\n",
    "    # Select potential driving nodes: those with fan_out > 0\n",
    "    potential_sources = df[df[\"fan_out\"] > 0][\"node\"].tolist()\n",
    "    num_fan_in = int(row[\"fan_in\"])\n",
    "    if num_fan_in > 0:\n",
    "        sources = potential_sources[:num_fan_in]\n",
    "        for src in sources:\n",
    "            if src in node_to_id:\n",
    "                edges.append((node_to_id[src], node_id))\n",
    "\n",
    "print(\"\\nðŸ” Extracted\", len(edges), \"edges.\")\n",
    "if len(edges) == 0:\n",
    "    raise ValueError(\"No edges found! Check your fan_in values.\")\n",
    "\n",
    "# Convert edges into tensors\n",
    "src_nodes, dst_nodes = zip(*edges) if edges else ([], [])\n",
    "src_tensor = torch.tensor(src_nodes, dtype=torch.int64)\n",
    "dst_tensor = torch.tensor(dst_nodes, dtype=torch.int64)\n",
    "valid_edges = (src_tensor >= 0) & (dst_tensor >= 0) & (src_tensor < len(nodes)) & (dst_tensor < len(nodes))\n",
    "src_tensor = src_tensor[valid_edges]\n",
    "dst_tensor = dst_tensor[valid_edges]\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Create the Original DGL Graph\n",
    "# ---------------------------\n",
    "graph = dgl.graph((src_tensor, dst_tensor), num_nodes=len(nodes))\n",
    "graph = dgl.add_self_loop(graph)  # add self-loops to avoid zero in-degree issues\n",
    "\n",
    "# Assign node features and labels\n",
    "graph.ndata['features'] = torch.tensor(df[feature_columns].values, dtype=torch.float32)\n",
    "graph.ndata['labels'] = torch.tensor(df[\"gate_label\"].values, dtype=torch.long)\n",
    "\n",
    "# Create train-test split using node indices\n",
    "nodes_idx = np.arange(len(nodes))\n",
    "train_idx, test_idx = train_test_split(nodes_idx, test_size=0.2, random_state=42)\n",
    "train_mask = torch.tensor(train_idx, dtype=torch.long)\n",
    "test_mask = torch.tensor(test_idx, dtype=torch.long)\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Define the GCNN Model\n",
    "# ---------------------------\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = dglnn.GraphConv(in_feats, hidden_feats, allow_zero_in_degree=True)\n",
    "        self.conv2 = dglnn.GraphConv(hidden_feats, out_feats, allow_zero_in_degree=True)\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        x = self.conv1(g, inputs)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(g, x)\n",
    "        return x\n",
    "\n",
    "in_feats = len(feature_columns)\n",
    "hidden_feats = 32\n",
    "out_feats = len(label_encoder.classes_)\n",
    "model = GCN(in_feats, hidden_feats, out_feats)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Training Loop\n",
    "# ---------------------------\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    logits = model(graph, graph.ndata['features'])\n",
    "    loss = loss_fn(logits[train_mask], graph.ndata['labels'][train_mask])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 6. Evaluation\n",
    "# ---------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(graph, graph.ndata['features'])\n",
    "    test_logits = logits[test_mask]\n",
    "    test_predictions = test_logits.argmax(dim=1)\n",
    "    orig_accuracy = (test_predictions == graph.ndata['labels'][test_mask]).float().mean().item()\n",
    "    \n",
    "    print(f\"\\nâœ… Test Accuracy on Original Graph: {orig_accuracy * 100:.2f}%\")\n",
    "    \n",
    "    true_labels_orig = graph.ndata['labels'][test_mask].cpu().numpy()\n",
    "    pred_labels_orig = test_predictions.cpu().numpy()\n",
    "    conf_mat_orig = confusion_matrix(true_labels_orig, pred_labels_orig)\n",
    "    \n",
    "    print(\"\\nðŸ“ Confusion Matrix (Original Graph):\")\n",
    "    print(conf_mat_orig)\n",
    "    \n",
    "    print(\"\\nClassification Report (Original Graph):\")\n",
    "    print(classification_report(true_labels_orig, pred_labels_orig, target_names=label_encoder.classes_))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018700d",
   "metadata": {},
   "source": [
    "#### Jacobian \n",
    "Calculation for one sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f42bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Jacobian Computation and Verification ---\n",
      "\n",
      "Selected test node index: 54063\n",
      "Original feature vector for test node (x0): tensor([ 0.5852,  3.3096, -0.2307, -0.2018, -0.1490,  0.2546, -0.0448,  0.2462,\n",
      "         0.4904, -0.4170, -0.2078,  0.2185,  0.1667], requires_grad=True)\n",
      "\n",
      "Jacobian shape: torch.Size([8, 13])\n",
      "Jacobian matrix:\n",
      " tensor([[ 0.8985,  0.3651, -0.3604,  0.2352,  0.5114, -0.2491,  0.1276, -0.2225,\n",
      "          0.4148,  0.1603, -0.2108,  0.0024, -0.2186],\n",
      "        [ 0.3432, -0.1366,  0.0459,  0.7290, -0.3247, -0.6114, -0.1305,  0.1473,\n",
      "         -0.2415, -0.3517,  0.5398,  0.3522,  0.6216],\n",
      "        [ 0.0298, -0.0806, -0.0050,  0.3152, -0.0629, -0.0671, -0.1677,  0.1670,\n",
      "         -0.2373,  0.2443,  0.1969,  0.3316,  0.0488],\n",
      "        [ 0.6087, -0.2459,  0.0078,  0.3005, -0.0187, -0.4585, -0.0212, -0.1625,\n",
      "          0.0031, -0.5966,  0.3872,  0.1420,  0.5246],\n",
      "        [-1.6733,  0.0235,  0.0924, -0.9347, -0.5967,  0.7131, -0.6982,  0.0328,\n",
      "         -0.3167,  0.2452, -0.5859,  0.0239, -0.3597],\n",
      "        [ 0.6097, -0.0975, -0.1468,  0.0103,  0.6887, -0.0092, -0.3544,  0.0417,\n",
      "          0.2749,  0.3605, -0.2749,  0.2529, -0.1234],\n",
      "        [ 0.4854, -0.0804, -0.2157, -0.0045,  0.7478, -0.1726, -0.0601, -0.1916,\n",
      "          0.3321,  0.1579, -0.0257,  0.4182, -0.0658],\n",
      "        [ 0.2599, -0.2500,  0.3781,  0.5617, -0.0683,  0.2124,  0.4484,  0.2048,\n",
      "          0.0200, -0.0696,  0.3397, -0.2909,  0.2819]])\n",
      "\n",
      "Perturbation delta vector: tensor([ 2.0348e-03,  1.3516e-05, -4.0578e-04, -1.8491e-03, -5.4067e-04,\n",
      "         1.9276e-05, -4.0229e-04, -1.1446e-03,  1.8294e-03, -9.3465e-04,\n",
      "        -5.8488e-04, -2.0007e-05,  2.5942e-03])\n",
      "\n",
      "Predicted change in output (Jacobian * delta): tensor([ 0.0016,  0.0006, -0.0013,  0.0026, -0.0025,  0.0010,  0.0012, -0.0004])\n",
      "Actual change in output after perturbation: tensor([ 0.0016,  0.0006, -0.0013,  0.0026, -0.0025,  0.0010,  0.0012, -0.0004],\n",
      "       grad_fn=<SubBackward0>)\n",
      "\n",
      "Relative error between predicted and actual change: 8.7657e-05\n",
      "\n",
      "Outcome: The Jacobian accurately captures the local sensitivity of the model's output relative to small perturbations in the input.\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# 7. Jacobian Computation and Verification\n",
    "#########################\n",
    "\n",
    "print(\"\\n--- Jacobian Computation and Verification ---\\n\")\n",
    "\n",
    "# Select one test node. Here, we simply choose the first node in the test set.\n",
    "test_idx = test_mask[0].item()\n",
    "print(f\"Selected test node index: {test_idx}\")\n",
    "\n",
    "# Get the feature vector for this test node and set it to require gradients.\n",
    "x0 = graph.ndata['features'][test_idx].clone().detach().requires_grad_(True)\n",
    "print(\"Original feature vector for test node (x0):\", x0)\n",
    "\n",
    "# Define a helper function that takes a feature vector for test_idx and returns the model's output (logit vector)\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    Given an input feature vector x for the selected test node (test_idx),\n",
    "    create a new features tensor by replacing the test node's features and compute the model's output.\n",
    "    \"\"\"\n",
    "    # Clone the original features from the graph.\n",
    "    new_features = graph.ndata['features'].clone().detach()\n",
    "    # Replace the test node's feature vector with x.\n",
    "    new_features[test_idx] = x\n",
    "    # Forward propagate through the model (the graph structure remains unchanged).\n",
    "    output = model(graph, new_features)\n",
    "    # Return the output (logit vector) for the test node.\n",
    "    return output[test_idx]\n",
    "\n",
    "# Compute the Jacobian of f with respect to x0.\n",
    "# The resulting Jacobian has shape (num_classes, feature_dim)\n",
    "jacobian = torch.autograd.functional.jacobian(f, x0)\n",
    "\n",
    "print(\"\\nJacobian shape:\", jacobian.shape)\n",
    "print(\"Jacobian matrix:\\n\", jacobian)\n",
    "\n",
    "#########################\n",
    "# 8. Jacobian Verification via Finite Differences\n",
    "#########################\n",
    "\n",
    "# Choose a small random perturbation delta.\n",
    "epsilon = 1e-3\n",
    "delta = epsilon * torch.randn_like(x0)\n",
    "print(\"\\nPerturbation delta vector:\", delta)\n",
    "\n",
    "# Compute the predicted change in output using the linear approximation: J * delta.\n",
    "predicted_change = jacobian.mv(delta)  # matrix-vector product\n",
    "print(\"\\nPredicted change in output (Jacobian * delta):\", predicted_change)\n",
    "\n",
    "# Now compute the actual change in output by explicitly perturbing x0.\n",
    "f_x0 = f(x0)\n",
    "f_x0_perturbed = f(x0 + delta)\n",
    "actual_change = f_x0_perturbed - f_x0\n",
    "print(\"Actual change in output after perturbation:\", actual_change)\n",
    "\n",
    "# Calculate the relative error between the predicted change and the actual change.\n",
    "relative_error = (predicted_change - actual_change).norm() / (actual_change.norm() + 1e-8)\n",
    "print(\"\\nRelative error between predicted and actual change: {:.4e}\".format(relative_error.item()))\n",
    "\n",
    "#########################\n",
    "# 9. Outcome Interpretation\n",
    "#########################\n",
    "\n",
    "if relative_error < 1e-2:\n",
    "    print(\"\\nOutcome: The Jacobian accurately captures the local sensitivity of the model's output relative to small perturbations in the input.\")\n",
    "else:\n",
    "    print(\"\\nOutcome: The relatively high error indicates that higher-order effects or estimation noise may be present, suggesting that the local model behavior is less linear.\")\n",
    "\n",
    "#############################################\n",
    "# 10. Discussion: Verifying Jacobian Information\n",
    "#############################################\n",
    "#\n",
    "# The procedure above gives us two key pieces of information:\n",
    "#\n",
    "# 1. The Jacobian matrix tells us how significantly each output logit is affected by changes in each feature component.\n",
    "#    - For example, large entries in the Jacobian indicate that a small change in that particular input dimension produces a large change in the output.\n",
    "#\n",
    "# 2. By comparing the linear prediction (via the Jacobian) to the actual output change for a small input alteration,\n",
    "#    we verify (via low relative error) that the Jacobian is a valid local approximation.\n",
    "#\n",
    "# In the context of circuit analysis:\n",
    "# - High local sensitivity (i.e. large norms of the Jacobian) might indicate that the GCNN's decision function is \"sharp\" or brittle in that region.\n",
    "# - An adversary could use such information to target the most sensitive input directions, while a defender might regularize the model to minimize the Jacobian norm.\n",
    "#\n",
    "# Verification:\n",
    "# - The relative error is used as a measure: If it is low (e.g., < 1%), then the linear approximation (Jacobian) is a reliable indicator of local sensitivity.\n",
    "# - This provides confidence that the model's predictions are indeed highly sensitive to specific segments of the input space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81e433b",
   "metadata": {},
   "source": [
    "##### Several Samples per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3969940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class-wise Jacobian Analysis Results:\n",
      "Class            Avg. Jacobian Norm Â± Std           Avg. Relative Error Â± Std\n",
      "-----------------------------------------------------------------------------\n",
      "and                 7.4365 Â± 1.5834            9.8170e-04 Â± 7.2927e-03\n",
      "or                  5.7241 Â± 0.4275            2.9550e-04 Â± 1.7438e-04\n",
      "nand                6.4330 Â± 1.9736            1.4521e-04 Â± 1.7947e-04\n",
      "nor                 5.5897 Â± 0.9371            1.7155e-04 Â± 1.1367e-04\n",
      "xor                 8.6396 Â± 1.1227            1.2890e-04 Â± 7.7688e-05\n",
      "xnor                6.0443 Â± 2.4619            1.2810e-02 Â± 4.6570e-02\n",
      "buf                 4.5112 Â± 0.1996            4.3216e-04 Â± 2.4847e-04\n",
      "not                 4.0101 Â± 0.0797            1.0110e-03 Â± 4.8172e-04\n",
      "\n",
      "Overall Aggregated Jacobian Analysis Results:\n",
      "Average Jacobian Norm: 6.2440 Â± 1.9325\n",
      "Average Relative Error: 2.0916e-03 Â± 1.7965e-02\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Define gate types corresponding to the labels\n",
    "gate_types = ['and', 'or', 'nand', 'nor', 'xor', 'xnor', 'buf', 'not']\n",
    "\n",
    "# Dictionary to store metrics for each class\n",
    "class_metrics = {gt: {'jacobian_norms': [], 'relative_errors': []} for gt in gate_types}\n",
    "overall_jacobian_norms = []\n",
    "overall_relative_errors = []\n",
    "\n",
    "# Function to compute the Jacobian for a given test index.\n",
    "def compute_jacobian_for_sample(test_idx):\n",
    "    # Get the feature vector for the selected test node and require gradients.\n",
    "    x0 = graph.ndata['features'][test_idx].clone().detach().requires_grad_(True)\n",
    "    def f(x):\n",
    "        new_features = graph.ndata['features'].clone().detach()\n",
    "        new_features[test_idx] = x\n",
    "        output = model(graph, new_features)\n",
    "        return output[test_idx]\n",
    "    # Compute the Jacobian of f with respect to x0.\n",
    "    jacobian = torch.autograd.functional.jacobian(f, x0)\n",
    "    return jacobian, x0, f\n",
    "\n",
    "# Loop over each selected test node (100 per class)\n",
    "# Taken same as earlier metric (Local Lipschitz Constant) copy that code here.\n",
    "for test_idx in selected_test_nodes:\n",
    "    # Determine the ground-truth label and corresponding gate type.\n",
    "    label_idx = graph.ndata['labels'][test_idx].item()\n",
    "    class_name = gate_types[label_idx]\n",
    "    \n",
    "    # Compute the Jacobian for the selected test node.\n",
    "    jacobian, x0, f = compute_jacobian_for_sample(test_idx)\n",
    "    # Compute the Frobenius norm of the Jacobian.\n",
    "    jacobian_norm = torch.norm(jacobian, p='fro').item()\n",
    "    \n",
    "    # Finite-difference verification:\n",
    "    epsilon = 1e-3\n",
    "    delta = epsilon * torch.randn_like(x0)\n",
    "    predicted_change = jacobian.mv(delta)\n",
    "    f_x0 = f(x0)\n",
    "    f_x0_perturbed = f(x0 + delta)\n",
    "    actual_change = f_x0_perturbed - f_x0\n",
    "    relative_error = (torch.norm(predicted_change - actual_change) /\n",
    "                      (torch.norm(actual_change) + 1e-8)).item()\n",
    "    \n",
    "    # Store values for the current sample.\n",
    "    class_metrics[class_name]['jacobian_norms'].append(jacobian_norm)\n",
    "    class_metrics[class_name]['relative_errors'].append(relative_error)\n",
    "    overall_jacobian_norms.append(jacobian_norm)\n",
    "    overall_relative_errors.append(relative_error)\n",
    "\n",
    "# Display per-class results in a tabular format.\n",
    "print(\"\\nClass-wise Jacobian Analysis Results:\")\n",
    "header = \"{:<10s} {:>30s} {:>35s}\".format(\"Class\", \"Avg. Jacobian Norm Â± Std\", \"Avg. Relative Error Â± Std\")\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for cls in gate_types:\n",
    "    norms = class_metrics[cls]['jacobian_norms']\n",
    "    errors = class_metrics[cls]['relative_errors']\n",
    "    avg_norm = np.mean(norms) if norms else 0\n",
    "    std_norm = np.std(norms) if norms else 0\n",
    "    avg_rel_error = np.mean(errors) if errors else 0\n",
    "    std_rel_error = np.std(errors) if errors else 0\n",
    "    print(\"{:<10s} {:>15.4f} Â± {:<12.4f} {:>15.4e} Â± {:<10.4e}\".format(\n",
    "        cls, avg_norm, std_norm, avg_rel_error, std_rel_error))\n",
    "\n",
    "# Compute overall aggregated metrics.\n",
    "overall_avg_norm = np.mean(overall_jacobian_norms)\n",
    "overall_std_norm = np.std(overall_jacobian_norms)\n",
    "overall_avg_rel_error = np.mean(overall_relative_errors)\n",
    "overall_std_rel_error = np.std(overall_relative_errors)\n",
    "\n",
    "print(\"\\nOverall Aggregated Jacobian Analysis Results:\")\n",
    "print(\"Average Jacobian Norm: {:.4f} Â± {:.4f}\".format(overall_avg_norm, overall_std_norm))\n",
    "print(\"Average Relative Error: {:.4e} Â± {:.4e}\".format(overall_avg_rel_error, overall_std_rel_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51079a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling report:\n",
      "- and: picked 100 from 5637 available.\n",
      "- input: picked 100 from 475 available.\n",
      "- nand: picked 100 from 527 available.\n",
      "- nor: picked 100 from 567 available.\n",
      "- not: picked 100 from 4478 available.\n",
      "- or: picked 100 from 197 available.\n",
      "- output: picked 100 from 266 available.\n",
      "- xor: only 30 available, taking all.\n",
      "\n",
      "Final counts in selected perturbed set:\n",
      "- and: 100\n",
      "- input: 100\n",
      "- nand: 100\n",
      "- nor: 100\n",
      "- not: 100\n",
      "- or: 100\n",
      "- output: 100\n",
      "- xor: 30\n",
      "\n",
      "âœ… Accuracy on Perturbed Set: 69.32%\n",
      "Precision: 0.6781\n",
      "Recall:    0.6932\n",
      "F1 Score:  0.6338\n",
      "\n",
      "Confusion Matrix (Perturbed Set, all classes):\n",
      "[[ 99   0   0   1   0   0   0   0]\n",
      " [  0  99   1   0   0   0   0   0]\n",
      " [ 82   0   3  15   0   0   0   0]\n",
      " [ 24   0   1  75   0   0   0   0]\n",
      " [  0   0   0   0 100   0   0   0]\n",
      " [ 99   0   1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 100   0]\n",
      " [  0   0   0   0   0   0   0  30]]\n",
      "\n",
      "Classification Report (present classes only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         and       0.33      0.99      0.49       100\n",
      "       input       1.00      0.99      0.99       100\n",
      "        nand       0.50      0.03      0.06       100\n",
      "         nor       0.82      0.75      0.79       100\n",
      "         not       1.00      1.00      1.00       100\n",
      "          or       0.00      0.00      0.00       100\n",
      "      output       1.00      1.00      1.00       100\n",
      "         xor       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.69       730\n",
      "   macro avg       0.71      0.72      0.67       730\n",
      "weighted avg       0.68      0.69      0.63       730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "\n",
    "# Ensure we have a NumPy array of node indices for the test set\n",
    "if torch.is_tensor(test_mask):\n",
    "    test_indices = test_mask.cpu().numpy()\n",
    "else:\n",
    "    test_indices = np.array(test_mask)\n",
    "\n",
    "labels_np = graph.ndata['labels'].cpu().numpy()\n",
    "class_names = list(label_encoder.classes_)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "rng = np.random.default_rng(seed=42)\n",
    "PER_CLASS = 100\n",
    "selected_test_nodes = []\n",
    "\n",
    "print(\"\\nSampling report:\")\n",
    "for c in range(num_classes):\n",
    "    idxs = [int(i) for i in test_indices if labels_np[int(i)] == c]\n",
    "    n_avail = len(idxs)\n",
    "\n",
    "    if n_avail == 0:\n",
    "        print(f\"- {class_names[c]}: 0 available in test set â€” skipped.\")\n",
    "        continue\n",
    "\n",
    "    if n_avail >= PER_CLASS:\n",
    "        chosen = rng.choice(idxs, size=PER_CLASS, replace=False)\n",
    "        print(f\"- {class_names[c]}: picked 100 from {n_avail} available.\")\n",
    "    else:\n",
    "        chosen = idxs\n",
    "        print(f\"- {class_names[c]}: only {n_avail} available, taking all.\")\n",
    "\n",
    "    selected_test_nodes.extend(chosen)\n",
    "\n",
    "selected_test_nodes = np.array(selected_test_nodes, dtype=np.int64)\n",
    "\n",
    "# Sanity check counts\n",
    "counts = {class_names[c]: int(np.sum(labels_np[selected_test_nodes] == c)) for c in range(num_classes)}\n",
    "print(\"\\nFinal counts in selected perturbed set:\")\n",
    "for name, cnt in counts.items():\n",
    "    print(f\"- {name}: {cnt}\")\n",
    "\n",
    "# Clone features for perturbation\n",
    "perturbed_features = graph.ndata['features'].clone().detach()\n",
    "epsilon = 0.05  # tweak for stronger/weaker perturbations\n",
    "\n",
    "for node_idx in selected_test_nodes:\n",
    "    x0 = graph.ndata['features'][node_idx]\n",
    "    if 'jacobian_perturbations' in globals() and node_idx in jacobian_perturbations:\n",
    "        delta = jacobian_perturbations[node_idx]\n",
    "        norm = torch.norm(delta)\n",
    "        if norm.item() > 0:\n",
    "            delta = epsilon * delta / norm\n",
    "    else:\n",
    "        delta = epsilon * torch.randn_like(x0)\n",
    "    perturbed_features[node_idx] = (x0 + delta)\n",
    "\n",
    "eval_idx = torch.tensor(selected_test_nodes, dtype=torch.long)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_pert = model(graph, perturbed_features)\n",
    "    preds = logits_pert[eval_idx].argmax(dim=1).cpu().numpy()\n",
    "    labels_true = labels_np[eval_idx]\n",
    "\n",
    "acc = np.mean(preds == labels_true)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_true, preds, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\nâœ… Accuracy on Perturbed Set: {acc * 100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(labels_true, preds, labels=np.arange(num_classes))\n",
    "print(\"\\nConfusion Matrix (Perturbed Set, all classes):\")\n",
    "print(cm)\n",
    "\n",
    "present_labels = np.unique(labels_true)\n",
    "present_names = [class_names[i] for i in present_labels]\n",
    "print(\"\\nClassification Report (present classes only):\")\n",
    "print(classification_report(labels_true, preds,\n",
    "                            labels=present_labels,\n",
    "                            target_names=present_names,\n",
    "                            zero_division=0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46efec1",
   "metadata": {},
   "source": [
    "#### Local Lipschitz constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf46d7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Local Lipschitz Constant Computation and Verification (100 Samples Per Class) ---\n",
      "\n",
      "\n",
      "Class-wise Local Lipschitz Constant Results:\n",
      "Class        Avg Lipschitz Constant Â± Std\n",
      "-----------------------------------------\n",
      "and                 5.5017 Â± 1.1898      \n",
      "or                  5.1081 Â± 0.4761      \n",
      "nand                4.6870 Â± 1.4592      \n",
      "nor                 4.2143 Â± 0.6937      \n",
      "xor                 7.0457 Â± 0.9065      \n",
      "xnor                4.4031 Â± 1.7521      \n",
      "buf                 3.2364 Â± 0.1262      \n",
      "not                 2.9905 Â± 0.0312      \n",
      "\n",
      "Overall Aggregated Local Lipschitz Constant:\n",
      "Average Lipschitz Constant: 4.8073 Â± 1.5585\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n--- Local Lipschitz Constant Computation and Verification (100 Samples Per Class) ---\\n\")\n",
    "\n",
    "# Initialize dictionaries to store the local Lipschitz constants (L_i) for each class.\n",
    "class_lipschitz = {gt: [] for gt in gate_types}\n",
    "overall_lipschitz = []\n",
    "\n",
    "def compute_jacobian_for_sample(test_idx):\n",
    "    \"\"\"\n",
    "    Compute the Jacobian matrix for a given test index.\n",
    "    Returns the Jacobian, the original input x0, and the output function f.\n",
    "    \"\"\"\n",
    "    x0 = graph.ndata['features'][test_idx].clone().detach().requires_grad_(True)\n",
    "    \n",
    "    def f(x):\n",
    "        new_features = graph.ndata['features'].clone().detach()\n",
    "        new_features[test_idx] = x\n",
    "        output = model(graph, new_features)\n",
    "        return output[test_idx]\n",
    "    \n",
    "    jacobian = torch.autograd.functional.jacobian(f, x0)\n",
    "    return jacobian, x0, f\n",
    "\n",
    "# Iterate over each selected test node from the chosen 100 samples per class.\n",
    "for test_idx in selected_test_nodes:\n",
    "    label_idx = graph.ndata['labels'][test_idx].item()\n",
    "    class_name = gate_types[label_idx]\n",
    "    \n",
    "    # Compute the Jacobian for this sample.\n",
    "    jacobian, x0, f = compute_jacobian_for_sample(test_idx)\n",
    "    \n",
    "    # The local Lipschitz constant is approximated as the spectral norm (i.e., the largest singular value)\n",
    "    # of the Jacobian matrix.\n",
    "    L_local = torch.linalg.norm(jacobian, ord=2).item()\n",
    "    \n",
    "    # Store the value per class and overall.\n",
    "    class_lipschitz[class_name].append(L_local)\n",
    "    overall_lipschitz.append(L_local)\n",
    "\n",
    "# Print the per-class results in a tabular format.\n",
    "print(\"\\nClass-wise Local Lipschitz Constant Results:\")\n",
    "header = \"{:<10s} {:>30s}\".format(\"Class\", \"Avg Lipschitz Constant Â± Std\")\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for cls in gate_types:\n",
    "    values = class_lipschitz[cls]\n",
    "    if len(values) > 0:\n",
    "        avg_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "    else:\n",
    "        avg_val = 0\n",
    "        std_val = 0\n",
    "    print(\"{:<10s} {:>15.4f} Â± {:<12.4f}\".format(cls, avg_val, std_val))\n",
    "    \n",
    "# Compute and display the overall aggregated metrics.\n",
    "overall_avg = np.mean(overall_lipschitz)\n",
    "overall_std = np.std(overall_lipschitz)\n",
    "print(\"\\nOverall Aggregated Local Lipschitz Constant:\")\n",
    "print(\"Average Lipschitz Constant: {:.4f} Â± {:.4f}\".format(overall_avg, overall_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f44ef157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Local Lipschitz Constant Computation & Relative Error Verification (100 Samples Per Class) ---\n",
      "\n",
      "\n",
      "Class-wise Local Lipschitz (with Relative Errors):\n",
      "Class              Avg Lipschitz Â± Std           Avg Rel. Error Â± Std\n",
      "---------------------------------------------------------------------\n",
      "and               5.5017 Â± 1.1898          2.4428e+00 Â± 6.0427e-01\n",
      "input             5.1081 Â± 0.4761          3.5274e+00 Â± 8.0134e-01\n",
      "nand              4.6870 Â± 1.4592          2.3030e+00 Â± 5.6106e-01\n",
      "nor               4.2143 Â± 0.6937          2.3866e+00 Â± 4.9467e-01\n",
      "not               7.0457 Â± 0.9065          2.9362e+00 Â± 7.1395e-01\n",
      "or                4.4031 Â± 1.7521          2.3817e+00 Â± 5.2646e-01\n",
      "output            3.2364 Â± 0.1262          2.1944e+00 Â± 4.3944e-01\n",
      "xor               2.9905 Â± 0.0312          2.3049e+00 Â± 3.0851e-01\n",
      "\n",
      "Overall Aggregated:\n",
      "Avg Lipschitz Constant: 4.8073 Â± 1.5585\n",
      "Avg Relative Error: 2.5840e+00 Â± 7.3497e-01\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n--- Local Lipschitz Constant Computation & Relative Error Verification (100 Samples Per Class) ---\\n\")\n",
    "\n",
    "# âœ… Get class names directly from label_encoder so they match the label indices\n",
    "class_names = list(label_encoder.classes_)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Build selected_test_nodes\n",
    "# -----------------------------\n",
    "rng = np.random.default_rng(42)  # for reproducibility\n",
    "test_labels = graph.ndata['labels'][test_mask].cpu().numpy()\n",
    "test_indices = test_mask.cpu().numpy()\n",
    "\n",
    "# Group test indices by class\n",
    "per_class_indices = {cls_idx: [] for cls_idx in range(len(class_names))}\n",
    "for idx, lbl in zip(test_indices, test_labels):\n",
    "    per_class_indices[lbl].append(idx)\n",
    "\n",
    "# Randomly choose up to 100 samples per class\n",
    "selected_test_nodes = []\n",
    "for cls_idx, idxs in per_class_indices.items():\n",
    "    if len(idxs) > 0:\n",
    "        k = min(100, len(idxs))\n",
    "        chosen = rng.choice(idxs, size=k, replace=False).tolist()\n",
    "        selected_test_nodes.extend(chosen)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Metrics storage\n",
    "# -----------------------------\n",
    "class_lipschitz = {cn: [] for cn in class_names}\n",
    "class_rel_errors = {cn: [] for cn in class_names}\n",
    "overall_lipschitz = []\n",
    "overall_rel_errors = []\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Jacobian helper\n",
    "# -----------------------------\n",
    "def compute_jacobian_for_sample(test_idx):\n",
    "    x0 = graph.ndata['features'][test_idx].clone().detach().requires_grad_(True)\n",
    "    def f(x):\n",
    "        new_features = graph.ndata['features'].clone().detach()\n",
    "        new_features[test_idx] = x\n",
    "        return model(graph, new_features)[test_idx]\n",
    "    J = torch.autograd.functional.jacobian(f, x0)\n",
    "    return J, x0, f\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Main loop with relative error check\n",
    "# -----------------------------\n",
    "epsilon = 1e-3\n",
    "trials_per_node = 10\n",
    "\n",
    "for test_idx in selected_test_nodes:\n",
    "    label_idx = graph.ndata['labels'][test_idx].item()\n",
    "    class_name = class_names[label_idx]\n",
    "\n",
    "    J, x0, f = compute_jacobian_for_sample(test_idx)\n",
    "    L_local = torch.linalg.norm(J, ord=2).item()\n",
    "\n",
    "    # Relative error: average over multiple random perturbations\n",
    "    rel_errors_for_node = []\n",
    "    for _ in range(trials_per_node):\n",
    "        delta = epsilon * torch.randn_like(x0)\n",
    "        pred_change_norm = L_local * torch.norm(delta).item()\n",
    "        actual_change_norm = torch.norm(f(x0 + delta) - f(x0)).item()\n",
    "        rel_error = abs(pred_change_norm - actual_change_norm) / (actual_change_norm + 1e-8)\n",
    "        rel_errors_for_node.append(rel_error)\n",
    "\n",
    "    avg_rel_error_node = float(np.mean(rel_errors_for_node))\n",
    "\n",
    "    # Store\n",
    "    class_lipschitz[class_name].append(L_local)\n",
    "    class_rel_errors[class_name].append(avg_rel_error_node)\n",
    "    overall_lipschitz.append(L_local)\n",
    "    overall_rel_errors.append(avg_rel_error_node)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Reporting\n",
    "# -----------------------------\n",
    "print(\"\\nClass-wise Local Lipschitz (with Relative Errors):\")\n",
    "header = \"{:<12s} {:>25s} {:>30s}\".format(\"Class\", \"Avg Lipschitz Â± Std\", \"Avg Rel. Error Â± Std\")\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for cn in class_names:\n",
    "    L_vals = class_lipschitz[cn]\n",
    "    E_vals = class_rel_errors[cn]\n",
    "    if L_vals:\n",
    "        print(\"{:<12s} {:>11.4f} Â± {:<10.4f} {:>15.4e} Â± {:<10.4e}\".format(\n",
    "            cn, np.mean(L_vals), np.std(L_vals), np.mean(E_vals), np.std(E_vals)\n",
    "        ))\n",
    "    else:\n",
    "        print(\"{:<12s} {:>11s} {:>10s} {:>15s} {:>10s}\".format(cn, \"-\", \"-\", \"-\", \"-\"))\n",
    "\n",
    "print(\"\\nOverall Aggregated:\")\n",
    "print(\"Avg Lipschitz Constant: {:.4f} Â± {:.4f}\".format(np.mean(overall_lipschitz), np.std(overall_lipschitz)))\n",
    "print(\"Avg Relative Error: {:.4e} Â± {:.4e}\".format(np.mean(overall_rel_errors), np.std(overall_rel_errors)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1f5a994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling report:\n",
      "- and: picked 100 from 5637 available.\n",
      "- input: picked 100 from 475 available.\n",
      "- nand: picked 100 from 527 available.\n",
      "- nor: picked 100 from 567 available.\n",
      "- not: picked 100 from 4478 available.\n",
      "- or: picked 100 from 197 available.\n",
      "- output: picked 100 from 266 available.\n",
      "- xor: only 30 available, taking all.\n",
      "\n",
      "âœ… Accuracy on Perturbed Set: 69.59%\n",
      "Precision: 0.7171\n",
      "Recall:    0.6959\n",
      "F1 Score:  0.6479\n",
      "\n",
      "Confusion Matrix (Perturbed Set, all classes):\n",
      "[[ 96   0   1   3   0   0   0   0]\n",
      " [  0 100   0   0   0   0   0   0]\n",
      " [ 83   0   9   8   0   0   0   0]\n",
      " [ 26   0   1  73   0   0   0   0]\n",
      " [  0   0   0   0 100   0   0   0]\n",
      " [ 99   0   1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 100   0]\n",
      " [  0   0   0   0   0   0   0  30]]\n",
      "\n",
      "Classification Report (present classes only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         and       0.32      0.96      0.48       100\n",
      "       input       1.00      1.00      1.00       100\n",
      "        nand       0.75      0.09      0.16       100\n",
      "         nor       0.87      0.73      0.79       100\n",
      "         not       1.00      1.00      1.00       100\n",
      "          or       0.00      0.00      0.00       100\n",
      "      output       1.00      1.00      1.00       100\n",
      "         xor       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.70       730\n",
      "   macro avg       0.74      0.72      0.68       730\n",
      "weighted avg       0.72      0.70      0.65       730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Assume:\n",
    "#  - `selected_test_nodes` already exists (from sampling step)\n",
    "#  - `jacobian_perturbations` is a dict: node_idx -> perturbation tensor\n",
    "#  - `graph`, `model`, `label_encoder` already defined\n",
    "# -------------------------------------------------\n",
    "\n",
    "# Ensure we have a NumPy array of node indices for the test set\n",
    "if torch.is_tensor(test_mask):\n",
    "    test_indices = test_mask.cpu().numpy()\n",
    "else:\n",
    "    test_indices = np.array(test_mask)\n",
    "\n",
    "labels_np = graph.ndata['labels'].cpu().numpy()\n",
    "class_names = list(label_encoder.classes_)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "rng = np.random.default_rng(seed=12)\n",
    "PER_CLASS = 100\n",
    "selected_test_nodes = []\n",
    "\n",
    "print(\"\\nSampling report:\")\n",
    "for c in range(num_classes):\n",
    "    idxs = [int(i) for i in test_indices if labels_np[int(i)] == c]\n",
    "    n_avail = len(idxs)\n",
    "\n",
    "    if n_avail == 0:\n",
    "        print(f\"- {class_names[c]}: 0 available in test set â€” skipped.\")\n",
    "        continue\n",
    "\n",
    "    if n_avail >= PER_CLASS:\n",
    "        chosen = rng.choice(idxs, size=PER_CLASS, replace=False)\n",
    "        print(f\"- {class_names[c]}: picked 100 from {n_avail} available.\")\n",
    "    else:\n",
    "        chosen = idxs\n",
    "        print(f\"- {class_names[c]}: only {n_avail} available, taking all.\")\n",
    "\n",
    "    selected_test_nodes.extend(chosen)\n",
    "\n",
    "selected_test_nodes = np.array(selected_test_nodes, dtype=np.int64)\n",
    "\n",
    "labels_np = graph.ndata['labels'].cpu().numpy()\n",
    "class_names = list(label_encoder.classes_)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Clone features for perturbation\n",
    "perturbed_features = graph.ndata['features'].clone().detach()\n",
    "\n",
    "epsilon = 0.05  # adjust perturbation strength if needed\n",
    "\n",
    "for node_idx in selected_test_nodes:\n",
    "    x0 = graph.ndata['features'][node_idx]\n",
    "    if 'jacobian_perturbations' in globals() and node_idx in jacobian_perturbations:\n",
    "        delta = jacobian_perturbations[node_idx]\n",
    "        norm = torch.norm(delta)\n",
    "        if norm.item() > 0:\n",
    "            delta = epsilon * delta / norm\n",
    "    else:\n",
    "        delta = epsilon * torch.randn_like(x0)\n",
    "    perturbed_features[node_idx] = (x0 + delta)\n",
    "\n",
    "# Evaluate only on these perturbed nodes\n",
    "eval_idx = torch.tensor(selected_test_nodes, dtype=torch.long)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_pert = model(graph, perturbed_features)\n",
    "    preds = logits_pert[eval_idx].argmax(dim=1).cpu().numpy()\n",
    "    labels_true = labels_np[eval_idx]\n",
    "\n",
    "# Metrics\n",
    "acc = np.mean(preds == labels_true)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_true, preds, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\nâœ… Accuracy on Perturbed Set: {acc * 100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# Confusion matrix for all classes\n",
    "cm = confusion_matrix(labels_true, preds, labels=np.arange(num_classes))\n",
    "print(\"\\nConfusion Matrix (Perturbed Set, all classes):\")\n",
    "print(cm)\n",
    "\n",
    "# Classification report for present classes only\n",
    "present_labels = np.unique(labels_true)\n",
    "present_names = [class_names[i] for i in present_labels]\n",
    "print(\"\\nClassification Report (present classes only):\")\n",
    "print(classification_report(labels_true, preds,\n",
    "                            labels=present_labels,\n",
    "                            target_names=present_names,\n",
    "                            zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b5349e",
   "metadata": {},
   "source": [
    "#### Hessian-Based Curvature Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2de8353f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hessian-Based Curvature Measure Computation (100 Samples Per Class) ---\n",
      "\n",
      "\n",
      "Class-wise Hessian-Based Curvature Results:\n",
      "Class                Avg. Max Eigenvalue Â± Std\n",
      "----------------------------------------------\n",
      "and                 0.0000 Â± 0.0000         \n",
      "or                  0.0000 Â± 0.0000         \n",
      "nand                0.0000 Â± 0.0000         \n",
      "nor                 0.0000 Â± 0.0000         \n",
      "xor                 0.0000 Â± 0.0000         \n",
      "xnor                0.0000 Â± 0.0000         \n",
      "buf                 0.0000 Â± 0.0000         \n",
      "not                 0.0000 Â± 0.0000         \n",
      "\n",
      "Overall Aggregated Hessian-Based Curvature Measure:\n",
      "Average Max Eigenvalue: 0.0000 Â± 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n--- Hessian-Based Curvature Measure Computation (100 Samples Per Class) ---\\n\")\n",
    "\n",
    "# Define gate types corresponding to your labels.\n",
    "gate_types = ['and', 'or', 'nand', 'nor', 'xor', 'xnor', 'buf', 'not']\n",
    "\n",
    "# Dictionary to store the maximum eigenvalue (lambda_max) for each gate type.\n",
    "class_hessian_eig = {gt: [] for gt in gate_types}\n",
    "overall_hessian_eig = []\n",
    "\n",
    "def compute_hessian_for_sample(test_idx):\n",
    "    \"\"\"\n",
    "    Compute the Hessian-based curvature measure for a given test sample.\n",
    "    We define a scalar function h(x) as the log probability (via log-softmax) \n",
    "    of the predicted class (determined on the unperturbed input). This helps\n",
    "    introduce nonlinearity, thereby yielding nonzero second-order derivatives.\n",
    "    \"\"\"\n",
    "    # Retrieve the feature vector for the test node and require gradients.\n",
    "    x0 = graph.ndata['features'][test_idx].clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Determine the predicted class for the test node.\n",
    "    with torch.no_grad():\n",
    "        logits = model(graph, graph.ndata['features'])\n",
    "        pred_class = torch.argmax(logits[test_idx])\n",
    "    \n",
    "    # Define a scalar function h(x) that returns log probability for the predicted class.\n",
    "    def h(x):\n",
    "        new_features = graph.ndata['features'].clone().detach()\n",
    "        new_features[test_idx] = x\n",
    "        logits = model(graph, new_features)[test_idx]\n",
    "        log_probs = torch.log_softmax(logits, dim=0)\n",
    "        return log_probs[pred_class]\n",
    "    \n",
    "    # Compute the Hessian of h(x) at x0.\n",
    "    H = torch.autograd.functional.hessian(h, x0, create_graph=False, vectorize=False)\n",
    "    H = H.detach()\n",
    "    \n",
    "    # Compute eigenvalues using a symmetric eigendecomposition.\n",
    "    eigvals = torch.linalg.eigvalsh(H)\n",
    "    lambda_max = torch.max(eigvals).item()\n",
    "    return lambda_max, x0, h\n",
    "\n",
    "# Iterate over each selected test node (assumed to be 100 samples per class).\n",
    "for test_idx in selected_test_nodes:\n",
    "    label_idx = graph.ndata['labels'][test_idx].item()\n",
    "    class_name = gate_types[label_idx]\n",
    "    \n",
    "    lambda_max, x0, h_func = compute_hessian_for_sample(test_idx)\n",
    "    class_hessian_eig[class_name].append(lambda_max)\n",
    "    overall_hessian_eig.append(lambda_max)\n",
    "\n",
    "# Display per-class results in a tabular format.\n",
    "print(\"\\nClass-wise Hessian-Based Curvature Results:\")\n",
    "header = \"{:<10s} {:>35s}\".format(\"Class\", \"Avg. Max Eigenvalue Â± Std\")\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for cls in gate_types:\n",
    "    values = class_hessian_eig[cls]\n",
    "    if len(values) > 0:\n",
    "        avg_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "    else:\n",
    "        avg_val, std_val = 0, 0\n",
    "    print(\"{:<10s} {:>15.4f} Â± {:<15.4f}\".format(cls, avg_val, std_val))\n",
    "\n",
    "# Compute and display the overall aggregated result.\n",
    "overall_avg = np.mean(overall_hessian_eig)\n",
    "overall_std = np.std(overall_hessian_eig)\n",
    "print(\"\\nOverall Aggregated Hessian-Based Curvature Measure:\")\n",
    "print(\"Average Max Eigenvalue: {:.4f} Â± {:.4f}\".format(overall_avg, overall_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab5750ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Hessian-Based Curvature Measure & Relative Error Verification (100 Samples Per Class) ---\n",
      "\n",
      "\n",
      "Class-wise Hessian-Based Curvature (with Relative Errors):\n",
      "Class                Avg. Max Eigenvalue Â± Std           Avg Rel. Error Â± Std\n",
      "-----------------------------------------------------------------------------\n",
      "and               0.0000 Â± 0.0000          1.6139e-01 Â± 1.9902e-01\n",
      "input             0.0000 Â± 0.0000          9.4402e-01 Â± 6.8588e-01\n",
      "nand              0.0000 Â± 0.0000          8.3175e-02 Â± 1.3977e-01\n",
      "nor               0.0000 Â± 0.0000          1.0848e-01 Â± 1.9403e-01\n",
      "not               0.0000 Â± 0.0000          1.7743e-01 Â± 2.5927e-01\n",
      "or                0.0000 Â± 0.0000          7.6506e-01 Â± 5.0202e+00\n",
      "output            0.0000 Â± 0.0000          6.1122e-01 Â± 3.7771e-01\n",
      "xor               0.0000 Â± 0.0000          2.6412e-01 Â± 2.0793e-01\n",
      "\n",
      "Overall Aggregated Hessian-Based Curvature:\n",
      "Avg Max Eigenvalue: 0.0000 Â± 0.0000\n",
      "Avg Relative Error: 4.0137e-01 Â± 1.9147e+00\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n--- Hessian-Based Curvature Measure & Relative Error Verification (100 Samples Per Class) ---\\n\")\n",
    "\n",
    "# Use class names aligned with the label encoder to match label indices\n",
    "class_names = list(label_encoder.classes_)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Build selected_test_nodes: up to 100 random test nodes per class\n",
    "# -----------------------------\n",
    "# Taken same as earlier metric (Local Lipschitz Constant)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Storage for metrics\n",
    "# -----------------------------\n",
    "class_hessian_eig = {cn: [] for cn in class_names}         # lambda_max (curvature proxy)\n",
    "class_rel_errors  = {cn: [] for cn in class_names}         # relative error of second-order approximation\n",
    "overall_hessian_eig = []\n",
    "overall_rel_errors = []\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Helper to compute H, grad, and scalar function h at x0\n",
    "# -----------------------------\n",
    "def compute_hessian_and_grad_for_sample(test_idx):\n",
    "    \"\"\"\n",
    "    Compute Hessian H and gradient g of h(x) at x0 for node test_idx.\n",
    "    h(x) = log-softmax(logits(x))[pred_class(x0)], i.e., log prob of class predicted at x0.\n",
    "    \"\"\"\n",
    "    # Base input with gradients\n",
    "    x0 = graph.ndata['features'][test_idx].clone().detach().requires_grad_(True)\n",
    "\n",
    "    # Determine the predicted class at the unperturbed point\n",
    "    with torch.no_grad():\n",
    "        base_logits = model(graph, graph.ndata['features'])\n",
    "        pred_class = torch.argmax(base_logits[test_idx])\n",
    "\n",
    "    # Scalar function: log prob of the predicted class at x0\n",
    "    def h(x):\n",
    "        new_features = graph.ndata['features'].clone().detach()\n",
    "        new_features[test_idx] = x\n",
    "        logits = model(graph, new_features)[test_idx]\n",
    "        log_probs = torch.log_softmax(logits, dim=0)\n",
    "        return log_probs[pred_class]\n",
    "\n",
    "    # Hessian (d^2 h / dx^2) at x0\n",
    "    H = torch.autograd.functional.hessian(h, x0, create_graph=False, vectorize=False).detach()\n",
    "\n",
    "    # Gradient g = dh/dx at x0\n",
    "    x0_grad = torch.autograd.functional.jacobian(h, x0).detach()\n",
    "\n",
    "    # Scalar baseline h(x0)\n",
    "    h0 = h(x0.detach())\n",
    "\n",
    "    return H, x0.detach(), x0_grad, h0, h\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Main loop with second-order verification\n",
    "# -----------------------------\n",
    "epsilon = 5e-3          # small step; second-order term ~ O(eps^2)\n",
    "trials_per_node = 10    # average over multiple directions to reduce noise\n",
    "\n",
    "for test_idx in selected_test_nodes:\n",
    "    label_idx = int(graph.ndata['labels'][test_idx].item())\n",
    "    class_name = class_names[label_idx]\n",
    "\n",
    "    # Compute Hessian, gradient, baseline\n",
    "    H, x0, g, h0, h_func = compute_hessian_and_grad_for_sample(test_idx)\n",
    "\n",
    "    # Curvature proxy: largest eigenvalue of H (symmetric)\n",
    "    try:\n",
    "        eigvals = torch.linalg.eigvalsh(H)\n",
    "        lambda_max = torch.max(eigvals).item()\n",
    "    except RuntimeError:\n",
    "        # Fallback in rare numerical issues: use power iteration on symmetric H\n",
    "        v = torch.randn_like(x0)\n",
    "        v = v / (v.norm() + 1e-12)\n",
    "        num_pi = 20\n",
    "        for _ in range(num_pi):\n",
    "            v = H @ v\n",
    "            v_norm = v.norm() + 1e-12\n",
    "            v = v / v_norm\n",
    "        lambda_max = torch.dot(v, H @ v).item()\n",
    "\n",
    "    # Relative error of second-order approximation:\n",
    "    # predicted second-order change: 0.5 * delta^T H delta\n",
    "    # actual second-order change: h(x0 + delta) - h(x0) - g^T delta\n",
    "    node_errors = []\n",
    "    for _ in range(trials_per_node):\n",
    "        delta = epsilon * torch.randn_like(x0)\n",
    "\n",
    "        # Predicted second-order change via Hessian quadratic form\n",
    "        pred_second = 0.5 * torch.dot(delta, H @ delta).item()\n",
    "\n",
    "        # Actual second-order change (subtract linear term)\n",
    "        actual_second = (h_func(x0 + delta) - h0 - torch.dot(g, delta)).item()\n",
    "\n",
    "        rel_error = abs(pred_second - actual_second) / (abs(actual_second) + 1e-8)\n",
    "        node_errors.append(rel_error)\n",
    "\n",
    "    avg_rel_error_node = float(np.mean(node_errors))\n",
    "\n",
    "    # Store metrics\n",
    "    class_hessian_eig[class_name].append(lambda_max)\n",
    "    class_rel_errors[class_name].append(avg_rel_error_node)\n",
    "    overall_hessian_eig.append(lambda_max)\n",
    "    overall_rel_errors.append(avg_rel_error_node)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Reporting\n",
    "# -----------------------------\n",
    "print(\"\\nClass-wise Hessian-Based Curvature (with Relative Errors):\")\n",
    "header = \"{:<12s} {:>33s} {:>30s}\".format(\"Class\", \"Avg. Max Eigenvalue Â± Std\", \"Avg Rel. Error Â± Std\")\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for cn in class_names:\n",
    "    c_vals = class_hessian_eig[cn]\n",
    "    e_vals = class_rel_errors[cn]\n",
    "    if c_vals:\n",
    "        print(\"{:<12s} {:>11.4f} Â± {:<10.4f} {:>15.4e} Â± {:<10.4e}\".format(\n",
    "            cn, np.mean(c_vals), np.std(c_vals), np.mean(e_vals), np.std(e_vals)\n",
    "        ))\n",
    "    else:\n",
    "        print(\"{:<12s} {:>11s} {:<10s} {:>15s} {:<10s}\".format(cn, \"-\", \"-\", \"-\", \"-\"))\n",
    "\n",
    "print(\"\\nOverall Aggregated Hessian-Based Curvature:\")\n",
    "print(\"Avg Max Eigenvalue: {:.4f} Â± {:.4f}\".format(np.mean(overall_hessian_eig), np.std(overall_hessian_eig)))\n",
    "print(\"Avg Relative Error: {:.4e} Â± {:.4e}\".format(np.mean(overall_rel_errors), np.std(overall_rel_errors)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d11295ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling report:\n",
      "- and: picked 100 from 5637 available.\n",
      "- input: picked 100 from 475 available.\n",
      "- nand: picked 100 from 527 available.\n",
      "- nor: picked 100 from 567 available.\n",
      "- not: picked 100 from 4478 available.\n",
      "- or: picked 100 from 197 available.\n",
      "- output: picked 100 from 266 available.\n",
      "- xor: only 30 available, taking all.\n",
      "\n",
      "âœ… Accuracy on Perturbed Set: 68.22%\n",
      "Precision: 0.7162\n",
      "Recall:    0.6822\n",
      "F1 Score:  0.6323\n",
      "\n",
      "Confusion Matrix (Perturbed Set, all classes):\n",
      "[[ 99   0   0   1   0   0   0   0]\n",
      " [  0 100   0   0   0   0   0   0]\n",
      " [ 82   0   7  11   0   0   0   0]\n",
      " [ 37   0   1  62   0   0   0   0]\n",
      " [  0   0   0   0 100   0   0   0]\n",
      " [ 99   0   1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 100   0]\n",
      " [  0   0   0   0   0   0   0  30]]\n",
      "\n",
      "Classification Report (present classes only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         and       0.31      0.99      0.47       100\n",
      "       input       1.00      1.00      1.00       100\n",
      "        nand       0.78      0.07      0.13       100\n",
      "         nor       0.84      0.62      0.71       100\n",
      "         not       1.00      1.00      1.00       100\n",
      "          or       0.00      0.00      0.00       100\n",
      "      output       1.00      1.00      1.00       100\n",
      "         xor       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.68       730\n",
      "   macro avg       0.74      0.71      0.66       730\n",
      "weighted avg       0.72      0.68      0.63       730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Assumes:\n",
    "#  - `selected_test_nodes` already exists (from Hessian sampling step)\n",
    "#  - `graph`, `model`, `label_encoder` already defined\n",
    "#  - You may or may not have `jacobian_perturbations`; if absent, uses Gaussian noise\n",
    "# -------------------------------------------------\n",
    "\n",
    "# Ensure we have a NumPy array of node indices for the test set\n",
    "if torch.is_tensor(test_mask):\n",
    "    test_indices = test_mask.cpu().numpy()\n",
    "else:\n",
    "    test_indices = np.array(test_mask)\n",
    "\n",
    "labels_np = graph.ndata['labels'].cpu().numpy()\n",
    "class_names = list(label_encoder.classes_)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "rng = np.random.default_rng(seed=1)\n",
    "PER_CLASS = 100\n",
    "selected_test_nodes = []\n",
    "\n",
    "print(\"\\nSampling report:\")\n",
    "for c in range(num_classes):\n",
    "    idxs = [int(i) for i in test_indices if labels_np[int(i)] == c]\n",
    "    n_avail = len(idxs)\n",
    "\n",
    "    if n_avail == 0:\n",
    "        print(f\"- {class_names[c]}: 0 available in test set â€” skipped.\")\n",
    "        continue\n",
    "\n",
    "    if n_avail >= PER_CLASS:\n",
    "        chosen = rng.choice(idxs, size=PER_CLASS, replace=False)\n",
    "        print(f\"- {class_names[c]}: picked 100 from {n_avail} available.\")\n",
    "    else:\n",
    "        chosen = idxs\n",
    "        print(f\"- {class_names[c]}: only {n_avail} available, taking all.\")\n",
    "\n",
    "    selected_test_nodes.extend(chosen)\n",
    "\n",
    "selected_test_nodes = np.array(selected_test_nodes, dtype=np.int64)\n",
    "\n",
    "labels_np = graph.ndata['labels'].cpu().numpy()\n",
    "class_names = list(label_encoder.classes_)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Clone original features\n",
    "perturbed_features = graph.ndata['features'].clone().detach()\n",
    "\n",
    "epsilon = 0.05  # adjust perturbation strength if desired\n",
    "\n",
    "# Apply perturbations to exactly the selected nodes\n",
    "for node_idx in selected_test_nodes:\n",
    "    x0 = graph.ndata['features'][node_idx]\n",
    "\n",
    "    if 'jacobian_perturbations' in globals() and node_idx in jacobian_perturbations:\n",
    "        delta = jacobian_perturbations[node_idx]\n",
    "        norm = torch.norm(delta)\n",
    "        if norm.item() > 0:\n",
    "            delta = epsilon * delta / norm\n",
    "    else:\n",
    "        delta = epsilon * torch.randn_like(x0)\n",
    "\n",
    "    perturbed_features[node_idx] = (x0 + delta)\n",
    "\n",
    "# Evaluate only on perturbed subset\n",
    "eval_idx = torch.tensor(selected_test_nodes, dtype=torch.long)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_pert = model(graph, perturbed_features)\n",
    "    preds = logits_pert[eval_idx].argmax(dim=1).cpu().numpy()\n",
    "    labels_true = labels_np[eval_idx]\n",
    "\n",
    "# ---- Metrics ----\n",
    "acc = np.mean(preds == labels_true)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_true, preds, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\nâœ… Accuracy on Perturbed Set: {acc * 100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# Confusion matrix across all classes\n",
    "cm = confusion_matrix(labels_true, preds, labels=np.arange(num_classes))\n",
    "print(\"\\nConfusion Matrix (Perturbed Set, all classes):\")\n",
    "print(cm)\n",
    "\n",
    "# Report only for present classes to avoid mismatch\n",
    "present_labels = np.unique(labels_true)\n",
    "present_names = [class_names[i] for i in present_labels]\n",
    "print(\"\\nClassification Report (present classes only):\")\n",
    "print(classification_report(labels_true, preds,\n",
    "                            labels=present_labels,\n",
    "                            target_names=present_names,\n",
    "                            zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4debe1da",
   "metadata": {},
   "source": [
    "#### Prediction Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd7ab3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prediction Margin Computation (100 Samples Per Class) ---\n",
      "\n",
      "\n",
      "Class-wise Prediction Margin Results:\n",
      "Class                             Avg. Margin Â± Std\n",
      "---------------------------------------------------\n",
      "and                 3.4587 Â± 1.4896         \n",
      "or                  5.7445 Â± 0.8630         \n",
      "nand                1.2225 Â± 0.6649         \n",
      "nor                 1.4505 Â± 0.7046         \n",
      "xor                 4.8346 Â± 1.0507         \n",
      "xnor                2.0727 Â± 1.1462         \n",
      "buf                 6.7341 Â± 0.5587         \n",
      "not                 4.5673 Â± 0.4763         \n",
      "\n",
      "Overall Aggregated Prediction Margin:\n",
      "Average Margin: 3.6833 Â± 2.2053\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n--- Prediction Margin Computation (100 Samples Per Class) ---\\n\")\n",
    "\n",
    "# Define gate types corresponding to your labels.\n",
    "gate_types = ['and', 'or', 'nand', 'nor', 'xor', 'xnor', 'buf', 'not']\n",
    "\n",
    "# Dictionary to store prediction margins for each gate type.\n",
    "class_margin = {gt: [] for gt in gate_types}\n",
    "overall_margin = []\n",
    "\n",
    "# Iterate over each selected test node.\n",
    "for test_idx in selected_test_nodes:\n",
    "    # Obtain model output (logit vector) for the test sample.\n",
    "    with torch.no_grad():\n",
    "        logits = model(graph, graph.ndata['features'])[test_idx]  # f(x_i)\n",
    "    \n",
    "    # Predicted class: argmax_j f_j(x_i)\n",
    "    pred_class = int(torch.argmax(logits))\n",
    "    pred_logit = logits[pred_class].item()\n",
    "    \n",
    "    # Obtain the second highest value: set pred_class index to a very low number,\n",
    "    # then take the max of the rest.\n",
    "    other_logits = logits.clone()\n",
    "    other_logits[pred_class] = -float('inf')\n",
    "    second_max = other_logits.max().item()\n",
    "    \n",
    "    # Prediction margin: f_{y_pred}(x_i) - max_{j \\neq y_pred} f_j(x_i)\n",
    "    margin = pred_logit - second_max\n",
    "    \n",
    "    # Group the margin by the actual gate type label.\n",
    "    label_idx = graph.ndata['labels'][test_idx].item()\n",
    "    class_name = gate_types[label_idx]\n",
    "    class_margin[class_name].append(margin)\n",
    "    overall_margin.append(margin)\n",
    "\n",
    "# Display per-class results in a tabular format.\n",
    "print(\"\\nClass-wise Prediction Margin Results:\")\n",
    "header = \"{:<10s} {:>40s}\".format(\"Class\", \"Avg. Margin Â± Std\")\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "for cls in gate_types:\n",
    "    values = class_margin[cls]\n",
    "    if values:\n",
    "        avg_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "    else:\n",
    "        avg_val, std_val = 0, 0\n",
    "    print(\"{:<10s} {:>15.4f} Â± {:<15.4f}\".format(cls, avg_val, std_val))\n",
    "\n",
    "# Compute and display the overall aggregated prediction margin.\n",
    "overall_avg_margin = np.mean(overall_margin)\n",
    "overall_std_margin = np.std(overall_margin)\n",
    "print(\"\\nOverall Aggregated Prediction Margin:\")\n",
    "print(\"Average Margin: {:.4f} Â± {:.4f}\".format(overall_avg_margin, overall_std_margin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abe10da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prediction Margin & Relative Error Verification (100 Samples Per Class) ---\n",
      "\n",
      "\n",
      "Class-wise Prediction Margin (with Relative Error):\n",
      "Class                        Avg. Margin Â± Std           Avg Rel. Error Â± Std\n",
      "-----------------------------------------------------------------------------\n",
      "and               4.1818 Â± 1.0851          9.6553e-06 Â± 7.8073e-06\n",
      "input             6.8378 Â± 0.0000          1.1052e-06 Â± 9.5447e-07\n",
      "nand                   - -                        - -         \n",
      "nor                    - -                        - -         \n",
      "not               4.9227 Â± 0.6428          9.6125e-06 Â± 7.7242e-06\n",
      "or                     - -                        - -         \n",
      "output            6.4653 Â± 0.0005          1.6930e-06 Â± 1.4186e-06\n",
      "xor                    - -                        - -         \n",
      "\n",
      "Overall Aggregated Prediction Margin:\n",
      "Avg Margin: 4.6119 Â± 1.0198\n",
      "Avg Relative Error: 9.3943e-06 Â± 7.7819e-06\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n--- Prediction Margin & Relative Error Verification (100 Samples Per Class) ---\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Use consistent class names from label encoder\n",
    "# -----------------------------\n",
    "class_names = list(label_encoder.classes_)\n",
    "\n",
    "# Build selected_test_nodes: up to 100 random test nodes per class\n",
    "rng = np.random.default_rng(42)\n",
    "test_labels = graph.ndata['labels'][test_mask].cpu().numpy()\n",
    "test_indices = np.where(test_mask.cpu().numpy())[0]\n",
    "\n",
    "per_class_indices = {cls_idx: [] for cls_idx in range(len(class_names))}\n",
    "for idx, lbl in zip(test_indices, test_labels):\n",
    "    per_class_indices[lbl].append(idx)\n",
    "\n",
    "selected_test_nodes = []\n",
    "for cls_idx, idxs in per_class_indices.items():\n",
    "    if idxs:\n",
    "        k = min(100, len(idxs))\n",
    "        chosen = rng.choice(idxs, size=k, replace=False).tolist()\n",
    "        selected_test_nodes.extend(chosen)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Storage for metrics\n",
    "# -----------------------------\n",
    "class_margin_vals = {cn: [] for cn in class_names}\n",
    "class_rel_errors  = {cn: [] for cn in class_names}\n",
    "overall_margin_vals = []\n",
    "overall_rel_errors = []\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Main loop with relative error verification\n",
    "# -----------------------------\n",
    "epsilon = 1e-5   # perturbation for verification\n",
    "\n",
    "for test_idx in selected_test_nodes:\n",
    "    label_idx = int(graph.ndata['labels'][test_idx].item())\n",
    "    class_name = class_names[label_idx]\n",
    "\n",
    "    # Original logits\n",
    "    with torch.no_grad():\n",
    "        logits = model(graph, graph.ndata['features'])[test_idx]\n",
    "\n",
    "    pred_class = int(torch.argmax(logits))\n",
    "    pred_logit = logits[pred_class].item()\n",
    "\n",
    "    # Mask out predicted class to find second max\n",
    "    other_logits = logits.clone()\n",
    "    other_logits[pred_class] = -float('inf')\n",
    "    second_max = other_logits.max().item()\n",
    "\n",
    "    margin = pred_logit - second_max\n",
    "\n",
    "    # -----------------------------\n",
    "    # Relative error verification:\n",
    "    # Compare to recomputation after a small perturbation in features\n",
    "    # -----------------------------\n",
    "    # Perturb node features slightly\n",
    "    perturbed_feats = graph.ndata['features'].clone()\n",
    "    perturb_vec = torch.randn_like(perturbed_feats[test_idx]) * epsilon\n",
    "    perturbed_feats[test_idx] += perturb_vec\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits_pert = model(graph, perturbed_feats)[test_idx]\n",
    "    pred_logit_pert = logits_pert[pred_class].item()\n",
    "    other_logits_pert = logits_pert.clone()\n",
    "    other_logits_pert[pred_class] = -float('inf')\n",
    "    second_max_pert = other_logits_pert.max().item()\n",
    "    margin_pert = pred_logit_pert - second_max_pert\n",
    "\n",
    "    rel_err = abs(margin - margin_pert) / (abs(margin_pert) + 1e-12)\n",
    "\n",
    "    # Store\n",
    "    class_margin_vals[class_name].append(margin)\n",
    "    class_rel_errors[class_name].append(rel_err)\n",
    "    overall_margin_vals.append(margin)\n",
    "    overall_rel_errors.append(rel_err)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Reporting\n",
    "# -----------------------------\n",
    "print(\"\\nClass-wise Prediction Margin (with Relative Error):\")\n",
    "header = \"{:<12s} {:>33s} {:>30s}\".format(\"Class\", \"Avg. Margin Â± Std\", \"Avg Rel. Error Â± Std\")\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for cn in class_names:\n",
    "    m_vals = class_margin_vals[cn]\n",
    "    e_vals = class_rel_errors[cn]\n",
    "    if m_vals:\n",
    "        print(\"{:<12s} {:>11.4f} Â± {:<10.4f} {:>15.4e} Â± {:<10.4e}\".format(\n",
    "            cn, np.mean(m_vals), np.std(m_vals),\n",
    "            np.mean(e_vals), np.std(e_vals)\n",
    "        ))\n",
    "    else:\n",
    "        print(\"{:<12s} {:>11s} {:<10s} {:>15s} {:<10s}\".format(cn, \"-\", \"-\", \"-\", \"-\"))\n",
    "\n",
    "print(\"\\nOverall Aggregated Prediction Margin:\")\n",
    "print(\"Avg Margin: {:.4f} Â± {:.4f}\".format(np.mean(overall_margin_vals), np.std(overall_margin_vals)))\n",
    "print(\"Avg Relative Error: {:.4e} Â± {:.4e}\".format(np.mean(overall_rel_errors), np.std(overall_rel_errors)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2241a386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling report:\n",
      "- and: picked 100 from 5637 available.\n",
      "- input: picked 100 from 475 available.\n",
      "- nand: picked 100 from 527 available.\n",
      "- nor: picked 100 from 567 available.\n",
      "- not: picked 100 from 4478 available.\n",
      "- or: picked 100 from 197 available.\n",
      "- output: picked 100 from 266 available.\n",
      "- xor: only 30 available, taking all.\n",
      "\n",
      "âœ… Accuracy on Perturbed Set: 70.27%\n",
      "Precision: 0.7263\n",
      "Recall:    0.7027\n",
      "F1 Score:  0.6508\n",
      "\n",
      "Confusion Matrix (Perturbed Set, all classes):\n",
      "[[ 99   0   0   1   0   0   0   0]\n",
      " [  0  99   1   0   0   0   0   0]\n",
      " [ 82   0   8  10   0   0   0   0]\n",
      " [ 22   0   1  77   0   0   0   0]\n",
      " [  0   0   0   0 100   0   0   0]\n",
      " [100   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 100   0]\n",
      " [  0   0   0   0   0   0   0  30]]\n",
      "\n",
      "Classification Report (present classes only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         and       0.33      0.99      0.49       100\n",
      "       input       1.00      0.99      0.99       100\n",
      "        nand       0.80      0.08      0.15       100\n",
      "         nor       0.88      0.77      0.82       100\n",
      "         not       1.00      1.00      1.00       100\n",
      "          or       0.00      0.00      0.00       100\n",
      "      output       1.00      1.00      1.00       100\n",
      "         xor       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.70       730\n",
      "   macro avg       0.75      0.73      0.68       730\n",
      "weighted avg       0.73      0.70      0.65       730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Assumes:\n",
    "#  - `selected_test_nodes` already exists (from Prediction Margin sampling step)\n",
    "#  - `graph`, `model`, `label_encoder` already defined\n",
    "#  - Optionally: `jacobian_perturbations` dict for node_idx -> perturbation tensor\n",
    "# -------------------------------------------------\n",
    "\n",
    "# Ensure we have a NumPy array of node indices for the test set\n",
    "if torch.is_tensor(test_mask):\n",
    "    test_indices = test_mask.cpu().numpy()\n",
    "else:\n",
    "    test_indices = np.array(test_mask)\n",
    "\n",
    "labels_np = graph.ndata['labels'].cpu().numpy()\n",
    "class_names = list(label_encoder.classes_)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "rng = np.random.default_rng(seed=22)\n",
    "PER_CLASS = 100\n",
    "selected_test_nodes = []\n",
    "\n",
    "print(\"\\nSampling report:\")\n",
    "for c in range(num_classes):\n",
    "    idxs = [int(i) for i in test_indices if labels_np[int(i)] == c]\n",
    "    n_avail = len(idxs)\n",
    "\n",
    "    if n_avail == 0:\n",
    "        print(f\"- {class_names[c]}: 0 available in test set â€” skipped.\")\n",
    "        continue\n",
    "\n",
    "    if n_avail >= PER_CLASS:\n",
    "        chosen = rng.choice(idxs, size=PER_CLASS, replace=False)\n",
    "        print(f\"- {class_names[c]}: picked 100 from {n_avail} available.\")\n",
    "    else:\n",
    "        chosen = idxs\n",
    "        print(f\"- {class_names[c]}: only {n_avail} available, taking all.\")\n",
    "\n",
    "    selected_test_nodes.extend(chosen)\n",
    "\n",
    "selected_test_nodes = np.array(selected_test_nodes, dtype=np.int64)\n",
    "\n",
    "labels_np = graph.ndata['labels'].cpu().numpy()\n",
    "class_names = list(label_encoder.classes_)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Clone original features\n",
    "perturbed_features = graph.ndata['features'].clone().detach()\n",
    "\n",
    "epsilon = 0.05  # adjust perturbation strength if desired\n",
    "\n",
    "# Apply perturbations to exactly the selected nodes\n",
    "for node_idx in selected_test_nodes:\n",
    "    x0 = graph.ndata['features'][node_idx]\n",
    "\n",
    "    if 'jacobian_perturbations' in globals() and node_idx in jacobian_perturbations:\n",
    "        delta = jacobian_perturbations[node_idx]\n",
    "        norm = torch.norm(delta)\n",
    "        if norm.item() > 0:\n",
    "            delta = epsilon * delta / norm\n",
    "    else:\n",
    "        delta = epsilon * torch.randn_like(x0)\n",
    "\n",
    "    perturbed_features[node_idx] = (x0 + delta)\n",
    "\n",
    "# Evaluate only on perturbed subset\n",
    "eval_idx = torch.tensor(selected_test_nodes, dtype=torch.long)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_pert = model(graph, perturbed_features)\n",
    "    preds = logits_pert[eval_idx].argmax(dim=1).cpu().numpy()\n",
    "    labels_true = labels_np[eval_idx]\n",
    "\n",
    "# ---- Metrics ----\n",
    "acc = np.mean(preds == labels_true)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_true, preds, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\nâœ… Accuracy on Perturbed Set: {acc * 100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# Confusion matrix across all classes\n",
    "cm = confusion_matrix(labels_true, preds, labels=np.arange(num_classes))\n",
    "print(\"\\nConfusion Matrix (Perturbed Set, all classes):\")\n",
    "print(cm)\n",
    "\n",
    "# Report only for present classes to avoid mismatch\n",
    "present_labels = np.unique(labels_true)\n",
    "present_names = [class_names[i] for i in present_labels]\n",
    "print(\"\\nClassification Report (present classes only):\")\n",
    "print(classification_report(labels_true, preds,\n",
    "                            labels=present_labels,\n",
    "                            target_names=present_names,\n",
    "                            zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a96ce7",
   "metadata": {},
   "source": [
    "#### Adversarial Robustness Radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2175c8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Adversarial Robustness Radius Computation (100 Samples Per Class) ---\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_55232\\2544620608.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mclass_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgate_types\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mradius\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madversarial_radius_for_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[0mclass_adv_radius\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0moverall_adv_radius\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_55232\\2544620608.py\u001b[0m in \u001b[0;36madversarial_radius_for_sample\u001b[1;34m(test_idx, initial_epsilon, growth_factor, max_epsilon, bs_iters, num_trials)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m# Increase epsilon until the classification changes or max_epsilon is reached.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[1;32mwhile\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmax_epsilon\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_same\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[0mepsilon\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mgrowth_factor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_55232\\2544620608.py\u001b[0m in \u001b[0;36mis_same\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# Helper function: returns True if prediction at x remains unchanged.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mis_same\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_for_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_55232\\2544620608.py\u001b[0m in \u001b[0;36mf_for_sample\u001b[1;34m(x, test_idx)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mnew_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1518\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_55232\\3990547334.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, g, inputs)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1518\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\graphconv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mfeat_src\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_dst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpand_as_pair\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_norm\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'both'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m                 \u001b[0mdegs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_degrees\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_src\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_norm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'both'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m                     \u001b[0mnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dgl\\heterograph.py\u001b[0m in \u001b[0;36mout_degrees\u001b[1;34m(self, u, etype)\u001b[0m\n\u001b[0;32m   3509\u001b[0m             \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrcnodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrctype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3510\u001b[0m         \u001b[0mu_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'u'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3511\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrctype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3512\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mDGLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'u contains invalid node IDs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3513\u001b[0m         \u001b[0mdeg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_degrees\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'u'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dgl\\heterograph.py\u001b[0m in \u001b[0;36mhas_nodes\u001b[1;34m(self, vid, ntype)\u001b[0m\n\u001b[0;32m   2711\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvid_tensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvid_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvid_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2712\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mDGLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'All IDs must be non-negative integers.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2713\u001b[1;33m         ret = self._graph.has_nodes(\n\u001b[0m\u001b[0;32m   2714\u001b[0m             self.get_ntype_id(ntype), vid_tensor)\n\u001b[0;32m   2715\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dgl\\heterograph_index.py\u001b[0m in \u001b[0;36mhas_nodes\u001b[1;34m(self, ntype, vids)\u001b[0m\n\u001b[0;32m    406\u001b[0m             \u001b[1;36m0\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[0marray\u001b[0m \u001b[0mindicating\u001b[0m \u001b[0mexistence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m         \"\"\"\n\u001b[1;32m--> 408\u001b[1;33m         return F.from_dgl_nd(\n\u001b[0m\u001b[0;32m    409\u001b[0m             \u001b[0m_CAPI_DGLHeteroHasVertices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dgl_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m         )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dgl\\backend\\__init__.py\u001b[0m in \u001b[0;36mfrom_dgl_nd\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfrom_dgl_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mzerocopy_from_dgl_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dgl\\backend\\pytorch\\tensor.py\u001b[0m in \u001b[0;36mzerocopy_from_dgl_ndarray\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    468\u001b[0m         )\n\u001b[0;32m    469\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdlpack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dlpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dlpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dgl\\_ffi\\_ctypes\\ndarray.py\u001b[0m in \u001b[0;36mto_dlpack\u001b[1;34m(self, alignment)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         check_call(\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDGLArrayToDLPack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malignment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         )\n\u001b[0;32m    108\u001b[0m         return ctypes.pythonapi.PyCapsule_New(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n--- Adversarial Robustness Radius Computation (100 Samples Per Class) ---\\n\")\n",
    "\n",
    "# Dictionary to store the adversarial robustness radius for each gate type.\n",
    "class_adv_radius = {gt: [] for gt in gate_types}\n",
    "overall_adv_radius = []\n",
    "\n",
    "def f_for_sample(x, test_idx):\n",
    "    \"\"\"\n",
    "    Given an input x (modified feature vector for the test node),\n",
    "    returns the output (logit vector) for that node.\n",
    "    \"\"\"\n",
    "    new_features = graph.ndata['features'].clone().detach()\n",
    "    new_features[test_idx] = x\n",
    "    with torch.no_grad():\n",
    "        out = model(graph, new_features)\n",
    "    return out[test_idx]\n",
    "\n",
    "def adversarial_radius_for_sample(test_idx, initial_epsilon=1e-3, growth_factor=1.2, max_epsilon=10.0, bs_iters=10, num_trials=10):\n",
    "    \"\"\"\n",
    "    For a given test node (identified by test_idx), this function computes the smallest\n",
    "    perturbation norm (adversarial robustness radius) required to change the model's prediction.\n",
    "    We sample a number of random directions and, for each, increase the perturbation until\n",
    "    the predicted class changes; a binary search is then performed to refine the minimal epsilon.\n",
    "    The minimal epsilon over all trials is returned.\n",
    "    \"\"\"\n",
    "    # Retrieve the original feature vector.\n",
    "    x0 = graph.ndata['features'][test_idx].clone().detach()\n",
    "    \n",
    "    # Determine the predicted class at x0.\n",
    "    with torch.no_grad():\n",
    "        out = model(graph, graph.ndata['features'])\n",
    "        y0 = torch.argmax(out[test_idx]).item()\n",
    "        \n",
    "    # Helper function: returns True if prediction at x remains unchanged.\n",
    "    def is_same(x):\n",
    "        out = f_for_sample(x, test_idx)\n",
    "        return (torch.argmax(out).item() == y0)\n",
    "    \n",
    "    radii = []\n",
    "    for _ in range(num_trials):\n",
    "        # Sample a random direction.\n",
    "        d = torch.randn_like(x0)\n",
    "        d = d / (torch.norm(d) + 1e-8)\n",
    "        epsilon = initial_epsilon\n",
    "        \n",
    "        # Increase epsilon until the classification changes or max_epsilon is reached.\n",
    "        while epsilon < max_epsilon and is_same(x0 + epsilon * d):\n",
    "            epsilon *= growth_factor\n",
    "        \n",
    "        # If maximum epsilon is reached, use max_epsilon as candidate.\n",
    "        if epsilon >= max_epsilon:\n",
    "            candidate = max_epsilon\n",
    "        else:\n",
    "            # Refine the candidate using binary search between [epsilon/growth_factor, epsilon].\n",
    "            low = epsilon / growth_factor\n",
    "            high = epsilon\n",
    "            for _ in range(bs_iters):\n",
    "                mid = (low + high) / 2\n",
    "                if is_same(x0 + mid * d):\n",
    "                    low = mid\n",
    "                else:\n",
    "                    high = mid\n",
    "            candidate = high\n",
    "        radii.append(candidate)\n",
    "    \n",
    "    return min(radii)\n",
    "\n",
    "# Iterate over each selected test node (assumed 100 samples per class are in selected_test_nodes).\n",
    "for test_idx in selected_test_nodes:\n",
    "    label_idx = graph.ndata['labels'][test_idx].item()\n",
    "    class_name = gate_types[label_idx]\n",
    "    \n",
    "    radius = adversarial_radius_for_sample(test_idx)\n",
    "    class_adv_radius[class_name].append(radius)\n",
    "    overall_adv_radius.append(radius)\n",
    "\n",
    "# Display per-class results.\n",
    "print(\"\\nClass-wise Adversarial Robustness Radius Results:\")\n",
    "header = \"{:<10s} {:>35s}\".format(\"Class\", \"Avg. Radius Â± Std\")\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "for cls in gate_types:\n",
    "    values = class_adv_radius[cls]\n",
    "    if values:\n",
    "        avg_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "    else:\n",
    "        avg_val, std_val = 0, 0\n",
    "    print(\"{:<10s} {:>15.4f} Â± {:<15.4f}\".format(cls, avg_val, std_val))\n",
    "    \n",
    "# Compute overall aggregated results.\n",
    "overall_avg = np.mean(overall_adv_radius)\n",
    "overall_std = np.std(overall_adv_radius)\n",
    "print(\"\\nOverall Aggregated Adversarial Robustness Radius:\")\n",
    "print(\"Average Radius: {:.4f} Â± {:.4f}\".format(overall_avg, overall_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bea1d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Adversarial Robustness Radius & Relative Error Verification (100 Samples Per Class) ---\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13592\\4269683519.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[0mclass_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m     \u001b[0mradius\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrel_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madversarial_radius_relerr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[0mclass_adv_radius\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13592\\4269683519.py\u001b[0m in \u001b[0;36madversarial_radius_relerr\u001b[1;34m(test_idx)\u001b[0m\n\u001b[0;32m    101\u001b[0m     r1 = adversarial_radius_for_sample(test_idx, initial_epsilon=1e-3, growth_factor=1.2,\n\u001b[0;32m    102\u001b[0m                                        max_epsilon=10.0, bs_iters=10, num_trials=10)\n\u001b[1;32m--> 103\u001b[1;33m     r2 = adversarial_radius_for_sample(test_idx, initial_epsilon=1e-3, growth_factor=1.3,\n\u001b[0m\u001b[0;32m    104\u001b[0m                                        max_epsilon=10.0, bs_iters=12, num_trials=10)\n\u001b[0;32m    105\u001b[0m     \u001b[0mrel_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mr2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13592\\4269683519.py\u001b[0m in \u001b[0;36madversarial_radius_for_sample\u001b[1;34m(test_idx, initial_epsilon, growth_factor, max_epsilon, bs_iters, num_trials)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_epsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;31m# Expand until flip or cap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[1;32mwhile\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmax_epsilon\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_same\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             \u001b[0mepsilon\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mgrowth_factor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13592\\4269683519.py\u001b[0m in \u001b[0;36mis_same\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mis_same\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_for_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13592\\4269683519.py\u001b[0m in \u001b[0;36mf_for_sample\u001b[1;34m(x, test_idx)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mnew_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1518\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13592\\3990547334.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, g, inputs)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1517\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1518\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1520\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1525\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\graphconv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[0;32m    422\u001b[0m                 \u001b[1;31m# mult W first to reduce the feature size for aggregation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m                     \u001b[0mfeat_src\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_src\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m                 \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrcdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'h'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeat_src\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m                 \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maggregate_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'h'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n--- Adversarial Robustness Radius & Relative Error Verification (100 Samples Per Class) ---\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Use consistent class names from label encoder and sample nodes\n",
    "# -----------------------------\n",
    "class_names = list(label_encoder.classes_)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "test_labels = graph.ndata['labels'][test_mask].cpu().numpy()\n",
    "test_indices = np.where(test_mask.cpu().numpy())[0]\n",
    "\n",
    "per_class_indices = {cls_idx: [] for cls_idx in range(len(class_names))}\n",
    "for idx, lbl in zip(test_indices, test_labels):\n",
    "    per_class_indices[lbl].append(idx)\n",
    "\n",
    "selected_test_nodes = []\n",
    "for cls_idx, idxs in per_class_indices.items():\n",
    "    if idxs:\n",
    "        k = min(100, len(idxs))\n",
    "        chosen = rng.choice(idxs, size=k, replace=False).tolist()\n",
    "        selected_test_nodes.extend(chosen)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Storage\n",
    "# -----------------------------\n",
    "class_adv_radius = {cn: [] for cn in class_names}\n",
    "class_rel_errors  = {cn: [] for cn in class_names}\n",
    "overall_adv_radius_vals = []\n",
    "overall_rel_errors      = []\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Prediction wrapper for a node\n",
    "# -----------------------------\n",
    "def f_for_sample(x, test_idx):\n",
    "    \"\"\"\n",
    "    Given an input x (modified feature vector for the test node),\n",
    "    returns the output (logit vector) for that node.\n",
    "    \"\"\"\n",
    "    new_features = graph.ndata['features'].clone().detach()\n",
    "    new_features[test_idx] = x\n",
    "    with torch.no_grad():\n",
    "        out = model(graph, new_features)\n",
    "    return out[test_idx]\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Adversarial radius along random directions + binary search\n",
    "# -----------------------------\n",
    "def adversarial_radius_for_sample(test_idx, initial_epsilon=1e-3, growth_factor=1.2,\n",
    "                                  max_epsilon=10.0, bs_iters=10, num_trials=10):\n",
    "    \"\"\"\n",
    "    Compute the minimal perturbation norm required to change the prediction,\n",
    "    by sampling random directions d (||d||=1), expanding epsilon until flip,\n",
    "    then binary-searching within the bracket. Returns the minimum over trials.\n",
    "    \"\"\"\n",
    "    x0 = graph.ndata['features'][test_idx].clone().detach()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        base_out = model(graph, graph.ndata['features'])\n",
    "        y0 = int(torch.argmax(base_out[test_idx]).item())\n",
    "\n",
    "    def is_same(x):\n",
    "        out = f_for_sample(x, test_idx)\n",
    "        return int(torch.argmax(out).item()) == y0\n",
    "\n",
    "    radii = []\n",
    "    for _ in range(num_trials):\n",
    "        d = torch.randn_like(x0)\n",
    "        d = d / (torch.norm(d) + 1e-12)\n",
    "\n",
    "        epsilon = initial_epsilon\n",
    "        # Expand until flip or cap\n",
    "        while epsilon < max_epsilon and is_same(x0 + epsilon * d):\n",
    "            epsilon *= growth_factor\n",
    "\n",
    "        if epsilon >= max_epsilon:\n",
    "            candidate = max_epsilon\n",
    "        else:\n",
    "            # Binary search in [epsilon/growth_factor, epsilon]\n",
    "            low = epsilon / growth_factor\n",
    "            high = epsilon\n",
    "            for _ in range(bs_iters):\n",
    "                mid = 0.5 * (low + high)\n",
    "                if is_same(x0 + mid * d):\n",
    "                    low = mid\n",
    "                else:\n",
    "                    high = mid\n",
    "            candidate = high\n",
    "        radii.append(candidate)\n",
    "\n",
    "    return float(min(radii))\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Relative error verification\n",
    "# -----------------------------\n",
    "# We verify by re-estimating the radius with a different randomness seed/config\n",
    "# and measuring |r - r'| / (r' + 1e-12). This checks stability of the estimator.\n",
    "def adversarial_radius_relerr(test_idx):\n",
    "    r1 = adversarial_radius_for_sample(test_idx, initial_epsilon=1e-3, growth_factor=1.2,\n",
    "                                       max_epsilon=10.0, bs_iters=10, num_trials=10)\n",
    "    r2 = adversarial_radius_for_sample(test_idx, initial_epsilon=1e-3, growth_factor=1.3,\n",
    "                                       max_epsilon=10.0, bs_iters=12, num_trials=10)\n",
    "    rel_err = abs(r1 - r2) / (abs(r2) + 1e-12)\n",
    "    return r1, rel_err\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Main loop\n",
    "# -----------------------------\n",
    "for test_idx in selected_test_nodes:\n",
    "    label_idx = int(graph.ndata['labels'][test_idx].item())\n",
    "    class_name = class_names[label_idx]\n",
    "\n",
    "    radius, rel_err = adversarial_radius_relerr(test_idx)\n",
    "\n",
    "    class_adv_radius[class_name].append(radius)\n",
    "    class_rel_errors[class_name].append(rel_err)\n",
    "    overall_adv_radius_vals.append(radius)\n",
    "    overall_rel_errors.append(rel_err)\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Reporting\n",
    "# -----------------------------\n",
    "print(\"\\nClass-wise Adversarial Robustness Radius (with Relative Error):\")\n",
    "header = \"{:<12s} {:>27s} {:>30s}\".format(\"Class\", \"Avg. Radius Â± Std\", \"Avg Rel. Error Â± Std\")\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for cn in class_names:\n",
    "    r_vals = class_adv_radius[cn]\n",
    "    e_vals = class_rel_errors[cn]\n",
    "    if r_vals:\n",
    "        print(\"{:<12s} {:>11.4f} Â± {:<10.4f} {:>15.4e} Â± {:<10.4e}\".format(\n",
    "            cn, np.mean(r_vals), np.std(r_vals), np.mean(e_vals), np.std(e_vals)\n",
    "        ))\n",
    "    else:\n",
    "        print(\"{:<12s} {:>11s} {:<10s} {:>15s} {:<10s}\".format(cn, \"-\", \"-\", \"-\", \"-\"))\n",
    "\n",
    "print(\"\\nOverall Aggregated Adversarial Robustness Radius:\")\n",
    "print(\"Avg Radius: {:.4f} Â± {:.4f}\".format(np.mean(overall_adv_radius_vals), np.std(overall_adv_radius_vals)))\n",
    "print(\"Avg Relative Error: {:.4e} Â± {:.4e}\".format(np.mean(overall_rel_errors), np.std(overall_rel_errors)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9226032d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling report:\n",
      "- and: picked 100 from 5637 available.\n",
      "- input: picked 100 from 475 available.\n",
      "- nand: picked 100 from 527 available.\n",
      "- nor: picked 100 from 567 available.\n",
      "- not: picked 100 from 4478 available.\n",
      "- or: picked 100 from 197 available.\n",
      "- output: picked 100 from 266 available.\n",
      "- xor: only 30 available, taking all.\n",
      "\n",
      "âœ… Accuracy on Perturbed Set: 70.14%\n",
      "Precision: 0.6945\n",
      "Recall:    0.7014\n",
      "F1 Score:  0.6452\n",
      "\n",
      "Confusion Matrix (Perturbed Set, all classes):\n",
      "[[100   0   0   0   0   0   0   0]\n",
      " [  0 100   0   0   0   0   0   0]\n",
      " [ 85   0   5  10   0   0   0   0]\n",
      " [ 22   0   1  77   0   0   0   0]\n",
      " [  0   0   0   0 100   0   0   0]\n",
      " [ 97   0   3   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 100   0]\n",
      " [  0   0   0   0   0   0   0  30]]\n",
      "\n",
      "Classification Report (present classes only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         and       0.33      1.00      0.50       100\n",
      "       input       1.00      1.00      1.00       100\n",
      "        nand       0.56      0.05      0.09       100\n",
      "         nor       0.89      0.77      0.82       100\n",
      "         not       1.00      1.00      1.00       100\n",
      "          or       0.00      0.00      0.00       100\n",
      "      output       1.00      1.00      1.00       100\n",
      "         xor       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.70       730\n",
      "   macro avg       0.72      0.73      0.68       730\n",
      "weighted avg       0.69      0.70      0.65       730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Assumes:\n",
    "#  - `selected_test_nodes` already exists (from ARR sampling step)\n",
    "#  - `graph`, `model`, `label_encoder` already defined\n",
    "#  - Optionally: `jacobian_perturbations` dict for node_idx -> perturbation tensor\n",
    "# -------------------------------------------------\n",
    "\n",
    "# Ensure we have a NumPy array of node indices for the test set\n",
    "if torch.is_tensor(test_mask):\n",
    "    test_indices = test_mask.cpu().numpy()\n",
    "else:\n",
    "    test_indices = np.array(test_mask)\n",
    "\n",
    "labels_np = graph.ndata['labels'].cpu().numpy()\n",
    "class_names = list(label_encoder.classes_)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "rng = np.random.default_rng(seed=18)\n",
    "PER_CLASS = 100\n",
    "selected_test_nodes = []\n",
    "\n",
    "print(\"\\nSampling report:\")\n",
    "for c in range(num_classes):\n",
    "    idxs = [int(i) for i in test_indices if labels_np[int(i)] == c]\n",
    "    n_avail = len(idxs)\n",
    "\n",
    "    if n_avail == 0:\n",
    "        print(f\"- {class_names[c]}: 0 available in test set â€” skipped.\")\n",
    "        continue\n",
    "\n",
    "    if n_avail >= PER_CLASS:\n",
    "        chosen = rng.choice(idxs, size=PER_CLASS, replace=False)\n",
    "        print(f\"- {class_names[c]}: picked 100 from {n_avail} available.\")\n",
    "    else:\n",
    "        chosen = idxs\n",
    "        print(f\"- {class_names[c]}: only {n_avail} available, taking all.\")\n",
    "\n",
    "    selected_test_nodes.extend(chosen)\n",
    "\n",
    "selected_test_nodes = np.array(selected_test_nodes, dtype=np.int64)\n",
    "\n",
    "labels_np = graph.ndata['labels'].cpu().numpy()\n",
    "class_names = list(label_encoder.classes_)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Clone original features\n",
    "perturbed_features = graph.ndata['features'].clone().detach()\n",
    "\n",
    "epsilon = 0.05  # adjust perturbation strength if desired\n",
    "\n",
    "# Apply perturbations to exactly the selected nodes\n",
    "for node_idx in selected_test_nodes:\n",
    "    x0 = graph.ndata['features'][node_idx]\n",
    "\n",
    "    if 'jacobian_perturbations' in globals() and node_idx in jacobian_perturbations:\n",
    "        delta = jacobian_perturbations[node_idx]\n",
    "        norm = torch.norm(delta)\n",
    "        if norm.item() > 0:\n",
    "            delta = epsilon * delta / norm\n",
    "    else:\n",
    "        delta = epsilon * torch.randn_like(x0)\n",
    "\n",
    "    perturbed_features[node_idx] = (x0 + delta)\n",
    "\n",
    "# Evaluate only on perturbed subset\n",
    "eval_idx = torch.tensor(selected_test_nodes, dtype=torch.long)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_pert = model(graph, perturbed_features)\n",
    "    preds = logits_pert[eval_idx].argmax(dim=1).cpu().numpy()\n",
    "    labels_true = labels_np[eval_idx]\n",
    "\n",
    "# ---- Metrics ----\n",
    "acc = np.mean(preds == labels_true)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_true, preds, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\nâœ… Accuracy on Perturbed Set: {acc * 100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# Confusion matrix across all classes\n",
    "cm = confusion_matrix(labels_true, preds, labels=np.arange(num_classes))\n",
    "print(\"\\nConfusion Matrix (Perturbed Set, all classes):\")\n",
    "print(cm)\n",
    "\n",
    "# Report only for present classes to avoid mismatch\n",
    "present_labels = np.unique(labels_true)\n",
    "present_names = [class_names[i] for i in present_labels]\n",
    "print(\"\\nClassification Report (present classes only):\")\n",
    "print(classification_report(labels_true, preds,\n",
    "                            labels=present_labels,\n",
    "                            target_names=present_names,\n",
    "                            zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00574a57",
   "metadata": {},
   "source": [
    "#### Stability Under Input Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "351dab58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Stability Under Input Noise Computation (100 Samples Per Class) ---\n",
      "\n",
      "\n",
      "Class-wise Stability Under Input Noise Results:\n",
      "Class                   Avg. Stability (S(x)) Â± Std\n",
      "---------------------------------------------------\n",
      "and                 0.0692 Â± 0.0177         \n",
      "or                  0.0458 Â± 0.0049         \n",
      "nand                0.0597 Â± 0.0185         \n",
      "nor                 0.0458 Â± 0.0103         \n",
      "xor                 0.0810 Â± 0.0126         \n",
      "xnor                0.0535 Â± 0.0224         \n",
      "buf                 0.0383 Â± 0.0040         \n",
      "not                 0.0270 Â± 0.0030         \n",
      "\n",
      "Overall Aggregated Stability Under Input Noise:\n",
      "Average Stability: 0.0550 Â± 0.0204\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n--- Stability Under Input Noise Computation (100 Samples Per Class) ---\\n\")\n",
    "\n",
    "# Standard deviation for Gaussian noise perturbations.\n",
    "sigma = 0.01\n",
    "\n",
    "# Number of noise samples to approximate the expectation.\n",
    "num_noise_samples = 20\n",
    "\n",
    "# Define gate types corresponding to your labels.\n",
    "gate_types = ['and', 'or', 'nand', 'nor', 'xor', 'xnor', 'buf', 'not']\n",
    "\n",
    "# Dictionaries to store stability metric per gate type and overall.\n",
    "class_stability = {gt: [] for gt in gate_types}\n",
    "overall_stability = []\n",
    "\n",
    "def stability_for_sample(test_idx, sigma, num_samples):\n",
    "    \"\"\"\n",
    "    Compute the stability under input noise for a given test sample.\n",
    "    For the sample at test_idx, the prediction difference is computed as the Euclidean norm \n",
    "    between the model outputs for the original and the noisy inputs. The stability measure \n",
    "    S(x_i) is obtained by averaging over multiple noise samples.\n",
    "    \"\"\"\n",
    "    # Retrieve the original feature vector.\n",
    "    x0 = graph.ndata['features'][test_idx].clone().detach()\n",
    "    \n",
    "    # Compute the model output for the unperturbed input.\n",
    "    with torch.no_grad():\n",
    "        f_orig = model(graph, graph.ndata['features'])[test_idx]\n",
    "    \n",
    "    differences = []\n",
    "    for _ in range(num_samples):\n",
    "        # Sample noise from a Gaussian distribution: N(0, sigma^2 I)\n",
    "        noise = sigma * torch.randn_like(x0)\n",
    "        x_noisy = x0 + noise\n",
    "        \n",
    "        # Replace the test node's feature with the noisy feature.\n",
    "        new_features = graph.ndata['features'].clone().detach()\n",
    "        new_features[test_idx] = x_noisy\n",
    "        \n",
    "        # Compute the model's output for the noisy input.\n",
    "        with torch.no_grad():\n",
    "            f_noisy = model(graph, new_features)[test_idx]\n",
    "        \n",
    "        # Calculate the Euclidean norm difference between the noisy and original outputs.\n",
    "        diff = torch.norm(f_noisy - f_orig).item()\n",
    "        differences.append(diff)\n",
    "    \n",
    "    # Average difference approximates the expectation.\n",
    "    return np.mean(differences)\n",
    "\n",
    "# Iterate over each selected test node (assumed to be 100 samples per class in selected_test_nodes).\n",
    "for test_idx in selected_test_nodes:\n",
    "    label_idx = graph.ndata['labels'][test_idx].item()\n",
    "    class_name = gate_types[label_idx]\n",
    "    \n",
    "    stability_measure = stability_for_sample(test_idx, sigma, num_noise_samples)\n",
    "    class_stability[class_name].append(stability_measure)\n",
    "    overall_stability.append(stability_measure)\n",
    "\n",
    "# Display per-class results.\n",
    "print(\"\\nClass-wise Stability Under Input Noise Results:\")\n",
    "header = \"{:<10s} {:>40s}\".format(\"Class\", \"Avg. Stability (S(x)) Â± Std\")\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "for cls in gate_types:\n",
    "    values = class_stability[cls]\n",
    "    if values:\n",
    "        avg_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "    else:\n",
    "        avg_val, std_val = 0, 0\n",
    "    print(\"{:<10s} {:>15.4f} Â± {:<15.4f}\".format(cls, avg_val, std_val))\n",
    "    \n",
    "overall_avg = np.mean(overall_stability)\n",
    "overall_std = np.std(overall_stability)\n",
    "print(\"\\nOverall Aggregated Stability Under Input Noise:\")\n",
    "print(\"Average Stability: {:.4f} Â± {:.4f}\".format(overall_avg, overall_std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc9a82ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Stability Under Input Noise & Relative Error Verification (100 Samples Per Class) ---\n",
      "\n",
      "\n",
      "Class-wise Stability Under Input Noise (with Relative Error):\n",
      "Class                     Avg. Stability Â± Std           Avg Rel. Error Â± Std\n",
      "-----------------------------------------------------------------------------\n",
      "and               0.0724 Â± 0.0122          9.1036e-02 Â± 6.9657e-02\n",
      "input             0.0531 Â± 0.0074          1.3913e-01 Â± 1.1634e-01\n",
      "nand                   - -                        - -         \n",
      "nor                    - -                        - -         \n",
      "not               0.0790 Â± 0.0106          8.5734e-02 Â± 5.9886e-02\n",
      "or                     - -                        - -         \n",
      "output            0.0440 Â± 0.0045          8.4250e-02 Â± 6.5533e-02\n",
      "xor                    - -                        - -         \n",
      "\n",
      "Overall Aggregated Stability Under Input Noise:\n",
      "Avg Stability: 0.0749 Â± 0.0125\n",
      "Avg Relative Error: 8.9337e-02 Â± 6.6771e-02\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n--- Stability Under Input Noise & Relative Error Verification (100 Samples Per Class) ---\\n\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Use consistent class names from label encoder\n",
    "# -----------------------------\n",
    "class_names = list(label_encoder.classes_)\n",
    "\n",
    "# Build selected_test_nodes: up to 100 random test nodes per class\n",
    "rng = np.random.default_rng(42)\n",
    "test_labels = graph.ndata['labels'][test_mask].cpu().numpy()\n",
    "test_indices = np.where(test_mask.cpu().numpy())[0]\n",
    "\n",
    "per_class_indices = {cls_idx: [] for cls_idx in range(len(class_names))}\n",
    "for idx, lbl in zip(test_indices, test_labels):\n",
    "    per_class_indices[lbl].append(idx)\n",
    "\n",
    "selected_test_nodes = []\n",
    "for cls_idx, idxs in per_class_indices.items():\n",
    "    if idxs:\n",
    "        k = min(100, len(idxs))\n",
    "        chosen = rng.choice(idxs, size=k, replace=False).tolist()\n",
    "        selected_test_nodes.extend(chosen)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Parameters\n",
    "# -----------------------------\n",
    "sigma = 0.01          # stddev of Gaussian noise\n",
    "num_noise_samples = 20\n",
    "relerr_resamples  = 5 # verification repetitions\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Storage\n",
    "# -----------------------------\n",
    "class_stability   = {cn: [] for cn in class_names}\n",
    "class_rel_errors  = {cn: [] for cn in class_names}\n",
    "overall_stability_vals = []\n",
    "overall_rel_errors     = []\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Helpers\n",
    "# -----------------------------\n",
    "def stability_for_sample(test_idx, sigma, num_samples):\n",
    "    \"\"\"\n",
    "    Compute stability under Gaussian noise: average L2 change in logits\n",
    "    between clean and noisy versions of the given test node.\n",
    "    \"\"\"\n",
    "    x0 = graph.ndata['features'][test_idx].clone().detach()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        f_orig = model(graph, graph.ndata['features'])[test_idx]\n",
    "\n",
    "    diffs = []\n",
    "    for _ in range(num_samples):\n",
    "        noise = sigma * torch.randn_like(x0)\n",
    "        x_noisy = x0 + noise\n",
    "\n",
    "        new_feats = graph.ndata['features'].clone().detach()\n",
    "        new_feats[test_idx] = x_noisy\n",
    "\n",
    "        with torch.no_grad():\n",
    "            f_noisy = model(graph, new_feats)[test_idx]\n",
    "\n",
    "        diffs.append(torch.norm(f_noisy - f_orig).item())\n",
    "\n",
    "    return float(np.mean(diffs))\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Main loop\n",
    "# -----------------------------\n",
    "for test_idx in selected_test_nodes:\n",
    "    label_idx = int(graph.ndata['labels'][test_idx].item())\n",
    "    class_name = class_names[label_idx]\n",
    "\n",
    "    stab_val = stability_for_sample(test_idx, sigma, num_noise_samples)\n",
    "\n",
    "    # Relative error check: reâ€‘estimate stability with fresh noise and compare\n",
    "    re_vals = [stability_for_sample(test_idx, sigma, num_noise_samples)\n",
    "               for _ in range(relerr_resamples)]\n",
    "    avg_reval = float(np.mean(re_vals))\n",
    "    rel_err = abs(stab_val - avg_reval) / (abs(avg_reval) + 1e-12)\n",
    "\n",
    "    class_stability[class_name].append(stab_val)\n",
    "    class_rel_errors[class_name].append(rel_err)\n",
    "    overall_stability_vals.append(stab_val)\n",
    "    overall_rel_errors.append(rel_err)\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Reporting\n",
    "# -----------------------------\n",
    "print(\"\\nClass-wise Stability Under Input Noise (with Relative Error):\")\n",
    "header = \"{:<12s} {:>33s} {:>30s}\".format(\"Class\", \"Avg. Stability Â± Std\", \"Avg Rel. Error Â± Std\")\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for cn in class_names:\n",
    "    s_vals = class_stability[cn]\n",
    "    e_vals = class_rel_errors[cn]\n",
    "    if s_vals:\n",
    "        print(\"{:<12s} {:>11.4f} Â± {:<10.4f} {:>15.4e} Â± {:<10.4e}\".format(\n",
    "            cn, np.mean(s_vals), np.std(s_vals),\n",
    "            np.mean(e_vals), np.std(e_vals)\n",
    "        ))\n",
    "    else:\n",
    "        print(\"{:<12s} {:>11s} {:<10s} {:>15s} {:<10s}\".format(cn, \"-\", \"-\", \"-\", \"-\"))\n",
    "\n",
    "print(\"\\nOverall Aggregated Stability Under Input Noise:\")\n",
    "print(\"Avg Stability: {:.4f} Â± {:.4f}\".format(np.mean(overall_stability_vals), np.std(overall_stability_vals)))\n",
    "print(\"Avg Relative Error: {:.4e} Â± {:.4e}\".format(np.mean(overall_rel_errors), np.std(overall_rel_errors)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7d7d9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling report:\n",
      "- and: picked 100 from 5637 available.\n",
      "- input: picked 100 from 475 available.\n",
      "- nand: picked 100 from 527 available.\n",
      "- nor: picked 100 from 567 available.\n",
      "- not: picked 100 from 4478 available.\n",
      "- or: picked 100 from 197 available.\n",
      "- output: picked 100 from 266 available.\n",
      "- xor: only 30 available, taking all.\n",
      "\n",
      "âœ… Accuracy on Perturbed Set: 69.59%\n",
      "Precision: 0.7203\n",
      "Recall:    0.6959\n",
      "F1 Score:  0.6431\n",
      "\n",
      "Confusion Matrix (Perturbed Set, all classes):\n",
      "[[100   0   0   0   0   0   0   0]\n",
      " [  0 100   0   0   0   0   0   0]\n",
      " [ 81   0   7  12   0   0   0   0]\n",
      " [ 29   0   0  71   0   0   0   0]\n",
      " [  0   0   0   0 100   0   0   0]\n",
      " [ 98   0   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 100   0]\n",
      " [  0   0   0   0   0   0   0  30]]\n",
      "\n",
      "Classification Report (present classes only):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         and       0.32      1.00      0.49       100\n",
      "       input       1.00      1.00      1.00       100\n",
      "        nand       0.78      0.07      0.13       100\n",
      "         nor       0.86      0.71      0.78       100\n",
      "         not       1.00      1.00      1.00       100\n",
      "          or       0.00      0.00      0.00       100\n",
      "      output       1.00      1.00      1.00       100\n",
      "         xor       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.70       730\n",
      "   macro avg       0.74      0.72      0.67       730\n",
      "weighted avg       0.72      0.70      0.64       730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Assumes:\n",
    "#  - `selected_test_nodes` already exists (from Stability sampling step)\n",
    "#  - `graph`, `model`, `label_encoder` already defined\n",
    "#  - Optionally: `jacobian_perturbations` dict for node_idx -> perturbation tensor\n",
    "# -------------------------------------------------\n",
    "\n",
    "# Ensure we have a NumPy array of node indices for the test set\n",
    "if torch.is_tensor(test_mask):\n",
    "    test_indices = test_mask.cpu().numpy()\n",
    "else:\n",
    "    test_indices = np.array(test_mask)\n",
    "\n",
    "labels_np = graph.ndata['labels'].cpu().numpy()\n",
    "class_names = list(label_encoder.classes_)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "rng = np.random.default_rng(seed=50)\n",
    "PER_CLASS = 100\n",
    "selected_test_nodes = []\n",
    "\n",
    "print(\"\\nSampling report:\")\n",
    "for c in range(num_classes):\n",
    "    idxs = [int(i) for i in test_indices if labels_np[int(i)] == c]\n",
    "    n_avail = len(idxs)\n",
    "\n",
    "    if n_avail == 0:\n",
    "        print(f\"- {class_names[c]}: 0 available in test set â€” skipped.\")\n",
    "        continue\n",
    "\n",
    "    if n_avail >= PER_CLASS:\n",
    "        chosen = rng.choice(idxs, size=PER_CLASS, replace=False)\n",
    "        print(f\"- {class_names[c]}: picked 100 from {n_avail} available.\")\n",
    "    else:\n",
    "        chosen = idxs\n",
    "        print(f\"- {class_names[c]}: only {n_avail} available, taking all.\")\n",
    "\n",
    "    selected_test_nodes.extend(chosen)\n",
    "\n",
    "selected_test_nodes = np.array(selected_test_nodes, dtype=np.int64)\n",
    "\n",
    "labels_np = graph.ndata['labels'].cpu().numpy()\n",
    "class_names = list(label_encoder.classes_)\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Clone original features\n",
    "perturbed_features = graph.ndata['features'].clone().detach()\n",
    "\n",
    "epsilon = 0.05  # adjust perturbation strength if desired\n",
    "\n",
    "# Apply perturbations to exactly the selected nodes\n",
    "for node_idx in selected_test_nodes:\n",
    "    x0 = graph.ndata['features'][node_idx]\n",
    "\n",
    "    if 'jacobian_perturbations' in globals() and node_idx in jacobian_perturbations:\n",
    "        delta = jacobian_perturbations[node_idx]\n",
    "        norm = torch.norm(delta)\n",
    "        if norm.item() > 0:\n",
    "            delta = epsilon * delta / norm\n",
    "    else:\n",
    "        delta = epsilon * torch.randn_like(x0)\n",
    "\n",
    "    perturbed_features[node_idx] = (x0 + delta)\n",
    "\n",
    "# Evaluate only on perturbed subset\n",
    "eval_idx = torch.tensor(selected_test_nodes, dtype=torch.long)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_pert = model(graph, perturbed_features)\n",
    "    preds = logits_pert[eval_idx].argmax(dim=1).cpu().numpy()\n",
    "    labels_true = labels_np[eval_idx]\n",
    "\n",
    "# ---- Metrics ----\n",
    "acc = np.mean(preds == labels_true)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_true, preds, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"\\nâœ… Accuracy on Perturbed Set: {acc * 100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# Confusion matrix across all classes\n",
    "cm = confusion_matrix(labels_true, preds, labels=np.arange(num_classes))\n",
    "print(\"\\nConfusion Matrix (Perturbed Set, all classes):\")\n",
    "print(cm)\n",
    "\n",
    "# Report only for present classes to avoid mismatch\n",
    "present_labels = np.unique(labels_true)\n",
    "present_names = [class_names[i] for i in present_labels]\n",
    "print(\"\\nClassification Report (present classes only):\")\n",
    "print(classification_report(labels_true, preds,\n",
    "                            labels=present_labels,\n",
    "                            target_names=present_names,\n",
    "                            zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09891bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
