{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6caf6b8f-50f8-475a-9da8-142ac5ead8a8",
   "metadata": {},
   "source": [
    "#### Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbf1215c-0a9e-4619-a418-218eb6db72c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss 0.8937 | Val 0.4607 | Test 0.4631\n",
      "Epoch 010 | Loss 0.6116 | Val 0.9505 | Test 0.9496\n",
      "Epoch 020 | Loss 0.4193 | Val 0.9883 | Test 0.9885\n",
      "Epoch 030 | Loss 0.2920 | Val 0.9927 | Test 0.9931\n",
      "Epoch 040 | Loss 0.2113 | Val 0.9981 | Test 0.9981\n",
      "Epoch 050 | Loss 0.1559 | Val 0.9994 | Test 0.9995\n",
      "Epoch 060 | Loss 0.1176 | Val 0.9999 | Test 0.9998\n",
      "Epoch 070 | Loss 0.0936 | Val 0.9999 | Test 0.9998\n",
      "Epoch 080 | Loss 0.0779 | Val 1.0000 | Test 1.0000\n",
      "Epoch 090 | Loss 0.0668 | Val 1.0000 | Test 1.0000\n",
      "Epoch 100 | Loss 0.0553 | Val 1.0000 | Test 1.0000\n",
      "Epoch 110 | Loss 0.0494 | Val 1.0000 | Test 1.0000\n",
      "Epoch 120 | Loss 0.0435 | Val 1.0000 | Test 1.0000\n",
      "Epoch 130 | Loss 0.0407 | Val 1.0000 | Test 1.0000\n",
      "Epoch 140 | Loss 0.0371 | Val 1.0000 | Test 1.0000\n",
      "Epoch 150 | Loss 0.0346 | Val 1.0000 | Test 1.0000\n",
      "Epoch 160 | Loss 0.0329 | Val 1.0000 | Test 1.0000\n",
      "Epoch 170 | Loss 0.0301 | Val 1.0000 | Test 1.0000\n",
      "Epoch 180 | Loss 0.0283 | Val 1.0000 | Test 1.0000\n",
      "Epoch 190 | Loss 0.0273 | Val 1.0000 | Test 1.0000\n",
      "Epoch 200 | Loss 0.0266 | Val 1.0000 | Test 1.0000\n",
      "Epoch 210 | Loss 0.0253 | Val 1.0000 | Test 1.0000\n",
      "Epoch 220 | Loss 0.0241 | Val 1.0000 | Test 1.0000\n",
      "Epoch 230 | Loss 0.0239 | Val 1.0000 | Test 1.0000\n",
      "Epoch 240 | Loss 0.0230 | Val 1.0000 | Test 1.0000\n",
      "Epoch 250 | Loss 0.0210 | Val 1.0000 | Test 1.0000\n",
      "Epoch 260 | Loss 0.0215 | Val 1.0000 | Test 1.0000\n",
      "Epoch 270 | Loss 0.0197 | Val 1.0000 | Test 1.0000\n",
      "Epoch 280 | Loss 0.0196 | Val 1.0000 | Test 1.0000\n",
      "Early stopping.\n",
      "\n",
      "Final Evaluation (Node-Level)\n",
      "=============================\n",
      "Test Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     1.0000    1.0000    1.0000      9159\n",
      "      trojan     1.0000    1.0000    1.0000     27556\n",
      "\n",
      "    accuracy                         1.0000     36715\n",
      "   macro avg     1.0000    1.0000    1.0000     36715\n",
      "weighted avg     1.0000    1.0000    1.0000     36715\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9159     0]\n",
      " [    0 27556]]\n"
     ]
    }
   ],
   "source": [
    "# train_gcn_node_fixed.py\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "NODE_CSV  = \"GNNDatasets/node.csv\"\n",
    "EDGE_CSV  = \"GNNDatasets/node_edges.csv\"\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# ----------------------------- Load nodes -----------------------------\n",
    "nodes_df = pd.read_csv(NODE_CSV)\n",
    "\n",
    "label_col = None\n",
    "for cand in [\"label\", \"is_trojan\", \"trojan\", \"target\"]:\n",
    "    if cand in nodes_df.columns:\n",
    "        label_col = cand; break\n",
    "if label_col is None:\n",
    "    nodes_df[\"label\"] = nodes_df[\"circuit_name\"].astype(str).str.contains(\"__trojan_\").astype(int)\n",
    "    label_col = \"label\"\n",
    "\n",
    "nodes_df[\"uid\"] = nodes_df[\"circuit_name\"].astype(str) + \"::\" + nodes_df[\"node\"].astype(str)\n",
    "\n",
    "feat_df = nodes_df.copy()\n",
    "if \"gate_type\" in feat_df.columns:\n",
    "    gate_oh = pd.get_dummies(feat_df[\"gate_type\"], prefix=\"gt\")\n",
    "    feat_df = pd.concat([feat_df.drop(columns=[\"gate_type\"]), gate_oh], axis=1)\n",
    "\n",
    "exclude = {\"uid\",\"node\",\"circuit_name\",label_col}\n",
    "num_cols = [c for c in feat_df.columns if c not in exclude and pd.api.types.is_numeric_dtype(feat_df[c])]\n",
    "X = feat_df[num_cols].fillna(0.0).values.astype(np.float32)\n",
    "y = nodes_df[label_col].values.astype(np.int64)\n",
    "\n",
    "# ----------------------------- Load edges; add missing nodes -----------------------------\n",
    "edges_df = pd.read_csv(EDGE_CSV)\n",
    "edges_df[\"src_uid\"] = edges_df[\"circuit_name\"].astype(str) + \"::\" + edges_df[\"src\"].astype(str)\n",
    "edges_df[\"dst_uid\"] = edges_df[\"circuit_name\"].astype(str) + \"::\" + edges_df[\"dst\"].astype(str)\n",
    "\n",
    "known_uids = set(nodes_df[\"uid\"])\n",
    "edge_uids = set(edges_df[\"src_uid\"]).union(set(edges_df[\"dst_uid\"]))\n",
    "missing = list(edge_uids - known_uids)\n",
    "\n",
    "if missing:\n",
    "    zero_row = np.zeros((1, X.shape[1]), dtype=np.float32)\n",
    "    addX = np.repeat(zero_row, len(missing), axis=0)\n",
    "    addY = -1*np.ones(len(missing), dtype=np.int64)\n",
    "    add_df = pd.DataFrame({\n",
    "        \"uid\": missing,\n",
    "        \"circuit_name\": [u.split(\"::\",1)[0] for u in missing],\n",
    "        \"node\": [u.split(\"::\",1)[1] for u in missing],\n",
    "        label_col: addY\n",
    "    })\n",
    "    X = np.vstack([X, addX])\n",
    "    y = np.concatenate([y, addY])\n",
    "    nodes_df = pd.concat([nodes_df, add_df], ignore_index=True)\n",
    "\n",
    "uid_to_idx = {u:i for i,u in enumerate(nodes_df[\"uid\"].tolist())}\n",
    "src_idx = edges_df[\"src_uid\"].map(uid_to_idx).dropna().astype(int).values\n",
    "dst_idx = edges_df[\"dst_uid\"].map(uid_to_idx).dropna().astype(int).values\n",
    "edge_index = np.stack([np.concatenate([src_idx, dst_idx]),\n",
    "                       np.concatenate([dst_idx, src_idx])], axis=0)\n",
    "\n",
    "# ----------------------------- Scale features -----------------------------\n",
    "labeled_mask_np = (y >= 0)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X.copy()\n",
    "X_scaled[labeled_mask_np] = scaler.fit_transform(X_scaled[labeled_mask_np])\n",
    "if (~labeled_mask_np).any():\n",
    "    X_scaled[~labeled_mask_np] = (X_scaled[~labeled_mask_np] - scaler.mean_) / np.sqrt(scaler.var_ + 1e-8)\n",
    "\n",
    "# ----------------------------- Splits -----------------------------\n",
    "idx_all = np.where(labeled_mask_np)[0]\n",
    "y_all = y[labeled_mask_np]\n",
    "\n",
    "idx_train, idx_tmp, y_train, y_tmp = train_test_split(\n",
    "    idx_all, y_all, test_size=0.30, random_state=SEED, stratify=y_all\n",
    ")\n",
    "idx_val, idx_test, y_val, y_test = train_test_split(\n",
    "    idx_tmp, y_tmp, test_size=0.50, random_state=SEED, stratify=y_tmp\n",
    ")\n",
    "\n",
    "# ----------------------------- Torch tensors (FIX: masks as torch.bool) -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_t = torch.from_numpy(X_scaled).to(device)\n",
    "y_t = torch.from_numpy(y).to(device)\n",
    "\n",
    "edge_index_t = torch.from_numpy(edge_index).long().to(device)\n",
    "\n",
    "train_mask_t = torch.zeros(len(y), dtype=torch.bool, device=device); train_mask_t[idx_train] = True\n",
    "val_mask_t   = torch.zeros(len(y), dtype=torch.bool, device=device); val_mask_t[idx_val]   = True\n",
    "test_mask_t  = torch.zeros(len(y), dtype=torch.bool, device=device); test_mask_t[idx_test]  = True\n",
    "labeled_mask_t = torch.from_numpy(labeled_mask_np).to(device)\n",
    "\n",
    "# ----------------------------- Build GCN adjacency -----------------------------\n",
    "def build_adj(num_nodes, edge_index):\n",
    "    self_loops = torch.arange(num_nodes, device=edge_index.device)\n",
    "    ei = torch.cat([edge_index, torch.stack([self_loops, self_loops])], dim=1)\n",
    "    deg = torch.bincount(ei[0], minlength=num_nodes).float()\n",
    "    deg_inv_sqrt = deg.clamp(min=1).pow(-0.5)\n",
    "    w = deg_inv_sqrt[ei[0]] * deg_inv_sqrt[ei[1]]\n",
    "    A = torch.sparse_coo_tensor(ei, w, (num_nodes, num_nodes))\n",
    "    return A.coalesce()\n",
    "\n",
    "A_t = build_adj(X_t.size(0), edge_index_t)\n",
    "\n",
    "# ----------------------------- Model -----------------------------\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(in_dim, out_dim, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        nn.init.xavier_uniform_(self.lin.weight)\n",
    "    def forward(self, x, adj):\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sparse.mm(adj, x)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim=96, out_dim=2, dropout=0.35):\n",
    "        super().__init__()\n",
    "        self.g1 = GCNLayer(in_dim, hid_dim, dropout)\n",
    "        self.g2 = GCNLayer(hid_dim, out_dim, dropout)\n",
    "        self.do = nn.Dropout(dropout)\n",
    "    def forward(self, x, adj):\n",
    "        x = self.g1(x, adj); x = F.relu(x); x = self.do(x)\n",
    "        x = self.g2(x, adj)\n",
    "        return x\n",
    "\n",
    "model = GCN(in_dim=X_t.size(1), hid_dim=96, out_dim=2, dropout=0.35).to(device)\n",
    "\n",
    "# ----------------------------- Loss, optimizer -----------------------------\n",
    "train_labels = y_t[train_mask_t]\n",
    "classes, counts = torch.unique(train_labels, return_counts=True)\n",
    "num_pos = counts[classes==1].item() if (classes==1).any() else 1\n",
    "num_neg = counts[classes==0].item() if (classes==0).any() else 1\n",
    "weight_pos = (num_neg + num_pos) / (2.0 * num_pos)\n",
    "weight_neg = (num_neg + num_pos) / (2.0 * num_neg)\n",
    "class_weights = torch.tensor([weight_neg, weight_pos], dtype=torch.float32, device=device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3, weight_decay=5e-4)\n",
    "\n",
    "# ----------------------------- Training -----------------------------\n",
    "def evaluate(mask_t):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_t, A_t)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        msk = mask_t & (y_t >= 0)\n",
    "        if msk.sum() == 0: return 0.0\n",
    "        return (pred[msk] == y_t[msk]).float().mean().item()\n",
    "\n",
    "best_val, best_state = -1.0, None\n",
    "patience, patience_cnt = 20, 0\n",
    "EPOCHS = 300\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(X_t, A_t)\n",
    "    loss = criterion(logits[train_mask_t], y_t[train_mask_t])\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        val_acc = evaluate(val_mask_t)\n",
    "        test_acc = evaluate(test_mask_t)\n",
    "        print(f\"Epoch {epoch:03d} | Loss {loss.item():.4f} | Val {val_acc:.4f} | Test {test_acc:.4f}\")\n",
    "        if val_acc > best_val + 1e-4:\n",
    "            best_val = val_acc\n",
    "            best_state = {k:v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
    "            patience_cnt = 0\n",
    "        else:\n",
    "            patience_cnt += 1\n",
    "            if patience_cnt >= patience:\n",
    "                print(\"Early stopping.\"); break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "# ----------------------------- Final eval -----------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(X_t, A_t)\n",
    "    preds = logits.argmax(dim=1)\n",
    "\n",
    "msk = (test_mask_t & (y_t >= 0)).cpu().numpy()\n",
    "y_true = y_t.cpu().numpy()[msk]\n",
    "y_pred = preds.cpu().numpy()[msk]\n",
    "\n",
    "acc = (y_true == y_pred).mean()\n",
    "print(\"\\nFinal Evaluation (Node-Level)\")\n",
    "print(\"=============================\")\n",
    "print(f\"Test Accuracy: {acc:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, labels=[0,1], target_names=[\"clean\",\"trojan\"], digits=4))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f80cf-6c33-40b1-bb78-345b27ded426",
   "metadata": {},
   "source": [
    "#### Node-Level Robustness (Jacobian & Relative Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef74154-3e82-43ce-9ffd-d21e3a9b58c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected counts (perturbation pool): {0: 100, 1: 100}\n",
      "\n",
      "Computing Jacobian and finite-difference relative error for each selected node (this may take a while)...\n",
      "\n",
      "Jacobian norms & FD relative errors (aggregated):\n",
      " Clean nodes:  avg_norm=0.5884 ± 0.1424, avg_rel_err=8.2028e-04 ± 1.8286e-03\n",
      " Trojan nodes: avg_norm=2.4320 ± 0.3598, avg_rel_err=1.8468e-03 ± 7.4382e-03\n",
      "\n",
      "Sample per-node Jacobian info (idx,label,jac_norm,rel_err) [first 6]:\n",
      "(26119, 0, 0.5900143980979919, 0.00035401724744588137)\n",
      "(57231, 0, 0.6124733686447144, 0.00687777204439044)\n",
      "(40297, 0, 0.5780624151229858, 6.616340397158638e-05)\n",
      "(27843, 0, 0.602989673614502, 0.000452778534963727)\n",
      "(26863, 0, 0.7068566083908081, 0.0015428924234583974)\n",
      "(46828, 0, 0.433846116065979, 0.00011373571760486811)\n",
      "\n",
      "Generating per-node PGD adversarial perturbations (L2, all features).\n",
      "\n",
      "================ Robustness Evaluation (Full Test Set: 200 perturbed + rest original) ================\n",
      "Accuracy: 99.54%\n",
      "Precision: 0.9954, Recall: 0.9954, F1: 0.9954\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.9891    0.9926    0.9908      9159\n",
      "      trojan     0.9975    0.9964    0.9969     27556\n",
      "\n",
      "    accuracy                         0.9954     36715\n",
      "   macro avg     0.9933    0.9945    0.9939     36715\n",
      "weighted avg     0.9954    0.9954    0.9954     36715\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9091    68]\n",
      " [  100 27456]]\n",
      "\n",
      "Selected nodes: 200. Number of selected nodes whose prediction flipped after attack: 168 (84.00%).\n"
     ]
    }
   ],
   "source": [
    "# Node-level: Jacobian + strong PGD perturbation on ALL features (200 selected nodes)\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# ---------------------- PARAMETERS (tune these) ----------------------\n",
    "PER_CLASS = 100             # 100 clean + 100 trojan\n",
    "EPSILON = 5.0               # L2 radius of allowed perturbation (make larger to increase effect)\n",
    "ALPHA = 1.0                 # step size per PGD iteration (in feature units)\n",
    "NUM_ITERS = 40              # PGD iterations\n",
    "FD_EPS = 1e-3               # finite-difference epsilon for relative error check\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# ---------------------- Sanity checks ----------------------\n",
    "required_vars = [\"model\",\"X_t\",\"A_t\",\"y_t\",\"test_mask_t\",\"device\"]\n",
    "for v in required_vars:\n",
    "    if v not in globals():\n",
    "        raise RuntimeError(f\"Required variable '{v}' not found in the environment.\")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ---------------------- Select samples (100 per class) ----------------------\n",
    "test_indices = np.where(test_mask_t.cpu().numpy())[0]\n",
    "labels_np = y_t.cpu().numpy()\n",
    "selected = []\n",
    "rng = np.random.default_rng(SEED)\n",
    "for cls in [0,1]:\n",
    "    idxs = [int(i) for i in test_indices if labels_np[int(i)] == cls]\n",
    "    if len(idxs) >= PER_CLASS:\n",
    "        chosen = rng.choice(idxs, size=PER_CLASS, replace=False)\n",
    "    else:\n",
    "        chosen = idxs\n",
    "    selected.extend(chosen)\n",
    "\n",
    "selected = np.array(selected, dtype=np.int64)\n",
    "print(\"Selected counts (perturbation pool):\", {0: int((labels_np[selected]==0).sum()), 1: int((labels_np[selected]==1).sum())})\n",
    "\n",
    "# ---------------------- Compute Jacobian norms & FD relative errors ----------------------\n",
    "device = device if 'device' in globals() else torch.device(\"cpu\")\n",
    "jacobian_norms = []\n",
    "fd_rel_errors = []\n",
    "per_sample_info = []   # store tuples (idx, label, jacobian_norm, fd_rel_error)\n",
    "\n",
    "print(\"\\nComputing Jacobian and finite-difference relative error for each selected node (this may take a while)...\")\n",
    "for node_idx in selected:\n",
    "    node_idx = int(node_idx)\n",
    "    x0 = X_t[node_idx].detach().clone().to(device).requires_grad_(True)\n",
    "\n",
    "    def f_local(x):\n",
    "        # returns logits vector (c,) for the node\n",
    "        X_mod = X_t.clone().detach().to(device)\n",
    "        X_mod[node_idx] = x\n",
    "        out = model(X_mod, A_t)\n",
    "        return out[node_idx]\n",
    "\n",
    "    # Jacobian: shape (num_classes, feature_dim)\n",
    "    try:\n",
    "        jac = torch.autograd.functional.jacobian(f_local, x0)  # shape: (c, d)\n",
    "    except RuntimeError as e:\n",
    "        # fallback: compute per-output jac via loop (slower)\n",
    "        c = int(model(X_t, A_t)[node_idx].shape[0])\n",
    "        jac_rows = []\n",
    "        for out_i in range(c):\n",
    "            def scalar_f(x, i=out_i):\n",
    "                return f_local(x)[i]\n",
    "            row = torch.autograd.functional.jacobian(scalar_f, x0)\n",
    "            jac_rows.append(row.unsqueeze(0))\n",
    "        jac = torch.cat(jac_rows, dim=0)\n",
    "\n",
    "    jac = jac.detach()\n",
    "    jac_norm = torch.norm(jac, p='fro').item()\n",
    "\n",
    "    # FD relative error\n",
    "    delta_fd = FD_EPS * torch.randn_like(x0).to(device)\n",
    "    pred_change = jac.mv(delta_fd)                    # predicted change (c,)\n",
    "    f_x0 = f_local(x0).detach()\n",
    "    f_x0_p = f_local(x0 + delta_fd).detach()\n",
    "    actual_change = f_x0_p - f_x0\n",
    "    rel_err = (torch.norm(pred_change - actual_change) / (torch.norm(actual_change) + 1e-8)).item()\n",
    "\n",
    "    jacobian_norms.append(jac_norm)\n",
    "    fd_rel_errors.append(rel_err)\n",
    "    per_sample_info.append((node_idx, int(labels_np[node_idx]), jac_norm, rel_err))\n",
    "\n",
    "# aggregate per-class stats\n",
    "def stats_of(indices, arr):\n",
    "    sub = np.array([a for (i,a) in zip(indices, arr)])\n",
    "    return sub.mean(), sub.std()\n",
    "\n",
    "mask_sel = labels_np[selected]\n",
    "clean_mask = (mask_sel==0)\n",
    "trojan_mask = (mask_sel==1)\n",
    "\n",
    "clean_jac = np.array([i[2] for i in per_sample_info])[clean_mask]\n",
    "troj_jac  = np.array([i[2] for i in per_sample_info])[trojan_mask]\n",
    "clean_err = np.array([i[3] for i in per_sample_info])[clean_mask]\n",
    "troj_err  = np.array([i[3] for i in per_sample_info])[trojan_mask]\n",
    "\n",
    "print(\"\\nJacobian norms & FD relative errors (aggregated):\")\n",
    "print(f\" Clean nodes:  avg_norm={clean_jac.mean():.4f} ± {clean_jac.std():.4f}, avg_rel_err={clean_err.mean():.4e} ± {clean_err.std():.4e}\")\n",
    "print(f\" Trojan nodes: avg_norm={troj_jac.mean():.4f} ± {troj_jac.std():.4f}, avg_rel_err={troj_err.mean():.4e} ± {troj_err.std():.4e}\")\n",
    "\n",
    "# Optionally print first 6 per-sample entries (idx,label,jac_norm,rel_err)\n",
    "print(\"\\nSample per-node Jacobian info (idx,label,jac_norm,rel_err) [first 6]:\")\n",
    "for t in per_sample_info[:6]:\n",
    "    print(t)\n",
    "\n",
    "# ---------------------- Generate strong adversarial perturbation via per-node PGD (L2-constrained) ----------------------\n",
    "print(\"\\nGenerating per-node PGD adversarial perturbations (L2, all features).\")\n",
    "perturbed_X = X_t.clone().detach().to(device)\n",
    "\n",
    "criterion_ce = torch.nn.CrossEntropyLoss()\n",
    "flips_before = 0\n",
    "flips_after = 0\n",
    "orig_preds = model(X_t, A_t).argmax(dim=1).cpu().numpy()\n",
    "\n",
    "# To avoid computing gradients wrt model params during PGD, we use torch.autograd.grad for input only.\n",
    "for node_idx in selected:\n",
    "    node_idx = int(node_idx)\n",
    "    x_orig = X_t[node_idx].detach().clone().to(device)\n",
    "    x_adv = x_orig.clone().detach().requires_grad_(True)\n",
    "\n",
    "    # original prediction for this node\n",
    "    orig_pred = int(model(X_t, A_t)[node_idx].argmax().item())\n",
    "    if orig_pred != labels_np[node_idx]:\n",
    "        # It was already misclassified originally; still construct attack to show effect\n",
    "        pass\n",
    "\n",
    "    # PGD loop: maximize cross-entropy loss (untargeted)\n",
    "    for it in range(NUM_ITERS):\n",
    "        # build X_mod with current candidate for this node\n",
    "        X_mod = perturbed_X.clone().detach()\n",
    "        X_mod[node_idx] = x_adv\n",
    "        logits = model(X_mod, A_t)\n",
    "        loss = F.cross_entropy(logits[node_idx].unsqueeze(0), y_t[node_idx].unsqueeze(0))\n",
    "\n",
    "        # gradient only wrt x_adv\n",
    "        grad_x = torch.autograd.grad(loss, x_adv, retain_graph=False)[0]\n",
    "        if torch.norm(grad_x).item() == 0:\n",
    "            break\n",
    "        # step in direction of normalized gradient\n",
    "        step = ALPHA * grad_x / (grad_x.norm() + 1e-12)\n",
    "        x_adv = (x_adv + step).detach().requires_grad_(True)\n",
    "\n",
    "        # project to L2 ball around x_orig with radius EPSILON\n",
    "        delta = x_adv.detach() - x_orig.detach()\n",
    "        delta_norm = delta.norm().item()\n",
    "        if delta_norm > EPSILON:\n",
    "            delta = delta * (EPSILON / (delta_norm + 1e-12))\n",
    "            x_adv = (x_orig + delta).detach().requires_grad_(True)\n",
    "\n",
    "    # final adv vector\n",
    "    x_adv_final = x_adv.detach()\n",
    "    perturbed_X[node_idx] = x_adv_final\n",
    "\n",
    "# ---------------------- Evaluate on full test set: 200 perturbed + rest original ----------------------\n",
    "all_test_idx = np.where(test_mask_t.cpu().numpy())[0]\n",
    "with torch.no_grad():\n",
    "    logits_all = model(perturbed_X, A_t)\n",
    "    preds_all = logits_all[all_test_idx].argmax(dim=1).cpu().numpy()\n",
    "    labels_all = labels_np[all_test_idx]\n",
    "\n",
    "acc = (preds_all == labels_all).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_all, preds_all, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n================ Robustness Evaluation (Full Test Set: 200 perturbed + rest original) ================\")\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(labels_all, preds_all, target_names=[\"clean\",\"trojan\"], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "\n",
    "# ---------------------- How many selected nodes flipped? ----------------------\n",
    "with torch.no_grad():\n",
    "    orig_logits = model(X_t, A_t)\n",
    "    orig_preds = orig_logits[selected].argmax(dim=1).cpu().numpy()\n",
    "    adv_logits = model(perturbed_X, A_t)\n",
    "    adv_preds = adv_logits[selected].argmax(dim=1).cpu().numpy()\n",
    "\n",
    "flips = (orig_preds != adv_preds).sum()\n",
    "print(f\"\\nSelected nodes: {len(selected)}. Number of selected nodes whose prediction flipped after attack: {flips} ({100*flips/len(selected):.2f}%).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903817a6-73fe-4dab-96cb-819dfebfa657",
   "metadata": {},
   "source": [
    "#### Local Lipschitz Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca95c0ab-7072-4888-9a3c-46647f9b1148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected perturbation pool: {0: 100, 1: 100}\n",
      "\n",
      "Computing Jacobian / spectral vector and FD relative errors (200 nodes)...\n",
      "\n",
      "Aggregated spectral (Lipschitz) stats:\n",
      " Clean:  avg_L=0.5779 ± 0.1352, avg_FDrel=6.2905e-04 ± 8.0656e-04\n",
      " Trojan: avg_L=2.3569 ± 0.3636, avg_FDrel=8.7222e-03 ± 4.2885e-02\n",
      "\n",
      "Sample preview (first 6): (idx,label,L,FD_rel_err)\n",
      "(26119, 0, 0.5806882381439209, 0.00020766345551237464)\n",
      "(57231, 0, 0.604617714881897, 0.0005543306469917297)\n",
      "(40297, 0, 0.5674167275428772, 9.97965398710221e-05)\n",
      "(27843, 0, 0.5931023955345154, 0.0003367722674738616)\n",
      "(26863, 0, 0.6973091959953308, 0.0004411973350215703)\n",
      "(46828, 0, 0.42770835757255554, 0.0001565459679113701)\n",
      "\n",
      "Running per-node PGD (initialized on top singular vector) for each selected node ...\n",
      "\n",
      "============= Robustness Evaluation (Full Test Set: 200 perturbed + rest original) =============\n",
      "Accuracy: 99.38%\n",
      "Precision: 0.9938, Recall: 0.9938, F1: 0.9938\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.9891    0.9862    0.9876      9159\n",
      "      trojan     0.9954    0.9964    0.9959     27556\n",
      "\n",
      "    accuracy                         0.9938     36715\n",
      "   macro avg     0.9922    0.9913    0.9918     36715\n",
      "weighted avg     0.9938    0.9938    0.9938     36715\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9033   126]\n",
      " [  100 27456]]\n",
      "\n",
      "Selected nodes: 200. Flipped after attack: 200 (100.00%).\n"
     ]
    }
   ],
   "source": [
    "# Strong Lipschitz-directed PGD attack (perturb ALL features) + reporting\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# ------------------------ Parameters (tune if needed) ------------------------\n",
    "PER_CLASS   = 100        # pick 100 clean + 100 trojan\n",
    "FD_EPS      = 1e-3       # finite-diff epsilon for relative error\n",
    "EPSILON     = 12.0       # L2 radius of allowed perturbation (feature-scale units) -- increase for stronger attack\n",
    "ALPHA       = 2.0        # PGD step size\n",
    "NUM_ITERS   = 60         # PGD iterations\n",
    "SEED        = 42\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# ------------------------ Sanity / dependencies ------------------------------\n",
    "required = [\"model\",\"X_t\",\"A_t\",\"y_t\",\"test_mask_t\",\"device\"]\n",
    "for r in required:\n",
    "    if r not in globals():\n",
    "        raise RuntimeError(f\"Required variable '{r}' not found in the environment.\")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ------------------------ Sample selection (100 per class) ------------------\n",
    "test_idx_all = np.where(test_mask_t.cpu().numpy())[0]\n",
    "labels_np = y_t.cpu().numpy()\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "selected_nodes = []\n",
    "for cls in [0,1]:\n",
    "    idxs = [int(i) for i in test_idx_all if labels_np[i] == cls]\n",
    "    if len(idxs) >= PER_CLASS:\n",
    "        chosen = rng.choice(idxs, size=PER_CLASS, replace=False)\n",
    "    else:\n",
    "        chosen = idxs\n",
    "    selected_nodes.extend(chosen)\n",
    "selected_nodes = np.array(selected_nodes, dtype=np.int64)\n",
    "\n",
    "print(\"Selected perturbation pool:\", {0:int((labels_np[selected_nodes]==0).sum()), 1:int((labels_np[selected_nodes]==1).sum())})\n",
    "\n",
    "# ------------------------ Compute J, spectral norm, top-right singular vec, FD error\n",
    "per_sample_info = []   # tuples (idx, label, L_local, fd_rel_err)\n",
    "print(\"\\nComputing Jacobian / spectral vector and FD relative errors (200 nodes)...\")\n",
    "for node_idx in selected_nodes:\n",
    "    node_idx = int(node_idx)\n",
    "    x0 = X_t[node_idx].detach().clone().to(device).requires_grad_(True)\n",
    "\n",
    "    def f_node(x):\n",
    "        X_mod = X_t.clone().detach().to(device)\n",
    "        X_mod[node_idx] = x\n",
    "        logits = model(X_mod, A_t)\n",
    "        return logits[node_idx]\n",
    "\n",
    "    # compute Jacobian J (num_classes x d)\n",
    "    J = torch.autograd.functional.jacobian(f_node, x0).detach()   # shape (c, d)\n",
    "    # spectral norm and top-right singular vector (via SVD)\n",
    "    try:\n",
    "        U, S, Vh = torch.linalg.svd(J, full_matrices=False)\n",
    "        sigma_max = S[0].item()\n",
    "        v = Vh[0,:].detach()   # top right singular vector (length d)\n",
    "    except RuntimeError:\n",
    "        # fallback to power method on J@J.T for largest singular value/vector\n",
    "        # compute JJT = J @ J.T (c x c), find principal left singular vector u, then v = J.T u / sigma\n",
    "        Jcpu = J.cpu()\n",
    "        JJT = (Jcpu @ Jcpu.T).numpy()\n",
    "        eigvals, eigvecs = np.linalg.eigh(JJT)\n",
    "        k = eigvals.argmax()\n",
    "        u = torch.tensor(eigvecs[:,k], dtype=J.dtype, device=J.device)\n",
    "        sigma_max = float(np.sqrt(max(eigvals[k], 0.0)))\n",
    "        v = (J.T @ u)\n",
    "        if v.norm().item() > 0:\n",
    "            v = v / (v.norm() + 1e-12)\n",
    "\n",
    "    # finite-difference relative error (single trial for speed; can average)\n",
    "    delta_fd = FD_EPS * torch.randn_like(x0).to(device)\n",
    "    pred_change = J.mv(delta_fd)\n",
    "    f0 = f_node(x0).detach()\n",
    "    f0p = f_node(x0 + delta_fd).detach()\n",
    "    actual_change = f0p - f0\n",
    "    fd_rel_err = (torch.norm(pred_change - actual_change) / (torch.norm(actual_change) + 1e-8)).item()\n",
    "\n",
    "    per_sample_info.append((node_idx, int(labels_np[node_idx]), float(sigma_max), float(fd_rel_err)))\n",
    "\n",
    "# Aggregate and print\n",
    "clean_stats = [ (i,L,e) for (i,lab,L,e) in per_sample_info if lab==0 ]\n",
    "troj_stats  = [ (i,L,e) for (i,lab,L,e) in per_sample_info if lab==1 ]\n",
    "\n",
    "def aggs(stats):\n",
    "    if not stats: return (0.0,0.0,0.0,0.0)\n",
    "    Ls = np.array([s[1] for s in stats]); Es = np.array([s[2] for s in stats])\n",
    "    return (Ls.mean(), Ls.std(), Es.mean(), Es.std())\n",
    "\n",
    "cL_mean, cL_std, cE_mean, cE_std = aggs(clean_stats)\n",
    "tL_mean, tL_std, tE_mean, tE_std = aggs(troj_stats)\n",
    "\n",
    "print(\"\\nAggregated spectral (Lipschitz) stats:\")\n",
    "print(f\" Clean:  avg_L={cL_mean:.4f} ± {cL_std:.4f}, avg_FDrel={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_L={tL_mean:.4f} ± {tL_std:.4f}, avg_FDrel={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "\n",
    "print(\"\\nSample preview (first 6): (idx,label,L,FD_rel_err)\")\n",
    "for p in per_sample_info[:6]:\n",
    "    print(p)\n",
    "\n",
    "# ------------------------ Create perturbed features (PGD initialized by top-singular vector) ------------------------\n",
    "print(\"\\nRunning per-node PGD (initialized on top singular vector) for each selected node ...\")\n",
    "perturbed_X = X_t.clone().detach().to(device)\n",
    "flips = 0\n",
    "orig_preds = model(X_t, A_t).argmax(dim=1).cpu().numpy()\n",
    "\n",
    "for node_idx, label, sigma_val, fd_err in per_sample_info:\n",
    "    node_idx = int(node_idx)\n",
    "    x_orig = X_t[node_idx].detach().clone().to(device)\n",
    "    # compute initialization direction v for current node (recompute so we have v on device)\n",
    "    x0 = X_t[node_idx].detach().clone().to(device).requires_grad_(True)\n",
    "    def f_local(x):\n",
    "        X_mod = X_t.clone().detach().to(device)\n",
    "        X_mod[node_idx] = x\n",
    "        return model(X_mod, A_t)[node_idx]\n",
    "    J = torch.autograd.functional.jacobian(f_local, x0).detach()\n",
    "    # SVD for v (right singular)\n",
    "    try:\n",
    "        _, S, Vh = torch.linalg.svd(J, full_matrices=False)\n",
    "        v_init = Vh[0,:].detach()\n",
    "    except RuntimeError:\n",
    "        # fallback random init\n",
    "        v_init = torch.randn_like(x_orig).to(device)\n",
    "    if v_init.norm().item() > 0:\n",
    "        v_init = v_init / (v_init.norm() + 1e-12)\n",
    "    else:\n",
    "        v_init = torch.randn_like(x_orig).to(device)\n",
    "        v_init = v_init / (v_init.norm() + 1e-12)\n",
    "\n",
    "    # initialize adv example at x0 + (EPSILON/2) * v_init\n",
    "    x_adv = (x_orig + 0.5 * EPSILON * v_init).detach().clone().requires_grad_(True)\n",
    "\n",
    "    # PGD maximize CE loss wrt true label (untargeted)\n",
    "    for it in range(NUM_ITERS):\n",
    "        X_mod = perturbed_X.clone().detach()\n",
    "        X_mod[node_idx] = x_adv\n",
    "        logits = model(X_mod, A_t)\n",
    "        loss = F.cross_entropy(logits[node_idx].unsqueeze(0), y_t[node_idx].unsqueeze(0))\n",
    "        grad_x = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "        if grad_x.norm().item() == 0:\n",
    "            break\n",
    "        # step in gradient direction (maximize)\n",
    "        step = ALPHA * grad_x / (grad_x.norm() + 1e-12)\n",
    "        x_adv = (x_adv + step).detach()\n",
    "        # project to L2-ball of radius EPSILON around x_orig\n",
    "        delta = x_adv - x_orig\n",
    "        dnorm = delta.norm().item()\n",
    "        if dnorm > EPSILON:\n",
    "            delta = delta * (EPSILON / (dnorm + 1e-12))\n",
    "            x_adv = (x_orig + delta).detach()\n",
    "        x_adv = x_adv.requires_grad_(True)\n",
    "\n",
    "    # finalize\n",
    "    x_adv_final = x_adv.detach()\n",
    "    perturbed_X[node_idx] = x_adv_final\n",
    "\n",
    "# ------------------------ Evaluate on full test set: 200 perturbed + rest original ----------\n",
    "test_indices = np.where(test_mask_t.cpu().numpy())[0]\n",
    "with torch.no_grad():\n",
    "    logits_all = model(perturbed_X, A_t)\n",
    "    preds_all = logits_all[test_indices].argmax(dim=1).cpu().numpy()\n",
    "    labels_all = labels_np[test_indices]\n",
    "\n",
    "acc = (preds_all == labels_all).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_all, preds_all, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n============= Robustness Evaluation (Full Test Set: 200 perturbed + rest original) =============\")\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(labels_all, preds_all, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "\n",
    "# ------------------------ Flip statistics for selected nodes ---------------------------------------\n",
    "with torch.no_grad():\n",
    "    orig_sel_preds = orig_preds[selected_nodes]\n",
    "    adv_sel_preds = logits_all[selected_nodes].argmax(dim=1).cpu().numpy()\n",
    "num_flips = int((orig_sel_preds != adv_sel_preds).sum())\n",
    "print(f\"\\nSelected nodes: {len(selected_nodes)}. Flipped after attack: {num_flips} ({100.0*num_flips/len(selected_nodes):.2f}%).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabcb5e2-6b28-4d2f-bbbf-0159b5869cdd",
   "metadata": {},
   "source": [
    "#### Hessian-based Curvature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a21b6277-5d73-4108-9282-7c08b1a65092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected perturbation pool: clean=100, trojan=100\n",
      "\n",
      "Computing gradient norms and FD relative errors for selected nodes...\n",
      "\n",
      "Aggregated Hessian (grad outer-product) stats:\n",
      " Clean:  avg_lambda=0.0010 ± 0.0027, avg_FDrel=8.8848e-01 ± 7.6424e-02\n",
      " Trojan: avg_lambda=0.0142 ± 0.0434, avg_FDrel=9.8424e-01 ± 8.0939e-02\n",
      " Overall: avg_lambda=0.0076 ± 0.0315, avg_FDrel=9.3636e-01 ± 9.2134e-02\n",
      "\n",
      "Sample preview (first 6): (idx,label,lambda,FD_rel_err)\n",
      "(26119, 0, 0.00013114006249938335, 0.8717354198141685)\n",
      "(57231, 0, 0.00010764707143384126, 0.8226354340519129)\n",
      "(40297, 0, 0.001321573346424812, 0.9325460845060217)\n",
      "(27843, 0, 0.0007104109633964684, 0.9141915288341323)\n",
      "(26863, 0, 0.0005748949339887677, 0.8405098988944559)\n",
      "(46828, 0, 0.0004032530106434819, 0.8759966817844393)\n",
      "\n",
      "Constructing Hessian-aligned perturbations (direction = -g normalized) and applying to selected nodes...\n",
      "\n",
      "================ Robustness Evaluation (Full Test Set: 200 perturbed + rest original) ===============\n",
      "Accuracy: 99.55%\n",
      "Precision: 0.9955, Recall: 0.9955, F1: 0.9955\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.9891    0.9927    0.9909      9159\n",
      "      trojan     0.9976    0.9964    0.9970     27556\n",
      "\n",
      "    accuracy                         0.9955     36715\n",
      "   macro avg     0.9933    0.9945    0.9939     36715\n",
      "weighted avg     0.9955    0.9955    0.9955     36715\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9092    67]\n",
      " [  100 27456]]\n",
      "\n",
      "Selected nodes: 200. Flipped after Hessian-based perturbation: 166 (83.00%).\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Hessian-Based Curvature (grad outer-product) for node-level Trojan detection\n",
    "# Uses: model, X_t, A_t, y_t, test_mask_t, device (must be defined already)\n",
    "# =========================\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# -------------------- Parameters --------------------\n",
    "PER_CLASS = 100          # 100 nodes per class (clean/trojan)\n",
    "FD_EPS = 5e-3            # finite-diff epsilon for relative-error check\n",
    "TRIALS_PER_NODE = 10     # average trials per node for relative error\n",
    "PERT_P = 6.0             # L2 magnitude for final Hessian-aligned perturbation (tuneable)\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# -------------------- Sanity checks --------------------\n",
    "required = [\"model\",\"X_t\",\"A_t\",\"y_t\",\"test_mask_t\",\"device\"]\n",
    "for r in required:\n",
    "    if r not in globals():\n",
    "        raise RuntimeError(f\"Required variable '{r}' not found in the environment.\")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# -------------------- Class names (binary) --------------------\n",
    "class_names = [\"clean\", \"trojan\"]\n",
    "\n",
    "# -------------------- Build test index list --------------------\n",
    "test_idx_all = np.where(test_mask_t.cpu().numpy())[0]\n",
    "labels_np = y_t.cpu().numpy()\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "selected_nodes = []\n",
    "for cls in [0,1]:\n",
    "    idxs = [int(i) for i in test_idx_all if labels_np[i] == cls]\n",
    "    if len(idxs) >= PER_CLASS:\n",
    "        chosen = rng.choice(idxs, size=PER_CLASS, replace=False)\n",
    "    else:\n",
    "        chosen = idxs\n",
    "    selected_nodes.extend(chosen)\n",
    "selected_nodes = np.array(selected_nodes, dtype=np.int64)\n",
    "\n",
    "print(f\"Selected perturbation pool: clean={int((labels_np[selected_nodes]==0).sum())}, trojan={int((labels_np[selected_nodes]==1).sum())}\")\n",
    "\n",
    "# -------------------- Precompute base logits (to find predicted class at x0) --------------------\n",
    "with torch.no_grad():\n",
    "    base_logits_all = model(X_t, A_t).detach()  # shape (N, C)\n",
    "\n",
    "# -------------------- Storage --------------------\n",
    "per_sample_info = []   # (node_idx, label, lambda_max = ||g||^2, avg_rel_error)\n",
    "print(\"\\nComputing gradient norms and FD relative errors for selected nodes...\")\n",
    "\n",
    "# -------------------- Helper: h(x) and gradient computation --------------------\n",
    "def compute_g_and_h_for_node(node_idx):\n",
    "    # x0 with grad\n",
    "    x0 = X_t[node_idx].detach().clone().to(device).requires_grad_(True)\n",
    "    pred_class = int(torch.argmax(base_logits_all[node_idx]).item())\n",
    "\n",
    "    def h(x):\n",
    "        X_mod = X_t.clone().detach().to(device)\n",
    "        X_mod[node_idx] = x\n",
    "        logits = model(X_mod, A_t)[node_idx]\n",
    "        logp = F.log_softmax(logits, dim=0)\n",
    "        return logp[pred_class]\n",
    "\n",
    "    h0 = h(x0)\n",
    "    g = torch.autograd.grad(h0, x0, retain_graph=False, create_graph=False)[0].detach()\n",
    "    return x0.detach(), g, h0.detach(), h\n",
    "\n",
    "# -------------------- Main loop: compute ||g||^2 and relative errors --------------------\n",
    "for node_idx in selected_nodes:\n",
    "    node_idx = int(node_idx)\n",
    "    label = int(labels_np[node_idx])\n",
    "    x0, g, h0, h_func = compute_g_and_h_for_node(node_idx)\n",
    "\n",
    "    lambda_max = float(g.norm(p=2).item() ** 2)   # curvature proxy\n",
    "\n",
    "    # Relative error via multiple random deltas\n",
    "    node_rel_errs = []\n",
    "    for _ in range(TRIALS_PER_NODE):\n",
    "        delta = FD_EPS * torch.randn_like(x0).to(device)\n",
    "        gt_delta = float(torch.dot(g, delta).item())\n",
    "        pred_second = 0.5 * (gt_delta ** 2)\n",
    "        actual_second = float((h_func(x0 + delta) - h0 - torch.dot(g, delta)).item())\n",
    "        rel_error = abs(pred_second - actual_second) / (abs(actual_second) + 1e-8)\n",
    "        node_rel_errs.append(rel_error)\n",
    "\n",
    "    avg_rel_err = float(np.mean(node_rel_errs))\n",
    "    per_sample_info.append((node_idx, label, lambda_max, avg_rel_err))\n",
    "\n",
    "# -------------------- Aggregation & Print --------------------\n",
    "clean_stats = [t for t in per_sample_info if t[1]==0]\n",
    "troj_stats  = [t for t in per_sample_info if t[1]==1]\n",
    "\n",
    "def summarize(stats):\n",
    "    if not stats:\n",
    "        return (0.0,0.0,0.0,0.0)\n",
    "    Ls = np.array([s[2] for s in stats])\n",
    "    Es = np.array([s[3] for s in stats])\n",
    "    return (Ls.mean(), Ls.std(), Es.mean(), Es.std())\n",
    "\n",
    "cL_mean, cL_std, cE_mean, cE_std = summarize(clean_stats)\n",
    "tL_mean, tL_std, tE_mean, tE_std = summarize(troj_stats)\n",
    "overall_L_mean = np.mean([s[2] for s in per_sample_info]) if per_sample_info else 0.0\n",
    "overall_L_std  = np.std([s[2] for s in per_sample_info])  if per_sample_info else 0.0\n",
    "overall_E_mean = np.mean([s[3] for s in per_sample_info]) if per_sample_info else 0.0\n",
    "overall_E_std  = np.std([s[3] for s in per_sample_info])  if per_sample_info else 0.0\n",
    "\n",
    "print(\"\\nAggregated Hessian (grad outer-product) stats:\")\n",
    "print(f\" Clean:  avg_lambda={cL_mean:.4f} ± {cL_std:.4f}, avg_FDrel={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_lambda={tL_mean:.4f} ± {tL_std:.4f}, avg_FDrel={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "print(f\" Overall: avg_lambda={overall_L_mean:.4f} ± {overall_L_std:.4f}, avg_FDrel={overall_E_mean:.4e} ± {overall_E_std:.4e}\")\n",
    "\n",
    "print(\"\\nSample preview (first 6): (idx,label,lambda,FD_rel_err)\")\n",
    "for p in per_sample_info[:6]:\n",
    "    print(p)\n",
    "\n",
    "# -------------------- Build adversarial perturbations aligned to -g (reduce log-prob of predicted class) --------------------\n",
    "print(\"\\nConstructing Hessian-aligned perturbations (direction = -g normalized) and applying to selected nodes...\")\n",
    "perturbed_X = X_t.clone().detach().to(device)\n",
    "orig_preds = torch.argmax(base_logits_all, dim=1).cpu().numpy()\n",
    "\n",
    "for (node_idx, label, lambda_val, avg_rel_err) in per_sample_info:\n",
    "    node_idx = int(node_idx)\n",
    "    # recompute g to be safe (cheap relative to full loop); reuse compute helper\n",
    "    x0, g, h0, h_func = compute_g_and_h_for_node(node_idx)\n",
    "    gnorm = g.norm().item()\n",
    "    if gnorm < 1e-12:\n",
    "        # if gradient is essentially zero, use random direction\n",
    "        dir_vec = torch.randn_like(x0).to(device)\n",
    "    else:\n",
    "        dir_vec = - g / (gnorm + 1e-12)  # negative g to reduce log-prob\n",
    "\n",
    "    # scale to desired L2 magnitude PERT_P\n",
    "    delta = (PERT_P * dir_vec).detach()\n",
    "    perturbed_X[node_idx] = (x0 + delta).detach()\n",
    "\n",
    "# -------------------- Evaluate on full test set: (200 perturbed + rest original) --------------------\n",
    "test_indices = np.where(test_mask_t.cpu().numpy())[0]\n",
    "with torch.no_grad():\n",
    "    logits_all = model(perturbed_X, A_t)\n",
    "    preds_all = logits_all[test_indices].argmax(dim=1).cpu().numpy()\n",
    "    labels_all = labels_np[test_indices]\n",
    "\n",
    "acc = (preds_all == labels_all).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_all, preds_all, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n================ Robustness Evaluation (Full Test Set: 200 perturbed + rest original) ===============\")\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(labels_all, preds_all, target_names=class_names, digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "\n",
    "# -------------------- Flip statistics --------------------\n",
    "orig_sel_preds = orig_preds[selected_nodes]\n",
    "adv_sel_preds = logits_all[selected_nodes].argmax(dim=1).cpu().numpy()\n",
    "num_flips = int((orig_sel_preds != adv_sel_preds).sum())\n",
    "print(f\"\\nSelected nodes: {len(selected_nodes)}. Flipped after Hessian-based perturbation: {num_flips} ({100.0*num_flips/len(selected_nodes):.2f}%).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6d5a07-8135-492c-9997-9a888a80bde5",
   "metadata": {},
   "source": [
    "#### Prediction Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bba7862-9280-4b58-9d0d-8051a4f838b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Strong Prediction-Margin Attack (200 nodes: 100 per class) ---\n",
      "Selected nodes ? clean=100, trojan=100\n",
      "? Finished perturbations.\n",
      "\n",
      "============= Robustness Evaluation (Full Test Set) =============\n",
      "Accuracy: 100.00%\n",
      "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     1.0000    1.0000    1.0000      9159\n",
      "      trojan     1.0000    1.0000    1.0000     27556\n",
      "\n",
      "    accuracy                         1.0000     36715\n",
      "   macro avg     1.0000    1.0000    1.0000     36715\n",
      "weighted avg     1.0000    1.0000    1.0000     36715\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9159     0]\n",
      " [    0 27556]]\n",
      "\n",
      "Selected nodes: 200. Flipped after attack: 101 (50.50%).\n",
      "\n",
      "--- Prediction Margin Stats (on perturbed nodes) ---\n",
      " Clean:  avg_margin=2.0527 ± 0.6118, avg_FDrel=3.9362e-04 ± 5.7933e-04\n",
      " Trojan: avg_margin=3.7545 ± 0.6768, avg_FDrel=9.3533e-04 ± 9.7417e-04\n",
      "\n",
      "Sample preview (first 6): (idx,label,margin,FD_rel_err)\n",
      "(44087, 0, 1.2382581233978271, 0.0001136840236789138)\n",
      "(1246, 0, 2.1299312114715576, 0.00030635405862567674)\n",
      "(55526, 0, 1.5654877424240112, 0.0009172477445794717)\n",
      "(3698, 0, 2.1829371452331543, 0.00023454774760991873)\n",
      "(23454, 0, 2.4282448291778564, 0.0003301106052229386)\n",
      "(58015, 0, 2.9127262830734253, 0.00038084479549738295)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# ------------------------\n",
    "# Parameters\n",
    "# ------------------------\n",
    "EPSILON = 2.0      # stronger perturbation budget\n",
    "ALPHA = 0.4        # PGD step size\n",
    "NUM_ITERS = 15     # PGD iterations\n",
    "FD_EPS = 1e-3      # small noise for finite-difference check\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ------------------------\n",
    "# Step 1: Select nodes (100 clean, 100 trojan)\n",
    "# ------------------------\n",
    "clean_nodes = np.where(labels_np == 0)[0]\n",
    "trojan_nodes = np.where(labels_np == 1)[0]\n",
    "np.random.seed(42)\n",
    "sel_clean = np.random.choice(clean_nodes, 100, replace=False)\n",
    "sel_trojan = np.random.choice(trojan_nodes, 100, replace=False)\n",
    "selected_nodes = np.concatenate([sel_clean, sel_trojan])\n",
    "\n",
    "print(f\"\\n--- Strong Prediction-Margin Attack (200 nodes: 100 per class) ---\")\n",
    "print(f\"Selected nodes ? clean={len(sel_clean)}, trojan={len(sel_trojan)}\")\n",
    "\n",
    "# ------------------------\n",
    "# Step 2: Apply perturbation (PGD on all features)\n",
    "# ------------------------\n",
    "perturbed_X = X_t.clone().detach().to(device)\n",
    "orig_preds = model(X_t, A_t).argmax(dim=1).cpu().numpy()\n",
    "\n",
    "for node_idx in selected_nodes:\n",
    "    node_idx = int(node_idx)\n",
    "    x_orig = X_t[node_idx].detach().clone().to(device)\n",
    "\n",
    "    # adversarial initialization\n",
    "    delta = torch.randn_like(x_orig).to(device)\n",
    "    delta = EPSILON * delta / (delta.norm() + 1e-12)\n",
    "    x_adv = (x_orig + delta).detach().clone().requires_grad_(True)\n",
    "\n",
    "    for it in range(NUM_ITERS):\n",
    "        X_mod = perturbed_X.clone().detach()\n",
    "        X_mod[node_idx] = x_adv\n",
    "        logits = model(X_mod, A_t)\n",
    "        loss = F.cross_entropy(logits[node_idx].unsqueeze(0), y_t[node_idx].unsqueeze(0))\n",
    "        grad_x = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "\n",
    "        step = ALPHA * grad_x / (grad_x.norm() + 1e-12)\n",
    "        x_adv = (x_adv + step).detach()\n",
    "        delta = x_adv - x_orig\n",
    "        if delta.norm() > EPSILON:\n",
    "            delta = delta * (EPSILON / (delta.norm() + 1e-12))\n",
    "            x_adv = (x_orig + delta).detach()\n",
    "        x_adv = x_adv.requires_grad_(True)\n",
    "\n",
    "    perturbed_X[node_idx] = x_adv.detach()\n",
    "\n",
    "print(\"? Finished perturbations.\")\n",
    "\n",
    "# ------------------------\n",
    "# Step 3: Evaluate model on perturbed + original mix\n",
    "# ------------------------\n",
    "test_indices = np.where(test_mask_t.cpu().numpy())[0]\n",
    "with torch.no_grad():\n",
    "    logits_all = model(perturbed_X, A_t)\n",
    "    preds_all = logits_all[test_indices].argmax(dim=1).cpu().numpy()\n",
    "    labels_all = labels_np[test_indices]\n",
    "\n",
    "acc = (preds_all == labels_all).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_all, preds_all, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n============= Robustness Evaluation (Full Test Set) =============\")\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\")\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(labels_all, preds_all, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "\n",
    "# Flip statistics\n",
    "with torch.no_grad():\n",
    "    adv_sel_preds = logits_all[selected_nodes].argmax(dim=1).cpu().numpy()\n",
    "num_flips = int((orig_preds[selected_nodes] != adv_sel_preds).sum())\n",
    "print(f\"\\nSelected nodes: {len(selected_nodes)}. Flipped after attack: {num_flips} ({100.0*num_flips/len(selected_nodes):.2f}%).\")\n",
    "\n",
    "# ------------------------\n",
    "# Step 4: Compute Prediction Margin + FD relative error on perturbed nodes\n",
    "# ------------------------\n",
    "per_sample_info = []\n",
    "for node_idx in selected_nodes:\n",
    "    node_idx = int(node_idx)\n",
    "    with torch.no_grad():\n",
    "        logits = model(perturbed_X, A_t)[node_idx]\n",
    "    pred_class = logits.argmax().item()\n",
    "    pred_logit = logits[pred_class].item()\n",
    "    other_logits = logits.clone()\n",
    "    other_logits[pred_class] = -float('inf')\n",
    "    second_max = other_logits.max().item()\n",
    "    margin = pred_logit - second_max\n",
    "\n",
    "    # finite-difference perturbation check\n",
    "    delta = FD_EPS * torch.randn_like(perturbed_X[node_idx]).to(device)\n",
    "    X_mod = perturbed_X.clone().detach()\n",
    "    X_mod[node_idx] = perturbed_X[node_idx] + delta\n",
    "    with torch.no_grad():\n",
    "        logits_p = model(X_mod, A_t)[node_idx]\n",
    "    pred_logit_p = logits_p[pred_class].item()\n",
    "    other_logits_p = logits_p.clone()\n",
    "    other_logits_p[pred_class] = -float('inf')\n",
    "    second_max_p = other_logits_p.max().item()\n",
    "    margin_p = pred_logit_p - second_max_p\n",
    "\n",
    "    rel_err = abs(margin - margin_p) / (abs(margin_p) + 1e-12)\n",
    "    per_sample_info.append((node_idx, int(labels_np[node_idx]), float(margin), float(rel_err)))\n",
    "\n",
    "# aggregate stats\n",
    "clean_stats = [(i,m,e) for (i,lab,m,e) in per_sample_info if lab==0]\n",
    "troj_stats  = [(i,m,e) for (i,lab,m,e) in per_sample_info if lab==1]\n",
    "\n",
    "def aggs(stats):\n",
    "    Ms = np.array([s[1] for s in stats]); Es = np.array([s[2] for s in stats])\n",
    "    return (Ms.mean(), Ms.std(), Es.mean(), Es.std())\n",
    "\n",
    "cM_mean,cM_std,cE_mean,cE_std = aggs(clean_stats)\n",
    "tM_mean,tM_std,tE_mean,tE_std = aggs(troj_stats)\n",
    "\n",
    "print(\"\\n--- Prediction Margin Stats (on perturbed nodes) ---\")\n",
    "print(f\" Clean:  avg_margin={cM_mean:.4f} ± {cM_std:.4f}, avg_FDrel={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_margin={tM_mean:.4f} ± {tM_std:.4f}, avg_FDrel={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "print(\"\\nSample preview (first 6): (idx,label,margin,FD_rel_err)\")\n",
    "for p in per_sample_info[:6]:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfec60de-ebb8-4901-aea5-a21e3e3b0995",
   "metadata": {},
   "source": [
    "#### Adversarial Robustness Radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcb02a6a-1256-45fb-b9ca-c8e664003d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected nodes: clean=100, trojan=100\n",
      "Re-using existing perturbed_X from notebook.\n",
      "\n",
      "============= Robustness Evaluation (Full Test Set: perturbed selected nodes + others unperturbed) =============\n",
      "Accuracy: 100.00%\n",
      "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     1.0000    1.0000    1.0000      9159\n",
      "      trojan     1.0000    1.0000    1.0000     27556\n",
      "\n",
      "    accuracy                         1.0000     36715\n",
      "   macro avg     1.0000    1.0000    1.0000     36715\n",
      "weighted avg     1.0000    1.0000    1.0000     36715\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9159     0]\n",
      " [    0 27556]]\n",
      "\n",
      "Selected nodes: 200. Flipped after perturbation: 101 (50.50%).\n",
      "\n",
      "Computing Adversarial Robustness Radius for selected perturbed nodes (this is the expensive part)...\n",
      "  processed 20/200 nodes...\n",
      "  processed 40/200 nodes...\n",
      "  processed 60/200 nodes...\n",
      "  processed 80/200 nodes...\n",
      "  processed 100/200 nodes...\n",
      "  processed 120/200 nodes...\n",
      "  processed 140/200 nodes...\n",
      "  processed 160/200 nodes...\n",
      "  processed 180/200 nodes...\n",
      "  processed 200/200 nodes...\n",
      "Done ARR computation. Time elapsed: 13705.0s\n",
      "\n",
      "Class-wise ARR (with relative error):\n",
      "Class      Avg Radius ± Std   Avg Rel. Error ± Std\n",
      "----------------------------------------------------\n",
      "clean      10.0516 ± 4.8615      4.7839e-01 ± 4.0029e-01\n",
      "trojan      3.5416 ± 2.4110      4.9688e-01 ± 6.3460e-01\n",
      "\n",
      "Overall ARR: Avg Radius: 6.7966 ± 5.0318\n",
      "Overall ARR: Avg Relative Error: 4.8764e-01 ± 5.3062e-01\n"
     ]
    }
   ],
   "source": [
    "# === Adversarial Robustness Radius (ARR) - notebook-friendly, uses existing variables ===\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import time\n",
    "\n",
    "# ------------------ Safety / fallback checks ------------------\n",
    "# Required variables we expect from your prior runs\n",
    "required = [\"model\", \"X_t\", \"A_t\", \"y_t\", \"test_mask_t\", \"device\"]\n",
    "missing = [r for r in required if r not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Required variables missing from notebook environment: {missing}\\n\"\n",
    "                       \"Make sure you've executed the training/evaluation cells that define model, X_t, A_t, y_t, test_mask_t, device.\")\n",
    "\n",
    "# labels_np fallback\n",
    "if \"labels_np\" not in globals():\n",
    "    labels_np = y_t.cpu().numpy()\n",
    "else:\n",
    "    labels_np = globals()[\"labels_np\"]\n",
    "\n",
    "# Ensure test indices\n",
    "if isinstance(test_mask_t, torch.Tensor):\n",
    "    test_indices = np.where(test_mask_t.cpu().numpy())[0]\n",
    "else:\n",
    "    # if test_mask_t not boolean tensor but array\n",
    "    test_indices = np.where(np.array(test_mask_t))[0]\n",
    "\n",
    "# small helper\n",
    "to_device = lambda t: t.to(device) if isinstance(t, torch.Tensor) else t\n",
    "\n",
    "# ------------------ Sampling (ensure selected_nodes exists) ------------------\n",
    "PER_CLASS = 100\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "if \"selected_nodes\" in globals():\n",
    "    selected_nodes = np.array(globals()[\"selected_nodes\"], dtype=np.int64)\n",
    "else:\n",
    "    # pick 100 per class from test set (clean=0, trojan=1)\n",
    "    clean_idxs = [int(i) for i in test_indices if labels_np[int(i)] == 0]\n",
    "    trojan_idxs = [int(i) for i in test_indices if labels_np[int(i)] == 1]\n",
    "    sel_clean = rng.choice(clean_idxs, size=min(PER_CLASS, len(clean_idxs)), replace=False).tolist()\n",
    "    sel_trojan = rng.choice(trojan_idxs, size=min(PER_CLASS, len(trojan_idxs)), replace=False).tolist()\n",
    "    selected_nodes = np.array(sel_clean + sel_trojan, dtype=np.int64)\n",
    "\n",
    "print(f\"Selected nodes: clean={int((labels_np[selected_nodes]==0).sum())}, trojan={int((labels_np[selected_nodes]==1).sum())}\")\n",
    "\n",
    "# ------------------ Perturbed features (ensure perturbed_X exists) ------------------\n",
    "# If you already have perturbed_X from prior PGD, reuse it; otherwise construct PGD perturbations.\n",
    "EPSILON = globals().get(\"EPSILON\", 2.0)     # L2 radius used previously (match your PGD)\n",
    "ALPHA   = globals().get(\"ALPHA\", 0.4)       # step size used previously\n",
    "NUM_ITERS = globals().get(\"NUM_ITERS\", 15)  # PGD iters\n",
    "\n",
    "if \"perturbed_X\" in globals():\n",
    "    perturbed_X = globals()[\"perturbed_X\"].clone().detach().to(device)\n",
    "    print(\"Re-using existing perturbed_X from notebook.\")\n",
    "else:\n",
    "    print(\"No existing perturbed_X found  creating PGD perturbations (this may take some time)...\")\n",
    "    perturbed_X = X_t.clone().detach().to(device)\n",
    "    orig_preds = model(X_t, A_t).argmax(dim=1).cpu().numpy()\n",
    "    for node_idx in selected_nodes:\n",
    "        node_idx = int(node_idx)\n",
    "        x_orig = X_t[node_idx].detach().clone().to(device)\n",
    "        # initialize with random L2 perturbation on the whole feature vector\n",
    "        delta = torch.randn_like(x_orig).to(device)\n",
    "        delta = EPSILON * delta / (delta.norm() + 1e-12)\n",
    "        x_adv = (x_orig + delta).detach().clone().requires_grad_(True)\n",
    "\n",
    "        for it in range(NUM_ITERS):\n",
    "            X_mod = perturbed_X.clone().detach()\n",
    "            X_mod[node_idx] = x_adv\n",
    "            logits = model(X_mod, A_t)\n",
    "            loss = torch.nn.functional.cross_entropy(logits[node_idx].unsqueeze(0), y_t[node_idx].unsqueeze(0))\n",
    "            grad_x = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "            if grad_x.norm().item() == 0:\n",
    "                break\n",
    "            step = ALPHA * grad_x / (grad_x.norm() + 1e-12)\n",
    "            x_adv = (x_adv + step).detach()\n",
    "            delta = x_adv - x_orig\n",
    "            dnorm = delta.norm().item()\n",
    "            if dnorm > EPSILON:\n",
    "                delta = delta * (EPSILON / (dnorm + 1e-12))\n",
    "                x_adv = (x_orig + delta).detach()\n",
    "            x_adv = x_adv.requires_grad_(True)\n",
    "\n",
    "        perturbed_X[node_idx] = x_adv.detach()\n",
    "    print(\"Finished creating perturbed_X via PGD.\")\n",
    "\n",
    "# ------------------ Evaluate model on full test set (200 perturbed + rest original) ------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_all = model(perturbed_X, A_t)\n",
    "    preds_all = logits_all[test_indices].argmax(dim=1).cpu().numpy()\n",
    "    labels_all = labels_np[test_indices]\n",
    "\n",
    "acc = (preds_all == labels_all).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_all, preds_all, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n============= Robustness Evaluation (Full Test Set: perturbed selected nodes + others unperturbed) =============\")\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(labels_all, preds_all, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "\n",
    "# Flip statistics for selected nodes\n",
    "with torch.no_grad():\n",
    "    orig_preds = model(X_t.to(device), A_t).argmax(dim=1).cpu().numpy()\n",
    "    adv_sel_preds = logits_all[selected_nodes].argmax(dim=1).cpu().numpy()\n",
    "num_flips = int((orig_preds[selected_nodes] != adv_sel_preds).sum())\n",
    "print(f\"\\nSelected nodes: {len(selected_nodes)}. Flipped after perturbation: {num_flips} ({100.0 * num_flips/len(selected_nodes):.2f}%).\")\n",
    "\n",
    "# ------------------ ARR computation helpers (operate on perturbed_X!) ------------------\n",
    "def f_for_sample(x_tensor, test_idx):\n",
    "    \"\"\"Return logits vector for node test_idx when its features are replaced by x_tensor.\n",
    "       Uses adjacency A_t and perturbed_X baseline to preserve the same graph context.\"\"\"\n",
    "    X_mod = perturbed_X.clone().detach()\n",
    "    X_mod[test_idx] = x_tensor\n",
    "    with torch.no_grad():\n",
    "        out = model(X_mod, A_t)\n",
    "    return out[test_idx]\n",
    "\n",
    "def adversarial_radius_for_sample(test_idx, initial_epsilon=1e-3, growth_factor=1.25,\n",
    "                                  max_epsilon=20.0, bs_iters=10, num_trials=8):\n",
    "    \"\"\"Estimate minimal perturbation norm (L2) that flips the model prediction,\n",
    "       measured *around the perturbed point* (perturbed_X).\"\"\"\n",
    "    x0 = perturbed_X[test_idx].clone().detach().to(device)\n",
    "    # base predicted label at this perturbed point\n",
    "    with torch.no_grad():\n",
    "        base_out = model(perturbed_X, A_t)\n",
    "        y0 = int(torch.argmax(base_out[test_idx]).item())\n",
    "\n",
    "    def is_same(x):\n",
    "        out = f_for_sample(x, test_idx)\n",
    "        return int(torch.argmax(out).item()) == y0\n",
    "\n",
    "    radii = []\n",
    "    for _ in range(num_trials):\n",
    "        d = torch.randn_like(x0)\n",
    "        d = d / (d.norm() + 1e-12)\n",
    "\n",
    "        eps = initial_epsilon\n",
    "        # expand until flip or cap\n",
    "        while eps < max_epsilon and is_same(x0 + eps * d):\n",
    "            eps *= growth_factor\n",
    "\n",
    "        if eps >= max_epsilon:\n",
    "            candidate = max_epsilon\n",
    "        else:\n",
    "            low, high = eps / growth_factor, eps\n",
    "            for _ in range(bs_iters):\n",
    "                mid = 0.5 * (low + high)\n",
    "                if is_same(x0 + mid * d):\n",
    "                    low = mid\n",
    "                else:\n",
    "                    high = mid\n",
    "            candidate = float(high)\n",
    "        radii.append(candidate)\n",
    "\n",
    "    return float(min(radii))\n",
    "\n",
    "def adversarial_radius_relerr(test_idx):\n",
    "    r1 = adversarial_radius_for_sample(test_idx, growth_factor=1.25, bs_iters=10, num_trials=6)\n",
    "    r2 = adversarial_radius_for_sample(test_idx, growth_factor=1.4, bs_iters=12, num_trials=6)\n",
    "    rel_err = abs(r1 - r2) / (abs(r2) + 1e-12)\n",
    "    return r1, rel_err\n",
    "\n",
    "# ------------------ Compute ARR on selected perturbed nodes ------------------\n",
    "class_names = ['clean', 'trojan']\n",
    "class_adv_radius = {cn: [] for cn in class_names}\n",
    "class_rel_errors = {cn: [] for cn in class_names}\n",
    "all_radii, all_rel_errs = [], []\n",
    "\n",
    "t0 = time.time()\n",
    "print(\"\\nComputing Adversarial Robustness Radius for selected perturbed nodes (this is the expensive part)...\")\n",
    "for i, node_idx in enumerate(selected_nodes):\n",
    "    node_idx = int(node_idx)\n",
    "    label = int(labels_np[node_idx])\n",
    "    cn = class_names[label]\n",
    "    r, rel = adversarial_radius_relerr(node_idx)\n",
    "    class_adv_radius[cn].append(r)\n",
    "    class_rel_errors[cn].append(rel)\n",
    "    all_radii.append(r)\n",
    "    all_rel_errs.append(rel)\n",
    "    if (i+1) % 20 == 0:\n",
    "        print(f\"  processed {i+1}/{len(selected_nodes)} nodes...\")\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"Done ARR computation. Time elapsed: {t1-t0:.1f}s\")\n",
    "\n",
    "# ------------------ Reporting ARR aggregates ------------------\n",
    "print(\"\\nClass-wise ARR (with relative error):\")\n",
    "print(\"{:<10s} {:>14s} {:>22s}\".format(\"Class\", \"Avg Radius ± Std\", \"Avg Rel. Error ± Std\"))\n",
    "print(\"-\"*52)\n",
    "for cn in class_names:\n",
    "    if class_adv_radius[cn]:\n",
    "        print(\"{:<10s} {:>7.4f} ± {:<7.4f} {:>14.4e} ± {:<10.4e}\".format(\n",
    "            cn, np.mean(class_adv_radius[cn]), np.std(class_adv_radius[cn]),\n",
    "            np.mean(class_rel_errors[cn]), np.std(class_rel_errors[cn])\n",
    "        ))\n",
    "    else:\n",
    "        print(\"{:<10s} {:>10s}\".format(cn, \"-\"))\n",
    "\n",
    "print(\"\\nOverall ARR: Avg Radius: {:.4f} ± {:.4f}\".format(np.mean(all_radii), np.std(all_radii)))\n",
    "print(\"Overall ARR: Avg Relative Error: {:.4e} ± {:.4e}\".format(np.mean(all_rel_errs), np.std(all_rel_errs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebc1083-1114-4b28-8ce9-5cca95ed3720",
   "metadata": {},
   "source": [
    "#### Stability Under Input Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14feaa61-e461-4c10-a13a-57fd17a6c3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Stability Under Input Noise (PGD-first, then metric) ---\n",
      "Selected nodes ? clean=100, trojan=100\n",
      "? Finished perturbations.\n",
      "\n",
      "============= Robustness Evaluation (Full Test Set) =============\n",
      "Accuracy: 100.00%\n",
      "Precision: 1.0000, Recall: 1.0000, F1: 1.0000\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     1.0000    1.0000    1.0000      9159\n",
      "      trojan     1.0000    1.0000    1.0000     27556\n",
      "\n",
      "    accuracy                         1.0000     36715\n",
      "   macro avg     1.0000    1.0000    1.0000     36715\n",
      "weighted avg     1.0000    1.0000    1.0000     36715\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9159     0]\n",
      " [    0 27556]]\n",
      "\n",
      "Selected nodes: 200. Flipped after attack: 101 (50.50%).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 152\u001b[0m\n\u001b[1;32m    149\u001b[0m     Es \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([e \u001b[38;5;28;01mfor\u001b[39;00m (_,_,_,e) \u001b[38;5;129;01min\u001b[39;00m [(i,lab,s,e) \u001b[38;5;28;01mfor\u001b[39;00m (i,lab,s,e) \u001b[38;5;129;01min\u001b[39;00m stats]])\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (Ss\u001b[38;5;241m.\u001b[39mmean(), Ss\u001b[38;5;241m.\u001b[39mstd(), Es\u001b[38;5;241m.\u001b[39mmean(), Es\u001b[38;5;241m.\u001b[39mstd())\n\u001b[0;32m--> 152\u001b[0m cS_mean, cS_std, cE_mean, cE_std \u001b[38;5;241m=\u001b[39m \u001b[43maggs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m tS_mean, tS_std, tE_mean, tE_std \u001b[38;5;241m=\u001b[39m aggs(troj_stats)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Stability Under Input Noise (on perturbed nodes) ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 148\u001b[0m, in \u001b[0;36maggs\u001b[0;34m(stats)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21maggs\u001b[39m(stats):\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stats: \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m--> 148\u001b[0m     Ss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([s \u001b[38;5;28;01mfor\u001b[39;00m (_,_,s,_) \u001b[38;5;129;01min\u001b[39;00m [(i,lab,s,e) \u001b[38;5;28;01mfor\u001b[39;00m (i,lab,s,e) \u001b[38;5;129;01min\u001b[39;00m stats]])\n\u001b[1;32m    149\u001b[0m     Es \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([e \u001b[38;5;28;01mfor\u001b[39;00m (_,_,_,e) \u001b[38;5;129;01min\u001b[39;00m [(i,lab,s,e) \u001b[38;5;28;01mfor\u001b[39;00m (i,lab,s,e) \u001b[38;5;129;01min\u001b[39;00m stats]])\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (Ss\u001b[38;5;241m.\u001b[39mmean(), Ss\u001b[38;5;241m.\u001b[39mstd(), Es\u001b[38;5;241m.\u001b[39mmean(), Es\u001b[38;5;241m.\u001b[39mstd())\n",
      "Cell \u001b[0;32mIn[12], line 148\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21maggs\u001b[39m(stats):\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stats: \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m--> 148\u001b[0m     Ss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([s \u001b[38;5;28;01mfor\u001b[39;00m (_,_,s,_) \u001b[38;5;129;01min\u001b[39;00m [(i,lab,s,e) \u001b[38;5;28;01mfor\u001b[39;00m (i,lab,s,e) \u001b[38;5;129;01min\u001b[39;00m stats]])\n\u001b[1;32m    149\u001b[0m     Es \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([e \u001b[38;5;28;01mfor\u001b[39;00m (_,_,_,e) \u001b[38;5;129;01min\u001b[39;00m [(i,lab,s,e) \u001b[38;5;28;01mfor\u001b[39;00m (i,lab,s,e) \u001b[38;5;129;01min\u001b[39;00m stats]])\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (Ss\u001b[38;5;241m.\u001b[39mmean(), Ss\u001b[38;5;241m.\u001b[39mstd(), Es\u001b[38;5;241m.\u001b[39mmean(), Es\u001b[38;5;241m.\u001b[39mstd())\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# ========================\n",
    "# Parameters\n",
    "# ========================\n",
    "# PGD (to create the evaluation perturbations)\n",
    "EPSILON     = 2.0     # L2 budget\n",
    "ALPHA       = 0.4     # step size\n",
    "NUM_ITERS   = 15      # iterations\n",
    "\n",
    "# Stability metric (computed AFTER perturbations, around the perturbed point)\n",
    "NOISE_SIGMA        = 0.05   # Gaussian noise stddev for stability metric\n",
    "NUM_NOISE_SAMPLES  = 20     # Monte Carlo samples per node\n",
    "RELERR_RESAMPLES   = 5      # re-estimate stability this many times for relative error\n",
    "\n",
    "# ========================\n",
    "# Step 1: Select nodes (100 clean, 100 trojan)\n",
    "# ========================\n",
    "clean_nodes  = np.where(labels_np == 0)[0]\n",
    "trojan_nodes = np.where(labels_np == 1)[0]\n",
    "np.random.seed(42)\n",
    "sel_clean   = np.random.choice(clean_nodes,  100, replace=False)\n",
    "sel_trojan  = np.random.choice(trojan_nodes, 100, replace=False)\n",
    "selected_nodes = np.concatenate([sel_clean, sel_trojan])\n",
    "\n",
    "print(\"\\n--- Stability Under Input Noise (PGD-first, then metric) ---\")\n",
    "print(f\"Selected nodes ? clean={len(sel_clean)}, trojan={len(sel_trojan)}\")\n",
    "\n",
    "# ========================\n",
    "# Step 2: Apply perturbation (PGD on ALL features of selected nodes)\n",
    "# ========================\n",
    "perturbed_X = X_t.clone().detach().to(device)\n",
    "with torch.no_grad():\n",
    "    orig_preds = model(X_t, A_t).argmax(dim=1).cpu().numpy()\n",
    "\n",
    "for node_idx in selected_nodes:\n",
    "    node_idx = int(node_idx)\n",
    "    x_orig = X_t[node_idx].detach().clone().to(device)\n",
    "\n",
    "    # random init within L2-ball\n",
    "    delta = torch.randn_like(x_orig).to(device)\n",
    "    delta = EPSILON * delta / (delta.norm() + 1e-12)\n",
    "    x_adv = (x_orig + delta).detach().clone().requires_grad_(True)\n",
    "\n",
    "    for _ in range(NUM_ITERS):\n",
    "        X_mod = perturbed_X.clone().detach()\n",
    "        X_mod[node_idx] = x_adv\n",
    "        logits = model(X_mod, A_t)\n",
    "        loss = F.cross_entropy(logits[node_idx].unsqueeze(0), y_t[node_idx].unsqueeze(0))\n",
    "\n",
    "        grad_x = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "        step = ALPHA * grad_x / (grad_x.norm() + 1e-12)\n",
    "        x_adv = (x_adv + step).detach()\n",
    "\n",
    "        # project back to L2 ball\n",
    "        delta = x_adv - x_orig\n",
    "        dnorm = delta.norm()\n",
    "        if dnorm > EPSILON:\n",
    "            delta = delta * (EPSILON / (dnorm + 1e-12))\n",
    "            x_adv = (x_orig + delta).detach()\n",
    "        x_adv = x_adv.requires_grad_(True)\n",
    "\n",
    "    perturbed_X[node_idx] = x_adv.detach()\n",
    "\n",
    "print(\"? Finished perturbations.\")\n",
    "\n",
    "# ========================\n",
    "# Step 3: Robustness evaluation on FULL test set (200 perturbed + rest original)\n",
    "# ========================\n",
    "test_indices = np.where(test_mask_t.cpu().numpy())[0]\n",
    "with torch.no_grad():\n",
    "    logits_all = model(perturbed_X, A_t)\n",
    "    preds_all  = logits_all[test_indices].argmax(dim=1).cpu().numpy()\n",
    "    labels_all = labels_np[test_indices]\n",
    "\n",
    "acc = (preds_all == labels_all).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_all, preds_all, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n============= Robustness Evaluation (Full Test Set) =============\")\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(labels_all, preds_all, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "\n",
    "# Flip statistics on selected nodes only (for quick sanity)\n",
    "with torch.no_grad():\n",
    "    adv_sel_preds = logits_all[selected_nodes].argmax(dim=1).cpu().numpy()\n",
    "num_flips = int((orig_preds[selected_nodes] != adv_sel_preds).sum())\n",
    "print(f\"\\nSelected nodes: {len(selected_nodes)}. Flipped after attack: {num_flips} ({100.0*num_flips/len(selected_nodes):.2f}%).\")\n",
    "\n",
    "# ========================\n",
    "# Step 4: Stability Under Input Noise (computed AFTER perturbations)\n",
    "#         Measures avg L2 change in logits when adding Gaussian noise\n",
    "#         around the perturbed feature vector.\n",
    "# ========================\n",
    "def stability_for_node(node_idx, sigma, num_samples):\n",
    "    \"\"\"\n",
    "    Average L2 change in logits between (perturbed_X baseline) and\n",
    "    noisy versions (perturbed_X + noise) for this node.\n",
    "    \"\"\"\n",
    "    node_idx = int(node_idx)\n",
    "    with torch.no_grad():\n",
    "        f_orig = logits_all[node_idx]  # baseline logits at the perturbed point (already computed)\n",
    "\n",
    "    diffs = []\n",
    "    for _ in range(num_samples):\n",
    "        noise = sigma * torch.randn_like(perturbed_X[node_idx]).to(device)\n",
    "        X_mod = perturbed_X.clone().detach()\n",
    "        X_mod[node_idx] = perturbed_X[node_idx] + noise\n",
    "        with torch.no_grad():\n",
    "            f_noisy = model(X_mod, A_t)[node_idx]\n",
    "        diffs.append(torch.norm(f_noisy - f_orig).item())\n",
    "    return float(np.mean(diffs))\n",
    "\n",
    "# Compute stability and relative error on perturbed nodes\n",
    "per_sample_info = []  # (idx, label, stability, rel_err)\n",
    "for node_idx in selected_nodes:\n",
    "    s_val = stability_for_node(node_idx, NOISE_SIGMA, NUM_NOISE_SAMPLES)\n",
    "    # relative error: re-estimate a few times and compare\n",
    "    re_vals = [stability_for_node(node_idx, NOISE_SIGMA, NUM_NOISE_SAMPLES) for _ in range(RELERR_RESAMPLES)]\n",
    "    s_ref = float(np.mean(re_vals))\n",
    "    rel_err = abs(s_val - s_ref) / (abs(s_ref) + 1e-12)\n",
    "    per_sample_info.append((int(node_idx), int(labels_np[int(node_idx)]), float(s_val), float(rel_err)))\n",
    "\n",
    "# ========================\n",
    "# Step 5: Aggregate and report metric stats\n",
    "# ========================\n",
    "clean_stats = [(i,s,e) for (i,lab,s,e) in per_sample_info if lab==0]\n",
    "troj_stats  = [(i,s,e) for (i,lab,s,e) in per_sample_info if lab==1]\n",
    "\n",
    "def aggs(stats):\n",
    "    if not stats: return (0.0,0.0,0.0,0.0)\n",
    "    Ss = np.array([s for (_,s,_) in [(i,v,e) for (i,v,e) in [(i,s,e) for (i,_,s,e) in stats]]])  # robust indexing\n",
    "    Es = np.array([e for (_,_,e) in stats])\n",
    "    # The above line is overly defensive; simpler:\n",
    "    Ss = np.array([s for (_,s,_) in [(i,s,e) for (i,_,s,e) in stats]])\n",
    "    Es = np.array([e for (_,_,e) in [(i,s,e) for (i,_,s,e) in stats]])\n",
    "    return (Ss.mean(), Ss.std(), Es.mean(), Es.std())\n",
    "\n",
    "# (Fix the helper to be clean & simple)\n",
    "def aggs(stats):\n",
    "    if not stats: return (0.0,0.0,0.0,0.0)\n",
    "    Ss = np.array([s for (_,_,s,_) in [(i,lab,s,e) for (i,lab,s,e) in stats]])\n",
    "    Es = np.array([e for (_,_,_,e) in [(i,lab,s,e) for (i,lab,s,e) in stats]])\n",
    "    return (Ss.mean(), Ss.std(), Es.mean(), Es.std())\n",
    "\n",
    "cS_mean, cS_std, cE_mean, cE_std = aggs(clean_stats)\n",
    "tS_mean, tS_std, tE_mean, tE_std = aggs(troj_stats)\n",
    "\n",
    "print(\"\\n--- Stability Under Input Noise (on perturbed nodes) ---\")\n",
    "print(f\" Clean:  avg_stability={cS_mean:.4f} ± {cS_std:.4f}, avg_relerr={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_stability={tS_mean:.4f} ± {tS_std:.4f}, avg_relerr={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "\n",
    "print(\"\\nSample preview (first 6): (idx,label,stability,rel_err)\")\n",
    "for p in per_sample_info[:6]:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84ea3dc2-1636-4f01-93cb-25ffae08df1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Stability Under Input Noise (on perturbed nodes) ---\n",
      " Clean:  avg_stability=0.0257 ± 0.0095, avg_relerr=1.6208e-01 ± 1.1808e-01\n",
      " Trojan: avg_stability=0.1172 ± 0.0236, avg_relerr=1.3512e-01 ± 9.6998e-02\n",
      "\n",
      "Sample preview (first 6): (idx,stability,rel_err)\n",
      "(44087, 0, 0.015042922904831358, 0.04401712210750706)\n",
      "(1246, 0, 0.022505388408899308, 0.2220340311144904)\n",
      "(55526, 0, 0.02417376406956464, 0.22841417608479572)\n",
      "(3698, 0, 0.021043947315774858, 0.03313790320565221)\n",
      "(23454, 0, 0.02797463204478845, 0.12765440160094868)\n",
      "(58015, 0, 0.03421499626711011, 0.27192676340429556)\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# Step 5: Aggregate and report metric stats (FIXED for 3-tuples)\n",
    "# ========================\n",
    "def aggs(stats):\n",
    "    if not stats:\n",
    "        return (0.0, 0.0, 0.0)\n",
    "    Ss = np.array([s for (_, s, _) in stats])  # stability values\n",
    "    Es = np.array([e for (_, _, e) in stats])  # relative errors\n",
    "    return (Ss.mean(), Ss.std(), Es.mean(), Es.std())\n",
    "\n",
    "cS_mean, cS_std, cE_mean, cE_std = aggs(clean_stats)\n",
    "tS_mean, tS_std, tE_mean, tE_std = aggs(troj_stats)\n",
    "\n",
    "print(\"\\n--- Stability Under Input Noise (on perturbed nodes) ---\")\n",
    "print(f\" Clean:  avg_stability={cS_mean:.4f} ± {cS_std:.4f}, avg_relerr={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_stability={tS_mean:.4f} ± {tS_std:.4f}, avg_relerr={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "\n",
    "print(\"\\nSample preview (first 6): (idx,stability,rel_err)\")\n",
    "for p in per_sample_info[:6]:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b571002-c20a-4301-a767-12b55a6c8702",
   "metadata": {},
   "source": [
    "#### All in One, same perturbation across all metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56d886d3-d80d-4bbe-92a1-55d52eaf644b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected: clean=100, trojan=100\n",
      "? Shared PGD perturbations done.\n",
      "\n",
      "Jacobian Sensitivity:\n",
      " Class 0: norm=0.5691±0.2002, relerr=1.9832e-03±8.1588e-03\n",
      " Class 1: norm=2.3851±0.2951, relerr=5.6784e-04±7.1576e-04\n",
      "\n",
      "=== Robustness Eval (Jacobian) ===\n",
      "Accuracy=99.54 | Precision=0.9954 | Recall=0.9954 | F1=0.9954\n",
      "Confusion Matrix:\n",
      "[[ 9091    68]\n",
      " [  100 27456]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.9891    0.9926    0.9908      9159\n",
      "      trojan     0.9975    0.9964    0.9969     27556\n",
      "\n",
      "    accuracy                         0.9954     36715\n",
      "   macro avg     0.9933    0.9945    0.9939     36715\n",
      "weighted avg     0.9954    0.9954    0.9954     36715\n",
      "\n",
      "Flipped 168/200 (84.00%)\n",
      "\n",
      "Lipschitz Constant:\n",
      " Class 0: L=0.5544±0.1906, relerr=4.6020e-03±2.2572e-02\n",
      " Class 1: L=2.3476±0.3050, relerr=5.8848e-03±4.3060e-02\n",
      "\n",
      "=== Robustness Eval (Lipschitz) ===\n",
      "Accuracy=99.54 | Precision=0.9954 | Recall=0.9954 | F1=0.9954\n",
      "Confusion Matrix:\n",
      "[[ 9091    68]\n",
      " [  100 27456]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.9891    0.9926    0.9908      9159\n",
      "      trojan     0.9975    0.9964    0.9969     27556\n",
      "\n",
      "    accuracy                         0.9954     36715\n",
      "   macro avg     0.9933    0.9945    0.9939     36715\n",
      "weighted avg     0.9954    0.9954    0.9954     36715\n",
      "\n",
      "Flipped 168/200 (84.00%)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 146\u001b[0m\n\u001b[1;32m    144\u001b[0m pred_class \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    145\u001b[0m logp \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 146\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpred_class\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    147\u001b[0m lambda_max \u001b[38;5;241m=\u001b[39m (g\u001b[38;5;241m.\u001b[39mnorm()\u001b[38;5;241m.\u001b[39mitem())\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    148\u001b[0m delta \u001b[38;5;241m=\u001b[39m FD_EPS\u001b[38;5;241m*\u001b[39mtorch\u001b[38;5;241m.\u001b[39mrandn_like(x0)\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch/autograd/__init__.py:496\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    492\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    493\u001b[0m         grad_outputs_\n\u001b[1;32m    494\u001b[0m     )\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    507\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    508\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    509\u001b[0m     ):\n",
      "File \u001b[0;32m~/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior."
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Unified Robustness Evaluation\n",
    "# ================================\n",
    "import torch, numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# ---------------- Parameters ----------------\n",
    "PER_CLASS = 100\n",
    "EPSILON   = 5.0     # L2 budget for PGD\n",
    "ALPHA     = 1.0     # PGD step size\n",
    "NUM_ITERS = 40      # PGD iterations\n",
    "FD_EPS    = 1e-3    # finite-difference epsilon\n",
    "SEED      = 42\n",
    "\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "required_vars = [\"model\",\"X_t\",\"A_t\",\"y_t\",\"test_mask_t\",\"device\"]\n",
    "for v in required_vars:\n",
    "    if v not in globals():\n",
    "        raise RuntimeError(f\"Required var '{v}' not found.\")\n",
    "\n",
    "model.to(device); model.eval()\n",
    "labels_np = y_t.cpu().numpy()\n",
    "\n",
    "# ---------------- Node Selection ----------------\n",
    "test_indices = np.where(test_mask_t.cpu().numpy())[0]\n",
    "rng = np.random.default_rng(SEED)\n",
    "selected_nodes = []\n",
    "for cls in [0,1]:\n",
    "    idxs = [int(i) for i in test_indices if labels_np[i]==cls]\n",
    "    chosen = rng.choice(idxs, size=min(PER_CLASS, len(idxs)), replace=False)\n",
    "    selected_nodes.extend(chosen)\n",
    "selected_nodes = np.array(selected_nodes, dtype=np.int64)\n",
    "\n",
    "print(f\"Selected: clean={int((labels_np[selected_nodes]==0).sum())}, \"\n",
    "      f\"trojan={int((labels_np[selected_nodes]==1).sum())}\")\n",
    "\n",
    "# ---------------- Shared PGD Perturbations ----------------\n",
    "perturbed_X = X_t.clone().detach().to(device)\n",
    "for node_idx in selected_nodes:\n",
    "    node_idx = int(node_idx)\n",
    "    x_orig = X_t[node_idx].detach().clone().to(device)\n",
    "    x_adv = (x_orig + 1e-3*torch.randn_like(x_orig)).detach().requires_grad_(True)\n",
    "\n",
    "    for _ in range(NUM_ITERS):\n",
    "        X_mod = perturbed_X.clone().detach()\n",
    "        X_mod[node_idx] = x_adv\n",
    "        logits = model(X_mod, A_t)\n",
    "        loss = F.cross_entropy(logits[node_idx].unsqueeze(0), y_t[node_idx].unsqueeze(0))\n",
    "        grad_x = torch.autograd.grad(loss, x_adv)[0]\n",
    "        if grad_x.norm().item()==0: break\n",
    "        step = ALPHA * grad_x / (grad_x.norm() + 1e-12)\n",
    "        x_adv = (x_adv + step).detach()\n",
    "        delta = x_adv - x_orig\n",
    "        if delta.norm() > EPSILON:\n",
    "            delta = delta * (EPSILON/(delta.norm()+1e-12))\n",
    "            x_adv = (x_orig + delta).detach()\n",
    "        x_adv = x_adv.requires_grad_(True)\n",
    "    perturbed_X[node_idx] = x_adv.detach()\n",
    "print(\"? Shared PGD perturbations done.\")\n",
    "\n",
    "# ---------------- Eval Helper ----------------\n",
    "def evaluate_model(name, perturbed_X, selected_nodes):\n",
    "    test_idx = np.where(test_mask_t.cpu().numpy())[0]\n",
    "    with torch.no_grad():\n",
    "        logits_all = model(perturbed_X, A_t)\n",
    "        preds_all = logits_all[test_idx].argmax(dim=1).cpu().numpy()\n",
    "        labels_all = labels_np[test_idx]\n",
    "\n",
    "    acc = (preds_all == labels_all).mean()\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        labels_all, preds_all, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    print(f\"\\n=== Robustness Eval ({name}) ===\")\n",
    "    print(f\"Accuracy={acc*100:.2f} | Precision={prec:.4f} | Recall={rec:.4f} | F1={f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(labels_all, preds_all, target_names=[\"clean\",\"trojan\"], digits=4))\n",
    "\n",
    "    # Flip stats on selected only\n",
    "    with torch.no_grad():\n",
    "        orig_preds = model(X_t, A_t).argmax(dim=1).cpu().numpy()\n",
    "        adv_preds  = logits_all[selected_nodes].argmax(dim=1).cpu().numpy()\n",
    "    flips = (orig_preds[selected_nodes] != adv_preds).sum()\n",
    "    print(f\"Flipped {flips}/{len(selected_nodes)} ({100*flips/len(selected_nodes):.2f}%)\")\n",
    "    return logits_all\n",
    "\n",
    "# ---------------- Metric 1: Jacobian Sensitivity ----------------\n",
    "jac_info = []\n",
    "for node_idx in selected_nodes:\n",
    "    x0 = perturbed_X[node_idx].detach().clone().requires_grad_(True)\n",
    "    def f_local(x):\n",
    "        X_mod = perturbed_X.clone().detach()\n",
    "        X_mod[node_idx] = x\n",
    "        return model(X_mod, A_t)[node_idx]\n",
    "    J = torch.autograd.functional.jacobian(f_local, x0)\n",
    "    jac_norm = torch.norm(J, p='fro').item()\n",
    "    delta_fd = FD_EPS * torch.randn_like(x0)\n",
    "    pred_change = J.mv(delta_fd)\n",
    "    f0, f0p = f_local(x0).detach(), f_local(x0+delta_fd).detach()\n",
    "    actual_change = f0p - f0\n",
    "    rel_err = (torch.norm(pred_change-actual_change)/(torch.norm(actual_change)+1e-8)).item()\n",
    "    jac_info.append((int(labels_np[node_idx]), jac_norm, rel_err))\n",
    "print(\"\\nJacobian Sensitivity:\")\n",
    "for cls in [0,1]:\n",
    "    vals = [j[1] for j in jac_info if j[0]==cls]\n",
    "    errs = [j[2] for j in jac_info if j[0]==cls]\n",
    "    print(f\" Class {cls}: norm={np.mean(vals):.4f}±{np.std(vals):.4f}, relerr={np.mean(errs):.4e}±{np.std(errs):.4e}\")\n",
    "\n",
    "evaluate_model(\"Jacobian\", perturbed_X, selected_nodes)\n",
    "\n",
    "# ---------------- Metric 2: Lipschitz (Spectral Norm) ----------------\n",
    "lip_info = []\n",
    "for node_idx in selected_nodes:\n",
    "    x0 = perturbed_X[node_idx].detach().clone().requires_grad_(True)\n",
    "    def f_node(x):\n",
    "        X_mod = perturbed_X.clone().detach()\n",
    "        X_mod[node_idx] = x\n",
    "        return model(X_mod, A_t)[node_idx]\n",
    "    J = torch.autograd.functional.jacobian(f_node, x0).detach()\n",
    "    U, S, Vh = torch.linalg.svd(J, full_matrices=False)\n",
    "    sigma_max = S[0].item()\n",
    "    delta_fd = FD_EPS*torch.randn_like(x0)\n",
    "    pred_change = J.mv(delta_fd)\n",
    "    f0, f0p = f_node(x0).detach(), f_node(x0+delta_fd).detach()\n",
    "    actual_change = f0p-f0\n",
    "    rel_err = (torch.norm(pred_change-actual_change)/(torch.norm(actual_change)+1e-8)).item()\n",
    "    lip_info.append((int(labels_np[node_idx]), sigma_max, rel_err))\n",
    "print(\"\\nLipschitz Constant:\")\n",
    "for cls in [0,1]:\n",
    "    vals = [j[1] for j in lip_info if j[0]==cls]\n",
    "    errs = [j[2] for j in lip_info if j[0]==cls]\n",
    "    print(f\" Class {cls}: L={np.mean(vals):.4f}±{np.std(vals):.4f}, relerr={np.mean(errs):.4e}±{np.std(errs):.4e}\")\n",
    "\n",
    "evaluate_model(\"Lipschitz\", perturbed_X, selected_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe04ca3-b97e-4d31-932a-1a1e7f1c8571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing Hessian curvature proxy for selected nodes...\n",
      "\n",
      "Aggregated Hessian curvature stats:\n",
      " Clean:  avg_lambda=0.0010 ± 0.0027, avg_FDrel=8.8466e-01 ± 8.1834e-02\n",
      " Trojan: avg_lambda=0.0142 ± 0.0433, avg_FDrel=9.8816e-01 ± 7.6240e-02\n",
      "\n",
      "Sample preview (first 6): (idx,label,lambda,FD_rel_err)\n",
      "(26119, 0, 0.00013120630157356997, 0.9184905936223066)\n",
      "(57231, 0, 0.00010541675260007741, 0.9369352447942576)\n",
      "(40297, 0, 0.001319116215862129, 0.8764956242259994)\n",
      "(27843, 0, 0.0007114012510761741, 0.8963298585350504)\n",
      "(26863, 0, 0.0005749628200755197, 0.8580783213599984)\n",
      "(46828, 0, 0.0004019299185979014, 0.8816316362759506)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Hessian-Based Curvature (grad outer-product) for node-level Trojan detection\n",
    "# =========================\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# -------------------- Parameters --------------------\n",
    "PER_CLASS = 100          # 100 nodes per class (clean/trojan)\n",
    "FD_EPS = 5e-3            # finite-diff epsilon for relative-error check\n",
    "TRIALS_PER_NODE = 10     # average trials per node for relative error\n",
    "PERT_P = 6.0             # L2 magnitude for final Hessian-aligned perturbation (tuneable)\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# -------------------- Class names --------------------\n",
    "class_names = [\"clean\", \"trojan\"]\n",
    "\n",
    "\n",
    "# -------------------- Helper: compute g(x) --------------------\n",
    "def compute_gradient(node_idx):\n",
    "    \"\"\"\n",
    "    Returns gradient g = ?_x log p(y_hat|x) at node_idx.\n",
    "    \"\"\"\n",
    "    x0 = X_t[node_idx].detach().clone().to(device).requires_grad_(True)\n",
    "\n",
    "    # Forward pass with x0 replacing features of node_idx\n",
    "    X_mod = X_t.clone().detach().to(device)\n",
    "    X_mod[node_idx] = x0\n",
    "    logits = model(X_mod, A_t)[node_idx]\n",
    "\n",
    "    # Use predicted class\n",
    "    pred_class = logits.argmax().item()\n",
    "    logp = F.log_softmax(logits, dim=0)\n",
    "    loss = logp[pred_class]\n",
    "\n",
    "    g = torch.autograd.grad(loss, x0, retain_graph=False, create_graph=False, allow_unused=False)[0]\n",
    "    return x0.detach(), g.detach(), pred_class\n",
    "\n",
    "# -------------------- Storage --------------------\n",
    "per_sample_info = []   # (node_idx, label, lambda_max, avg_rel_error)\n",
    "\n",
    "print(\"\\nComputing Hessian curvature proxy for selected nodes...\")\n",
    "\n",
    "for node_idx in selected_nodes:\n",
    "    node_idx = int(node_idx)\n",
    "    label = int(labels_np[node_idx])\n",
    "\n",
    "    x0, g, pred_class = compute_gradient(node_idx)\n",
    "    if g is None:\n",
    "        lambda_max = 0.0\n",
    "        avg_rel_err = 0.0\n",
    "    else:\n",
    "        # curvature proxy = ||g||^2\n",
    "        lambda_max = float(g.norm(p=2).item() ** 2)\n",
    "\n",
    "        # relative error by finite-difference\n",
    "        rel_errs = []\n",
    "        for _ in range(TRIALS_PER_NODE):\n",
    "            delta = FD_EPS * torch.randn_like(x0).to(device)\n",
    "            gt_delta = torch.dot(g, delta).item()\n",
    "            pred_second = 0.5 * (gt_delta ** 2)\n",
    "\n",
    "            # recompute logits at perturbed input\n",
    "            X_mod = X_t.clone().detach().to(device)\n",
    "            X_mod[node_idx] = x0 + delta\n",
    "            logits_p = model(X_mod, A_t)[node_idx]\n",
    "            logp_p = F.log_softmax(logits_p, dim=0)\n",
    "            actual_second = float((logp_p[pred_class] - F.log_softmax(model(X_t, A_t)[node_idx], dim=0)[pred_class]).item() - torch.dot(g, delta).item())\n",
    "\n",
    "            rel_error = abs(pred_second - actual_second) / (abs(actual_second) + 1e-8)\n",
    "            rel_errs.append(rel_error)\n",
    "\n",
    "        avg_rel_err = float(np.mean(rel_errs))\n",
    "\n",
    "    per_sample_info.append((node_idx, label, lambda_max, avg_rel_err))\n",
    "\n",
    "# -------------------- Aggregate stats --------------------\n",
    "clean_stats = [t for t in per_sample_info if t[1]==0]\n",
    "troj_stats  = [t for t in per_sample_info if t[1]==1]\n",
    "\n",
    "def summarize(stats):\n",
    "    if not stats: return (0.0,0.0,0.0,0.0)\n",
    "    Ls = np.array([s[2] for s in stats])\n",
    "    Es = np.array([s[3] for s in stats])\n",
    "    return (Ls.mean(), Ls.std(), Es.mean(), Es.std())\n",
    "\n",
    "cL_mean, cL_std, cE_mean, cE_std = summarize(clean_stats)\n",
    "tL_mean, tL_std, tE_mean, tE_std = summarize(troj_stats)\n",
    "\n",
    "print(\"\\nAggregated Hessian curvature stats:\")\n",
    "print(f\" Clean:  avg_lambda={cL_mean:.4f} ± {cL_std:.4f}, avg_FDrel={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_lambda={tL_mean:.4f} ± {tL_std:.4f}, avg_FDrel={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "\n",
    "print(\"\\nSample preview (first 6): (idx,label,lambda,FD_rel_err)\")\n",
    "for p in per_sample_info[:6]:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a9bd33-dc25-488d-9e06-57df4dd9e747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Robustness Eval (Margin) ===\n",
      "Accuracy=99.54 | Precision=0.9954 | Recall=0.9954 | F1=0.9954\n",
      "Confusion Matrix:\n",
      "[[ 9091    68]\n",
      " [  100 27456]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.9891    0.9926    0.9908      9159\n",
      "      trojan     0.9975    0.9964    0.9969     27556\n",
      "\n",
      "    accuracy                         0.9954     36715\n",
      "   macro avg     0.9933    0.9945    0.9939     36715\n",
      "weighted avg     0.9954    0.9954    0.9954     36715\n",
      "\n",
      "Flipped 168/200 (84.00%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8780, -1.8055],\n",
       "        [ 1.8517, -1.5237],\n",
       "        [ 1.7920, -1.3890],\n",
       "        ...,\n",
       "        [ 1.2558, -1.5113],\n",
       "        [ 0.9869, -1.1436],\n",
       "        [ 1.2348, -1.3873]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(\"Margin\", perturbed_X, selected_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25c362f5-a3ea-425b-9b6d-f3f63695e266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Margin:\n",
      " Class 0: margin=0.8551±1.1146, relerr=0.0000e+00±0.0000e+00\n",
      " Class 1: margin=14.4402±1.9893, relerr=0.0000e+00±0.0000e+00\n",
      "\n",
      "=== Robustness Eval (Margin) ===\n",
      "Accuracy=99.54 | Precision=0.9954 | Recall=0.9954 | F1=0.9954\n",
      "Confusion Matrix:\n",
      "[[ 9091    68]\n",
      " [  100 27456]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.9891    0.9926    0.9908      9159\n",
      "      trojan     0.9975    0.9964    0.9969     27556\n",
      "\n",
      "    accuracy                         0.9954     36715\n",
      "   macro avg     0.9933    0.9945    0.9939     36715\n",
      "weighted avg     0.9954    0.9954    0.9954     36715\n",
      "\n",
      "Flipped 168/200 (84.00%)\n",
      "\n",
      "Adversarial Robustness Radius:\n",
      " Class 0: radius=0.0010±0.0000\n",
      " Class 1: radius=0.0010±0.0000\n",
      "\n",
      "=== Robustness Eval (ARR) ===\n",
      "Accuracy=99.54 | Precision=0.9954 | Recall=0.9954 | F1=0.9954\n",
      "Confusion Matrix:\n",
      "[[ 9091    68]\n",
      " [  100 27456]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.9891    0.9926    0.9908      9159\n",
      "      trojan     0.9975    0.9964    0.9969     27556\n",
      "\n",
      "    accuracy                         0.9954     36715\n",
      "   macro avg     0.9933    0.9945    0.9939     36715\n",
      "weighted avg     0.9954    0.9954    0.9954     36715\n",
      "\n",
      "Flipped 168/200 (84.00%)\n",
      "\n",
      "Stability Under Noise:\n",
      " Class 0: stability=0.0228±0.0097\n",
      " Class 1: stability=0.0976±0.0239\n",
      "\n",
      "=== Robustness Eval (Stability) ===\n",
      "Accuracy=99.54 | Precision=0.9954 | Recall=0.9954 | F1=0.9954\n",
      "Confusion Matrix:\n",
      "[[ 9091    68]\n",
      " [  100 27456]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.9891    0.9926    0.9908      9159\n",
      "      trojan     0.9975    0.9964    0.9969     27556\n",
      "\n",
      "    accuracy                         0.9954     36715\n",
      "   macro avg     0.9933    0.9945    0.9939     36715\n",
      "weighted avg     0.9954    0.9954    0.9954     36715\n",
      "\n",
      "Flipped 168/200 (84.00%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8780, -1.8055],\n",
       "        [ 1.8517, -1.5237],\n",
       "        [ 1.7920, -1.3890],\n",
       "        ...,\n",
       "        [ 1.2558, -1.5113],\n",
       "        [ 0.9869, -1.1436],\n",
       "        [ 1.2348, -1.3873]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------- Metric 4: Prediction Margin ----------------\n",
    "margin_info = []\n",
    "for node_idx in selected_nodes:\n",
    "    logits = model(perturbed_X, A_t)[node_idx]\n",
    "    pred_class = logits.argmax().item()\n",
    "    margin = logits[pred_class].item() - logits[[j for j in range(len(logits)) if j!=pred_class]].max().item()\n",
    "    delta = FD_EPS*torch.randn_like(perturbed_X[node_idx])\n",
    "    logits_p = model(perturbed_X.clone().detach(), A_t)[node_idx]\n",
    "    margin_p = logits_p[pred_class].item() - logits_p[[j for j in range(len(logits_p)) if j!=pred_class]].max().item()\n",
    "    rel_err = abs(margin-margin_p)/(abs(margin_p)+1e-12)\n",
    "    margin_info.append((int(labels_np[node_idx]), margin, rel_err))\n",
    "print(\"\\nPrediction Margin:\")\n",
    "for cls in [0,1]:\n",
    "    vals = [j[1] for j in margin_info if j[0]==cls]\n",
    "    errs = [j[2] for j in margin_info if j[0]==cls]\n",
    "    print(f\" Class {cls}: margin={np.mean(vals):.4f}±{np.std(vals):.4f}, relerr={np.mean(errs):.4e}±{np.std(errs):.4e}\")\n",
    "\n",
    "evaluate_model(\"Margin\", perturbed_X, selected_nodes)\n",
    "\n",
    "# ---------------- Metric 5: ARR ----------------\n",
    "# (kept simplified: min perturbation until flip)\n",
    "def adversarial_radius(node_idx):\n",
    "    x0 = perturbed_X[node_idx].detach().clone()\n",
    "    base_pred = int(model(perturbed_X, A_t)[node_idx].argmax().item())\n",
    "    eps, growth = 1e-3, 1.2\n",
    "    while eps < 20:\n",
    "        x_try = x0 + eps*torch.randn_like(x0)\n",
    "        with torch.no_grad():\n",
    "            pred = int(model(perturbed_X.clone().detach(), A_t).argmax().item())\n",
    "        if pred != base_pred: return eps\n",
    "        eps *= growth\n",
    "    return 20.0\n",
    "arr_info = [(int(labels_np[n]), adversarial_radius(n)) for n in selected_nodes]\n",
    "print(\"\\nAdversarial Robustness Radius:\")\n",
    "for cls in [0,1]:\n",
    "    vals = [j[1] for j in arr_info if j[0]==cls]\n",
    "    print(f\" Class {cls}: radius={np.mean(vals):.4f}±{np.std(vals):.4f}\")\n",
    "\n",
    "evaluate_model(\"ARR\", perturbed_X, selected_nodes)\n",
    "\n",
    "# ---------------- Metric 6: Stability ----------------\n",
    "stability_info = []\n",
    "for node_idx in selected_nodes:\n",
    "    base_logits = model(perturbed_X, A_t)[node_idx].detach()\n",
    "    diffs = []\n",
    "    for _ in range(10):\n",
    "        noise = 0.05*torch.randn_like(perturbed_X[node_idx])\n",
    "        X_mod = perturbed_X.clone().detach()\n",
    "        X_mod[node_idx] = perturbed_X[node_idx]+noise\n",
    "        with torch.no_grad():\n",
    "            logits_n = model(X_mod, A_t)[node_idx]\n",
    "        diffs.append(torch.norm(logits_n-base_logits).item())\n",
    "    stability_info.append((int(labels_np[node_idx]), np.mean(diffs)))\n",
    "print(\"\\nStability Under Noise:\")\n",
    "for cls in [0,1]:\n",
    "    vals = [j[1] for j in stability_info if j[0]==cls]\n",
    "    print(f\" Class {cls}: stability={np.mean(vals):.4f}±{np.std(vals):.4f}\")\n",
    "\n",
    "evaluate_model(\"Stability\", perturbed_X, selected_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "966415c3-7b87-4ff1-9cee-bc6d5fdad7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adversarial Robustness Radius:\n",
      " Class 0: radius=20.0000±0.0000, relerr=0.0000e+00±0.0000e+00\n",
      " Class 1: radius=20.0000±0.0000, relerr=0.0000e+00±0.0000e+00\n",
      "\n",
      "=== Robustness Eval (ARR) ===\n",
      "Flipped 168/200 (84.00%)\n",
      "Accuracy=16.00 | Precision=0.1212 | Recall=0.1600 | F1=0.1379\n",
      "Confusion Matrix:\n",
      "[[ 32  68]\n",
      " [100   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.2424    0.3200    0.2759       100\n",
      "      trojan     0.0000    0.0000    0.0000       100\n",
      "\n",
      "    accuracy                         0.1600       200\n",
      "   macro avg     0.1212    0.1600    0.1379       200\n",
      "weighted avg     0.1212    0.1600    0.1379       200\n",
      "\n",
      "\n",
      "Stability Under Noise:\n",
      " Class 0: stability=0.0230±0.0093, relerr=9.3952e-01±9.3345e-01\n",
      " Class 1: stability=0.0971±0.0260, relerr=1.2967e+00±2.4180e+00\n",
      "\n",
      "=== Robustness Eval (Stability) ===\n",
      "Flipped 168/200 (84.00%)\n",
      "Accuracy=16.00 | Precision=0.1212 | Recall=0.1600 | F1=0.1379\n",
      "Confusion Matrix:\n",
      "[[ 32  68]\n",
      " [100   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.2424    0.3200    0.2759       100\n",
      "      trojan     0.0000    0.0000    0.0000       100\n",
      "\n",
      "    accuracy                         0.1600       200\n",
      "   macro avg     0.1212    0.1600    0.1379       200\n",
      "weighted avg     0.1212    0.1600    0.1379       200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8780, -1.8055],\n",
       "        [ 1.8517, -1.5237],\n",
       "        [ 1.7920, -1.3890],\n",
       "        ...,\n",
       "        [ 1.2558, -1.5113],\n",
       "        [ 0.9869, -1.1436],\n",
       "        [ 1.2348, -1.3873]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------- Metric 5: ARR ----------------\n",
    "# (kept simplified: min perturbation until flip)\n",
    "def adversarial_radius(node_idx):\n",
    "    x0 = perturbed_X[node_idx].detach().clone()\n",
    "    base_pred = int(model(perturbed_X, A_t)[node_idx].argmax().item())\n",
    "    eps, growth = 1e-3, 1.2\n",
    "    while eps < 20:\n",
    "        x_try = x0 + eps*torch.randn_like(x0)\n",
    "        with torch.no_grad():\n",
    "            pred = int(model(perturbed_X.clone().detach(), A_t)[node_idx].argmax().item())\n",
    "        if pred != base_pred: return eps\n",
    "        eps *= growth\n",
    "    return 20.0\n",
    "\n",
    "arr_info = []\n",
    "for n in selected_nodes:\n",
    "    arr_val = adversarial_radius(n)\n",
    "    # finite-difference style perturbation for ARR\n",
    "    delta = FD_EPS * torch.randn_like(perturbed_X[n])\n",
    "    arr_val_p = adversarial_radius(n)  # here you could recompute with perturbed input if desired\n",
    "    rel_err = abs(arr_val - arr_val_p) / (abs(arr_val_p) + 1e-12)\n",
    "    arr_info.append((int(labels_np[n]), arr_val, rel_err))\n",
    "\n",
    "print(\"\\nAdversarial Robustness Radius:\")\n",
    "for cls in [0,1]:\n",
    "    vals = [j[1] for j in arr_info if j[0] == cls]\n",
    "    errs = [j[2] for j in arr_info if j[0] == cls]\n",
    "    print(f\" Class {cls}: radius={np.mean(vals):.4f}±{np.std(vals):.4f}, relerr={np.mean(errs):.4e}±{np.std(errs):.4e}\")\n",
    "\n",
    "evaluate_model(\"ARR\", perturbed_X, selected_nodes)\n",
    "\n",
    "# ---------------- Metric 6: Stability ----------------\n",
    "stability_info = []\n",
    "for node_idx in selected_nodes:\n",
    "    base_logits = model(perturbed_X, A_t)[node_idx].detach()\n",
    "    diffs = []\n",
    "    for _ in range(10):\n",
    "        noise = 0.05 * torch.randn_like(perturbed_X[node_idx])\n",
    "        X_mod = perturbed_X.clone().detach()\n",
    "        X_mod[node_idx] = perturbed_X[node_idx] + noise\n",
    "        with torch.no_grad():\n",
    "            logits_n = model(X_mod, A_t)[node_idx]\n",
    "        diffs.append(torch.norm(logits_n - base_logits).item())\n",
    "    stability_val = np.mean(diffs)\n",
    "    # finite-difference style perturbation for stability\n",
    "    noise_fd = 0.05 * torch.randn_like(perturbed_X[node_idx])\n",
    "    X_fd = perturbed_X.clone().detach()\n",
    "    X_fd[node_idx] = perturbed_X[node_idx] + noise_fd\n",
    "    with torch.no_grad():\n",
    "        logits_fd = model(X_fd, A_t)[node_idx]\n",
    "    diffs_fd = [torch.norm(logits_fd - base_logits).item()]\n",
    "    stability_val_p = np.mean(diffs_fd)\n",
    "    rel_err = abs(stability_val - stability_val_p) / (abs(stability_val_p) + 1e-12)\n",
    "    stability_info.append((int(labels_np[node_idx]), stability_val, rel_err))\n",
    "\n",
    "print(\"\\nStability Under Noise:\")\n",
    "for cls in [0,1]:\n",
    "    vals = [j[1] for j in stability_info if j[0] == cls]\n",
    "    errs = [j[2] for j in stability_info if j[0] == cls]\n",
    "    print(f\" Class {cls}: stability={np.mean(vals):.4f}±{np.std(vals):.4f}, relerr={np.mean(errs):.4e}±{np.std(errs):.4e}\")\n",
    "\n",
    "evaluate_model(\"Stability\", perturbed_X, selected_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a112f76c-eb5d-4259-b1ee-11484b1f2248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Robustness Eval (Stability) ===\n",
      "Flipped 168/200 (84.00%)\n",
      "Accuracy=16.00 | Precision=0.1212 | Recall=0.1600 | F1=0.1379\n",
      "Confusion Matrix:\n",
      "[[ 32  68]\n",
      " [100   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.2424    0.3200    0.2759       100\n",
      "      trojan     0.0000    0.0000    0.0000       100\n",
      "\n",
      "    accuracy                         0.1600       200\n",
      "   macro avg     0.1212    0.1600    0.1379       200\n",
      "weighted avg     0.1212    0.1600    0.1379       200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8780, -1.8055],\n",
       "        [ 1.8517, -1.5237],\n",
       "        [ 1.7920, -1.3890],\n",
       "        ...,\n",
       "        [ 1.2558, -1.5113],\n",
       "        [ 0.9869, -1.1436],\n",
       "        [ 1.2348, -1.3873]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------- Refined Eval Helper ----------------\n",
    "def evaluate_model(name, perturbed_X, selected_nodes):\n",
    "    with torch.no_grad():\n",
    "        # Predictions on original and perturbed inputs\n",
    "        orig_logits = model(X_t, A_t)\n",
    "        pert_logits = model(perturbed_X, A_t)\n",
    "\n",
    "        orig_preds = orig_logits.argmax(dim=1).cpu().numpy()\n",
    "        pert_preds = pert_logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "    # Restrict to selected perturbed samples only\n",
    "    sel_idx = np.array(selected_nodes)\n",
    "    sel_labels = labels_np[sel_idx]\n",
    "    sel_orig_preds = orig_preds[sel_idx]\n",
    "    sel_pert_preds = pert_preds[sel_idx]\n",
    "\n",
    "    # Flip count first\n",
    "    flips = (sel_orig_preds != sel_pert_preds).sum()\n",
    "    print(f\"\\n=== Robustness Eval ({name}) ===\")\n",
    "    print(f\"Flipped {flips}/{len(sel_idx)} ({100*flips/len(sel_idx):.2f}%)\")\n",
    "\n",
    "    # Accuracy, precision, recall, F1 on perturbed subset only\n",
    "    acc = (sel_pert_preds == sel_labels).mean()\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        sel_labels, sel_pert_preds, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    print(f\"Accuracy={acc*100:.2f} | Precision={prec:.4f} | Recall={rec:.4f} | F1={f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(sel_labels, sel_pert_preds, labels=[0, 1]))\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(sel_labels, sel_pert_preds,\n",
    "                                target_names=[\"clean\", \"trojan\"], digits=4))\n",
    "\n",
    "    return pert_logits\n",
    "evaluate_model(\"Stability\", perturbed_X, selected_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b18f19-cc59-47e4-bea2-3d263b8f83f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
