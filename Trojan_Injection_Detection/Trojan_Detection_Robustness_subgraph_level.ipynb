{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfa6ce9e-9a74-4424-a211-23c117d27959",
   "metadata": {},
   "source": [
    "#### Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79de5491-1d0a-4061-a85c-bb3bdf26c81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building subgraphs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 674/674 [00:21<00:00, 32.00it/s]\n",
      "/home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 674 subgraphs (usable)\n",
      "Train: 471, Val: 101, Test: 102\n",
      "Epoch 001 | Loss 0.7464 | Val 0.2673\n",
      "Epoch 005 | Loss 0.6193 | Val 0.6238\n",
      "Epoch 010 | Loss 0.5896 | Val 0.5941\n",
      "Epoch 015 | Loss 0.5101 | Val 0.6832\n",
      "Epoch 020 | Loss 0.3784 | Val 0.8020\n",
      "Epoch 025 | Loss 0.2963 | Val 0.8317\n",
      "Epoch 030 | Loss 0.2182 | Val 0.8812\n",
      "Epoch 035 | Loss 0.1549 | Val 0.9208\n",
      "Epoch 040 | Loss 0.1265 | Val 0.9208\n",
      "Epoch 045 | Loss 0.1028 | Val 0.9208\n",
      "Epoch 050 | Loss 0.0897 | Val 0.9208\n",
      "Epoch 055 | Loss 0.0840 | Val 0.9208\n",
      "Epoch 060 | Loss 0.0851 | Val 0.9307\n",
      "Epoch 065 | Loss 0.0641 | Val 0.9307\n",
      "Epoch 070 | Loss 0.0713 | Val 0.9604\n",
      "Epoch 075 | Loss 0.0604 | Val 0.9604\n",
      "Epoch 080 | Loss 0.0645 | Val 0.9604\n",
      "\n",
      "Final Evaluation (Subgraph-Level)\n",
      "=================================\n",
      "Test Accuracy: 0.9902\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9167    1.0000    0.9565        11\n",
      "           1     1.0000    0.9890    0.9945        91\n",
      "\n",
      "    accuracy                         0.9902       102\n",
      "   macro avg     0.9583    0.9945    0.9755       102\n",
      "weighted avg     0.9910    0.9902    0.9904       102\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11  0]\n",
      " [ 1 90]]\n"
     ]
    }
   ],
   "source": [
    "# train_subgraph_gnn_fixed.py\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 80\n",
    "LR = 1e-3\n",
    "HID_DIM = 64\n",
    "\n",
    "# -----------------------\n",
    "# Load node features\n",
    "# -----------------------\n",
    "nodes_df = pd.read_csv(\"GNNDatasets/node.csv\")\n",
    "nodes_df[\"uid\"] = nodes_df[\"circuit_name\"].astype(str) + \"::\" + nodes_df[\"node\"].astype(str)\n",
    "\n",
    "# one-hot gate_type\n",
    "if \"gate_type\" in nodes_df.columns:\n",
    "    gate_ohe = pd.get_dummies(nodes_df[\"gate_type\"], prefix=\"gt\")\n",
    "    nodes_feat_df = pd.concat([nodes_df.drop(columns=[\"gate_type\"]), gate_ohe], axis=1)\n",
    "else:\n",
    "    nodes_feat_df = nodes_df.copy()\n",
    "\n",
    "meta_cols = {\"uid\",\"node\",\"circuit_name\",\"label\",\"label_node\",\"label_graph\",\"label_subgraph\",\"folder\"}\n",
    "num_cols = [c for c in nodes_feat_df.columns if c not in meta_cols and pd.api.types.is_numeric_dtype(nodes_feat_df[c])]\n",
    "\n",
    "uid_to_feat = {}\n",
    "for _, r in nodes_feat_df.iterrows():\n",
    "    uid_to_feat[r[\"uid\"]] = r[num_cols].astype(float).values\n",
    "\n",
    "scaler = StandardScaler().fit(np.stack(list(uid_to_feat.values())))\n",
    "for k in list(uid_to_feat.keys()):\n",
    "    uid_to_feat[k] = scaler.transform(uid_to_feat[k].reshape(1,-1)).reshape(-1)\n",
    "\n",
    "feat_dim = len(uid_to_feat[list(uid_to_feat.keys())[0]])\n",
    "\n",
    "# -----------------------\n",
    "# Merge edge CSVs\n",
    "# -----------------------\n",
    "edge_files = [\n",
    "    \"GNNDatasets/node_edges.csv\",\n",
    "    \"GNNDatasets/subgraph_edges_andxor.csv\",\n",
    "    \"GNNDatasets/subgraph_edges_countermux.csv\",\n",
    "    \"GNNDatasets/subgraph_edges_fsmor.csv\",\n",
    "]\n",
    "\n",
    "edges_by_circuit = defaultdict(list)\n",
    "for ef in edge_files:\n",
    "    df = pd.read_csv(ef)\n",
    "    for _, r in df.iterrows():\n",
    "        edges_by_circuit[r[\"circuit_name\"]].append((r[\"src\"], r[\"dst\"]))\n",
    "\n",
    "# -----------------------\n",
    "# Build dataset\n",
    "# -----------------------\n",
    "sub_df = pd.read_csv(\"GNNDatasets/subgraph.csv\")\n",
    "data_list, labels = [], []\n",
    "\n",
    "for idx, row in tqdm(sub_df.iterrows(), total=len(sub_df), desc=\"Building subgraphs\"):\n",
    "    ckt = row[\"circuit_name\"]\n",
    "    lbl = int(row.get(\"label_subgraph\", row.get(\"label\", 0)))\n",
    "    \n",
    "    if ckt not in edges_by_circuit:\n",
    "        continue\n",
    "    \n",
    "    # collect node uids from node.csv that belong to this circuit\n",
    "    sub_nodes = nodes_df[nodes_df[\"circuit_name\"]==ckt][\"node\"].tolist()\n",
    "    if not sub_nodes: \n",
    "        continue\n",
    "    \n",
    "    uid_map = {n:i for i,n in enumerate(sub_nodes)}\n",
    "    x_list = []\n",
    "    for n in sub_nodes:\n",
    "        uid = f\"{ckt}::{n}\"\n",
    "        if uid in uid_to_feat:\n",
    "            x_list.append(uid_to_feat[uid])\n",
    "        else:\n",
    "            x_list.append(np.zeros(feat_dim))\n",
    "    x = torch.tensor(np.vstack(x_list), dtype=torch.float)\n",
    "    \n",
    "    # build edge_index\n",
    "    edge_idx = [[], []]\n",
    "    for u,v in edges_by_circuit[ckt]:\n",
    "        if u in uid_map and v in uid_map:\n",
    "            edge_idx[0].append(uid_map[u]); edge_idx[1].append(uid_map[v])\n",
    "            edge_idx[0].append(uid_map[v]); edge_idx[1].append(uid_map[u])\n",
    "    if not edge_idx[0]:\n",
    "        continue\n",
    "    edge_index = torch.tensor(edge_idx, dtype=torch.long)\n",
    "    \n",
    "    data = Data(x=x, edge_index=edge_index, y=torch.tensor([lbl], dtype=torch.long))\n",
    "    data.circuit_name = ckt\n",
    "    data_list.append(data)\n",
    "    labels.append(lbl)\n",
    "\n",
    "print(f\"Built {len(data_list)} subgraphs (usable)\")\n",
    "\n",
    "# -----------------------\n",
    "# Split\n",
    "# -----------------------\n",
    "labels = np.array(labels)\n",
    "idxs = np.arange(len(data_list))\n",
    "train_idx, temp_idx, y_train, y_temp = train_test_split(idxs, labels, test_size=0.3, \n",
    "                                                        stratify=labels, random_state=RANDOM_SEED)\n",
    "val_idx, test_idx, y_val, y_test = train_test_split(temp_idx, y_temp, test_size=0.5,\n",
    "                                                    stratify=y_temp, random_state=RANDOM_SEED)\n",
    "\n",
    "train_loader = DataLoader([data_list[i] for i in train_idx], batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader([data_list[i] for i in val_idx], batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader([data_list[i] for i in test_idx], batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_idx)}, Val: {len(val_idx)}, Test: {len(test_idx)}\")\n",
    "\n",
    "# -----------------------\n",
    "# Model\n",
    "# -----------------------\n",
    "class SubgraphClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim=HID_DIM, out_dim=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_dim, hid_dim)\n",
    "        self.conv2 = SAGEConv(hid_dim, hid_dim)\n",
    "        self.lin = nn.Linear(hid_dim, out_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.4, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.lin(x)\n",
    "\n",
    "model = SubgraphClassifier(feat_dim).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=5e-4)\n",
    "\n",
    "# class weights\n",
    "cls_counts = np.bincount(labels)\n",
    "w = torch.tensor([cls_counts.sum()/c for c in cls_counts], dtype=torch.float32).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(weight=w)\n",
    "\n",
    "# -----------------------\n",
    "# Training loop\n",
    "# -----------------------\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    ys, preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for b in loader:\n",
    "            b = b.to(DEVICE)\n",
    "            out = model(b.x, b.edge_index, b.batch)\n",
    "            p = out.argmax(dim=1).cpu().numpy()\n",
    "            ys.extend(b.y.cpu().numpy())\n",
    "            preds.extend(p)\n",
    "    return np.array(ys), np.array(preds)\n",
    "\n",
    "best_val, best_state = -1, None\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss=0\n",
    "    for b in train_loader:\n",
    "        b = b.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(b.x, b.edge_index, b.batch)\n",
    "        loss = criterion(out, b.y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if epoch%5==0 or epoch==1:\n",
    "        yv,pv = evaluate(val_loader)\n",
    "        acc = accuracy_score(yv,pv)\n",
    "        print(f\"Epoch {epoch:03d} | Loss {total_loss/len(train_loader):.4f} | Val {acc:.4f}\")\n",
    "        if acc>best_val: \n",
    "            best_val=acc; best_state=model.state_dict().copy()\n",
    "\n",
    "# load best\n",
    "if best_state: model.load_state_dict(best_state)\n",
    "\n",
    "# -----------------------\n",
    "# Final test\n",
    "# -----------------------\n",
    "yt,pt = evaluate(test_loader)\n",
    "print(\"\\nFinal Evaluation (Subgraph-Level)\")\n",
    "print(\"=================================\")\n",
    "print(f\"Test Accuracy: {accuracy_score(yt,pt):.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(yt,pt,digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(yt,pt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d73614-3893-45e8-ae2f-c68d2240a89f",
   "metadata": {},
   "source": [
    "#### Jacobain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8bcf656-c8f3-4ec7-a6db-0bfd7b8512a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subgraphs: 102; class counts: [11 91]\n",
      "Selected counts: {0: 11, 1: 20}\n",
      "\n",
      "Running PGD perturbation on selected subgraphs (this may take a while)...\n",
      "? PGD perturbation finished for selected subgraphs.\n",
      "\n",
      "============= Robustness Evaluation (Full Test Set: perturbed selected + rest original) =============\n",
      "Accuracy: 96.08%\n",
      "Precision: 0.9651, Recall: 0.9608, F1: 0.9622\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.7692    0.9091    0.8333        11\n",
      "      trojan     0.9888    0.9670    0.9778        91\n",
      "\n",
      "    accuracy                         0.9608       102\n",
      "   macro avg     0.8790    0.9381    0.9056       102\n",
      "weighted avg     0.9651    0.9608    0.9622       102\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  1]\n",
      " [ 3 88]]\n",
      "\n",
      "Selected subgraphs: 31. Flipped after attack: 3 (9.68%).\n",
      "\n",
      "Computing Jacobian norms & FD relative error on the PERTURBED selected subgraphs...\n",
      "\n",
      "Jacobian norms & FD relative errors (aggregated):\n",
      " Clean subgraphs:  avg_norm=0.4876 ± 0.1973, avg_FDrel=2.7351e-02 ± 5.7933e-02\n",
      " Trojan subgraphs: avg_norm=0.9912 ± 2.6177, avg_FDrel=7.6477e-01 ± 2.4422e+00\n",
      "\n",
      "Sample preview (first 6): (idx,label,jacobian_frob,FD_rel_err)\n",
      "(5, 1, 0.5232011079788208, 0.006874935235828161)\n",
      "(7, 1, 12.308995246887207, 0.01924426294863224)\n",
      "(12, 0, 0.1714828461408615, 0.01224440336227417)\n",
      "(14, 0, 0.3758105933666229, 0.009414240717887878)\n",
      "(15, 1, 0.36891114711761475, 0.001470681163482368)\n",
      "(18, 0, 0.9355684518814087, 0.01225760206580162)\n",
      "\n",
      "Done. (Order: PGD perturbation -> full-test evaluation -> Jacobian computed at perturbed inputs.)\n"
     ]
    }
   ],
   "source": [
    "# Subgraph-level: PGD-first ? evaluation ? Jacobian + FD relative error\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# ---------------------- PARAMETERS ----------------------\n",
    "PER_CLASS = 20        # # subgraphs per class to perturb (adjust)\n",
    "EPSILON = 4.0         # L2 radius for PGD perturbation (on flattened subgraph features)\n",
    "ALPHA = 1.0           # PGD step size (normalized)\n",
    "NUM_ITERS = 30        # PGD iterations\n",
    "FD_EPS = 1e-3         # finite-difference epsilon for Jacobian check\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# ---------------------- Sanity check ----------------------\n",
    "required = [\"model\", \"test_loader\", \"DEVICE\"]\n",
    "for v in required:\n",
    "    if v not in globals():\n",
    "        raise RuntimeError(f\"Required variable '{v}' not found in the environment.\")\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# ---------------------- Get test dataset as list ----------------------\n",
    "test_data_list = list(test_loader.dataset)   # preserve the same order used by DataLoader\n",
    "test_labels = np.array([int(d.y.item()) for d in test_data_list])\n",
    "n_test = len(test_data_list)\n",
    "print(f\"Test subgraphs: {n_test}; class counts: {np.bincount(test_labels)}\")\n",
    "\n",
    "# ---------------------- Select subgraphs to perturb (PER_CLASS per class) ----------------------\n",
    "rng = np.random.default_rng(SEED)\n",
    "selected_idxs = []\n",
    "for cls in [0, 1]:\n",
    "    idxs = np.where(test_labels == cls)[0]\n",
    "    if len(idxs) == 0:\n",
    "        continue\n",
    "    k = min(PER_CLASS, len(idxs))\n",
    "    chosen = rng.choice(idxs, size=k, replace=False)\n",
    "    selected_idxs.extend(chosen.tolist())\n",
    "selected_idxs = np.array(sorted(selected_idxs), dtype=np.int64)\n",
    "print(\"Selected counts:\", {0:int((test_labels[selected_idxs]==0).sum()), 1:int((test_labels[selected_idxs]==1).sum())})\n",
    "\n",
    "# ---------------------- PGD perturbation for selected subgraphs ----------------------\n",
    "perturbed_map = {}  # idx -> perturbed x tensor (on DEVICE)\n",
    "print(\"\\nRunning PGD perturbation on selected subgraphs (this may take a while)...\")\n",
    "\n",
    "for idx in selected_idxs:\n",
    "    data = test_data_list[int(idx)]\n",
    "    x_orig = data.x.detach().to(DEVICE)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    n_nodes, feat_dim = x_orig.shape\n",
    "\n",
    "    # initialize adv example (random direction scaled to EPSILON)\n",
    "    delta = torch.randn_like(x_orig, device=DEVICE)\n",
    "    delta = delta * (EPSILON / (delta.view(-1).norm() + 1e-12))\n",
    "    x_adv = (x_orig + delta).detach().clone().requires_grad_(True)\n",
    "\n",
    "    # batch vector for single-graph forward\n",
    "    batch_zero = torch.zeros(n_nodes, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    y_true = torch.tensor([int(data.y.item())], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    for it in range(NUM_ITERS):\n",
    "        # forward\n",
    "        out = model(x_adv, edge_index, batch_zero)            # shape [1, C]\n",
    "        loss = F.cross_entropy(out, y_true)\n",
    "        # gradient wrt inputs\n",
    "        grad_x = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "        gnorm = grad_x.view(-1).norm().item()\n",
    "        if gnorm == 0:\n",
    "            break\n",
    "        step = (ALPHA * grad_x) / (gnorm + 1e-12)\n",
    "        x_adv = (x_adv + step).detach()\n",
    "        # project to L2 ball around x_orig\n",
    "        delta = x_adv - x_orig\n",
    "        dnorm = delta.view(-1).norm().item()\n",
    "        if dnorm > EPSILON:\n",
    "            delta = delta * (EPSILON / (dnorm + 1e-12))\n",
    "            x_adv = (x_orig + delta).detach()\n",
    "        x_adv = x_adv.requires_grad_(True)\n",
    "\n",
    "    perturbed_map[int(idx)] = x_adv.detach().clone()\n",
    "\n",
    "print(\"? PGD perturbation finished for selected subgraphs.\")\n",
    "\n",
    "# ---------------------- Evaluate model on full test set (perturbed selected + originals) ----------------------\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_data_list):\n",
    "        x_in = perturbed_map[i] if i in perturbed_map else data.x.to(DEVICE)\n",
    "        edge_index = data.edge_index.to(DEVICE)\n",
    "        batch_zero = torch.zeros(x_in.size(0), dtype=torch.long, device=DEVICE)\n",
    "        out = model(x_in, edge_index, batch_zero)         # [1, C]\n",
    "        pred = int(out.argmax(dim=1).item())\n",
    "        y_pred_list.append(pred)\n",
    "        y_true_list.append(int(data.y.item()))\n",
    "\n",
    "y_true_arr = np.array(y_true_list)\n",
    "y_pred_arr = np.array(y_pred_list)\n",
    "\n",
    "print(\"\\n============= Robustness Evaluation (Full Test Set: perturbed selected + rest original) =============\")\n",
    "acc = (y_true_arr == y_pred_arr).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true_arr, y_pred_arr, average='weighted', zero_division=0)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_true_arr, y_pred_arr, labels=[0,1], target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true_arr, y_pred_arr, labels=[0,1]))\n",
    "\n",
    "# how many selected flipped?\n",
    "orig_preds = []\n",
    "adv_preds = []\n",
    "with torch.no_grad():\n",
    "    for idx in selected_idxs:\n",
    "        data = test_data_list[int(idx)]\n",
    "        edge_index = data.edge_index.to(DEVICE)\n",
    "        batch_zero = torch.zeros(data.x.size(0), dtype=torch.long, device=DEVICE)\n",
    "        # original\n",
    "        out_orig = model(data.x.to(DEVICE), edge_index, batch_zero)\n",
    "        orig_preds.append(int(out_orig.argmax(dim=1).item()))\n",
    "        # adv\n",
    "        out_adv = model(perturbed_map[int(idx)], edge_index, batch_zero)\n",
    "        adv_preds.append(int(out_adv.argmax(dim=1).item()))\n",
    "orig_preds = np.array(orig_preds); adv_preds = np.array(adv_preds)\n",
    "num_flips = int((orig_preds != adv_preds).sum())\n",
    "print(f\"\\nSelected subgraphs: {len(selected_idxs)}. Flipped after attack: {num_flips} ({100.0*num_flips/len(selected_idxs):.2f}%).\")\n",
    "\n",
    "# ---------------------- Jacobian & finite-difference relative error (computed AT the PERTURBED input) ----------------------\n",
    "print(\"\\nComputing Jacobian norms & FD relative error on the PERTURBED selected subgraphs...\")\n",
    "per_sample_info = []   # tuples: (idx, label, jacobian_fro_norm, fd_rel_error)\n",
    "for idx in selected_idxs:\n",
    "    data = test_data_list[int(idx)]\n",
    "    x_adv = perturbed_map[int(idx)].detach().clone().to(DEVICE).requires_grad_(True)  # perturbed input\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    n_nodes, feat_dim = x_adv.shape\n",
    "    batch_zero = torch.zeros(n_nodes, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    # flatten input\n",
    "    x_flat = x_adv.view(-1).detach().clone().requires_grad_(True)\n",
    "\n",
    "    def f_flat(x_flat_input):\n",
    "        x_mat = x_flat_input.view_as(x_adv)\n",
    "        out = model(x_mat, edge_index, batch_zero)   # [1, C]\n",
    "        return out.squeeze(0)                        # (C,)\n",
    "\n",
    "    # Jacobian: shape (C, D) where D = n_nodes * feat_dim\n",
    "    try:\n",
    "        J = torch.autograd.functional.jacobian(f_flat, x_flat)    # (C, D)\n",
    "    except RuntimeError:\n",
    "        # fallback: compute per-output jacobian rows to avoid memory blowup (slower)\n",
    "        C = int(model(x_adv, edge_index, batch_zero).shape[1])\n",
    "        rows = []\n",
    "        for out_i in range(C):\n",
    "            def scalar_f(z, i=out_i):\n",
    "                return f_flat(z)[i]\n",
    "            r = torch.autograd.functional.jacobian(scalar_f, x_flat)\n",
    "            rows.append(r.unsqueeze(0))\n",
    "        J = torch.cat(rows, dim=0)\n",
    "\n",
    "    J = J.detach()\n",
    "    jac_frob = float(torch.norm(J, p='fro').item())\n",
    "\n",
    "    # finite-difference relative error\n",
    "    delta_fd = FD_EPS * torch.randn_like(x_flat).to(DEVICE)\n",
    "    pred_change = J @ delta_fd                          # (C,)\n",
    "    f0 = f_flat(x_flat).detach()\n",
    "    f0p = f_flat(x_flat + delta_fd).detach()\n",
    "    actual_change = f0p - f0\n",
    "    rel_err = float((torch.norm(pred_change - actual_change) / (torch.norm(actual_change) + 1e-8)).item())\n",
    "\n",
    "    per_sample_info.append((int(idx), int(data.y.item()), jac_frob, rel_err))\n",
    "\n",
    "# ---------------------- Aggregate & print summary ----------------------\n",
    "arr = np.array([[i,l,j,r] for (i,l,j,r) in per_sample_info], dtype=object)\n",
    "if arr.size:\n",
    "    clean_vals = arr[arr[:,1]==0][:,2].astype(float) if (arr[:,1]==0).any() else np.array([])\n",
    "    troj_vals  = arr[arr[:,1]==1][:,2].astype(float) if (arr[:,1]==1).any() else np.array([])\n",
    "    clean_errs = arr[arr[:,1]==0][:,3].astype(float) if (arr[:,1]==0).any() else np.array([])\n",
    "    troj_errs  = arr[arr[:,1]==1][:,3].astype(float) if (arr[:,1]==1).any() else np.array([])\n",
    "\n",
    "    def mean_std(a): return (a.mean(), a.std()) if len(a)>0 else (0.0,0.0)\n",
    "\n",
    "    c_mean, c_std = mean_std(clean_vals)\n",
    "    t_mean, t_std = mean_std(troj_vals)\n",
    "    ce_mean, ce_std = mean_std(clean_errs)\n",
    "    te_mean, te_std = mean_std(troj_errs)\n",
    "\n",
    "    print(\"\\nJacobian norms & FD relative errors (aggregated):\")\n",
    "    print(f\" Clean subgraphs:  avg_norm={c_mean:.4f} ± {c_std:.4f}, avg_FDrel={ce_mean:.4e} ± {ce_std:.4e}\")\n",
    "    print(f\" Trojan subgraphs: avg_norm={t_mean:.4f} ± {t_std:.4f}, avg_FDrel={te_mean:.4e} ± {te_std:.4e}\")\n",
    "\n",
    "    print(\"\\nSample preview (first 6): (idx,label,jacobian_frob,FD_rel_err)\")\n",
    "    for t in per_sample_info[:6]:\n",
    "        print(t)\n",
    "else:\n",
    "    print(\"No Jacobian samples computed (selected set empty).\")\n",
    "\n",
    "print(\"\\nDone. (Order: PGD perturbation -> full-test evaluation -> Jacobian computed at perturbed inputs.)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7087063-000b-40cf-a18c-d0914dc4195c",
   "metadata": {},
   "source": [
    "#### Local Lipschitz Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04efee09-a3d9-4711-adc0-0c6aabf08af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected perturbation pool: {0: 11, 1: 20}\n",
      "\n",
      "Running Lipschitz-directed PGD for selected subgraphs (this may take a while)...\n",
      "? Finished perturbations.\n",
      "\n",
      "============= Robustness Evaluation (Full Test Set) =============\n",
      "Accuracy: 96.08%\n",
      "Precision: 0.9651, Recall: 0.9608, F1: 0.9622\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.7692    0.9091    0.8333        11\n",
      "      trojan     0.9888    0.9670    0.9778        91\n",
      "\n",
      "    accuracy                         0.9608       102\n",
      "   macro avg     0.8790    0.9381    0.9056       102\n",
      "weighted avg     0.9651    0.9608    0.9622       102\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  1]\n",
      " [ 3 88]]\n",
      "\n",
      "Selected subgraphs: 31. Flipped after attack: 3 (9.68%).\n",
      "\n",
      "Computing Local Lipschitz constants + FD relative errors (on perturbed subgraphs)...\n",
      "\n",
      "--- Local Lipschitz Constants (on perturbed subgraphs) ---\n",
      " Clean:  avg_L=0.4934 ± 0.2302, avg_FDrel=1.4172e-02 ± 1.3608e-02\n",
      " Trojan: avg_L=1.0035 ± 2.6309, avg_FDrel=7.5908e-01 ± 2.5349e+00\n",
      "\n",
      "Sample preview (first 6): (idx,label,L,FD_rel_err)\n",
      "(14, 0, 0.4797338545322418, 0.005441294517368078)\n",
      "(33, 0, 0.7513017654418945, 0.0013163184048607945)\n",
      "(63, 0, 0.34226641058921814, 0.039065077900886536)\n",
      "(12, 0, 0.18972018361091614, 0.0031769643537700176)\n",
      "(18, 0, 0.9597011208534241, 0.002831539139151573)\n",
      "(36, 0, 0.6635523438453674, 0.004098290577530861)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- Local Lipschitz (Subgraph-Level) -----------------------\n",
    "import torch, numpy as np, torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# ----- parameters (tune if needed) -----\n",
    "PER_CLASS = 20      # up to this many per class from test set (min with available)\n",
    "FD_EPS = 1e-3\n",
    "EPSILON = 5.0       # L2 budget for PGD (feature units)\n",
    "ALPHA = 1.0         # PGD step size\n",
    "NUM_ITERS = 30      # PGD iters\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# ----- quick sanity -----\n",
    "if 'model' not in globals() or 'test_loader' not in globals():\n",
    "    raise RuntimeError(\"Required variables `model` and `test_loader` must exist in the notebook.\")\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# ----- get dataset (robust to DataLoader type) -----\n",
    "dataset = test_loader.dataset\n",
    "n_test = len(dataset)\n",
    "\n",
    "# extract labels array\n",
    "labels_np = np.array([int(d.y.item() if hasattr(d.y, 'item') else d.y[0].item()) for d in dataset])\n",
    "\n",
    "# ----- select indices (PER_CLASS per class) -----\n",
    "rng = np.random.default_rng(SEED)\n",
    "selected = []\n",
    "for cls in [0, 1]:\n",
    "    idxs = np.where(labels_np == cls)[0].tolist()\n",
    "    if len(idxs) == 0:\n",
    "        continue\n",
    "    k = min(PER_CLASS, len(idxs))\n",
    "    chosen = rng.choice(idxs, size=k, replace=False).tolist()\n",
    "    selected.extend(chosen)\n",
    "selected = np.array(selected, dtype=np.int64)\n",
    "print(\"Selected perturbation pool:\", {0:int((labels_np[selected]==0).sum()), 1:int((labels_np[selected]==1).sum())})\n",
    "\n",
    "# ----- perturb each selected subgraph using top-right singular vector init + PGD -----\n",
    "perturbed_map = {}   # idx -> perturbed_x (on DEVICE)\n",
    "orig_preds_list = []\n",
    "adv_preds_list = []\n",
    "\n",
    "print(\"\\nRunning Lipschitz-directed PGD for selected subgraphs (this may take a while)...\")\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x_orig = data.x.detach().clone().to(DEVICE)            # (num_nodes, feat_dim)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    y_true = torch.tensor([int(data.y.item())], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    # helper: produce batch vector of zeros for single graph\n",
    "    def batch_for(x):\n",
    "        return torch.zeros(x.size(0), dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    # define f_local that accepts x (num_nodes,feat) and returns logits (num_classes,)\n",
    "    def f_local(x):\n",
    "        return model(x, edge_index, batch_for(x)).squeeze(0)\n",
    "\n",
    "    # Compute Jacobian at x_orig (shape: (num_classes, num_nodes, feat_dim))\n",
    "    # NOTE: we compute Jacobian once per graph to get singular vector init\n",
    "    try:\n",
    "        J = torch.autograd.functional.jacobian(f_local, x_orig)    # (C, N, F)\n",
    "    except RuntimeError:\n",
    "        # if autograd fails due to graph size, compute per-output jac manually (slower)\n",
    "        logits0 = f_local(x_orig).detach()\n",
    "        C = logits0.shape[0]\n",
    "        rows = []\n",
    "        for c in range(C):\n",
    "            def scalar_f(x, cidx=c):\n",
    "                return f_local(x)[cidx]\n",
    "            row = torch.autograd.functional.jacobian(scalar_f, x_orig)  # (N, F)\n",
    "            rows.append(row.unsqueeze(0))\n",
    "        J = torch.cat(rows, dim=0)  # (C, N, F)\n",
    "\n",
    "    # flatten J to shape (C, d) where d = N * F\n",
    "    C = J.shape[0]\n",
    "    d = int(J.shape[1] * J.shape[2])\n",
    "    J_flat = J.reshape(C, d)\n",
    "\n",
    "    # get top-right singular vector v (length d)\n",
    "    try:\n",
    "        _, S, Vh = torch.linalg.svd(J_flat, full_matrices=False)\n",
    "        v = Vh[0, :].detach().to(DEVICE)   # (d,)\n",
    "    except RuntimeError:\n",
    "        # fallback random direction\n",
    "        v = torch.randn(d, device=DEVICE)\n",
    "    if v.norm().item() > 0:\n",
    "        v = v / (v.norm() + 1e-12)\n",
    "    else:\n",
    "        v = torch.randn_like(v).to(DEVICE); v = v / (v.norm() + 1e-12)\n",
    "\n",
    "    # initialize adversarial x_adv (reshape v -> (N,F))\n",
    "    v_mat = v.view(x_orig.shape[0], x_orig.shape[1])\n",
    "    x_adv = (x_orig + 0.5 * EPSILON * v_mat).detach().clone().requires_grad_(True)\n",
    "\n",
    "    # PGD loop maximize CE loss (untargeted)\n",
    "    for it in range(NUM_ITERS):\n",
    "        logits = model(x_adv, edge_index, batch_for(x_adv))\n",
    "        loss = F.cross_entropy(logits, y_true)\n",
    "        grad = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "        gn = grad.view(-1)\n",
    "        gnorm = gn.norm().item()\n",
    "        if gnorm == 0:\n",
    "            break\n",
    "        step = ALPHA * (grad / (gnorm + 1e-12))\n",
    "        x_adv = (x_adv + step).detach()\n",
    "        # project to L2-ball around x_orig\n",
    "        delta = (x_adv - x_orig).view(-1)\n",
    "        dnorm = delta.norm().item()\n",
    "        if dnorm > EPSILON:\n",
    "            delta = delta * (EPSILON / (dnorm + 1e-12))\n",
    "            x_adv = (x_orig + delta.view_as(x_orig)).detach()\n",
    "        x_adv = x_adv.requires_grad_(True)\n",
    "\n",
    "    # finalize\n",
    "    x_adv_final = x_adv.detach()\n",
    "    perturbed_map[int(idx)] = x_adv_final\n",
    "\n",
    "    # store preds for flip statistics\n",
    "    with torch.no_grad():\n",
    "        p_orig = f_local(x_orig).argmax().item()\n",
    "        p_adv  = f_local(x_adv_final).argmax().item()\n",
    "    orig_preds_list.append(p_orig)\n",
    "    adv_preds_list.append(p_adv)\n",
    "\n",
    "print(\"? Finished perturbations.\")\n",
    "\n",
    "# ----- Evaluate full test set using perturbed subgraphs for selected indices -----\n",
    "print(\"\\n============= Robustness Evaluation (Full Test Set) =============\")\n",
    "preds_all = []\n",
    "labels_all = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dataset):\n",
    "        x = data.x.detach().clone().to(DEVICE)\n",
    "        edge_index = data.edge_index.to(DEVICE)\n",
    "        lab = int(data.y.item())\n",
    "        if int(i) in perturbed_map:\n",
    "            x_eval = perturbed_map[int(i)]\n",
    "        else:\n",
    "            x_eval = x\n",
    "        logits = model(x_eval, edge_index, batch_for(x_eval))\n",
    "        preds_all.append(int(logits.argmax(dim=1).item()))\n",
    "        labels_all.append(lab)\n",
    "\n",
    "preds_all = np.array(preds_all)\n",
    "labels_all = np.array(labels_all)\n",
    "\n",
    "acc = (preds_all == labels_all).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_all, preds_all, average='weighted', zero_division=0)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(labels_all, preds_all, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "\n",
    "# flip statistics\n",
    "num_flips = int((np.array(orig_preds_list) != np.array(adv_preds_list)).sum())\n",
    "print(f\"\\nSelected subgraphs: {len(selected)}. Flipped after attack: {num_flips} ({100.0*num_flips/len(selected):.2f}%).\")\n",
    "\n",
    "# ----- Now compute Local Lipschitz constants and FD relative error ON THE PERTURBED SUBGRAPHS -----\n",
    "print(\"\\nComputing Local Lipschitz constants + FD relative errors (on perturbed subgraphs)...\")\n",
    "per_sample_info = []   # tuples (dataset_idx, label, sigma_max, fd_rel_err)\n",
    "for i, idx in enumerate(selected):\n",
    "    data = dataset[int(idx)]\n",
    "    x_adv = perturbed_map[int(idx)].detach().clone().to(DEVICE).requires_grad_(True)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    label = int(data.y.item())\n",
    "\n",
    "    # define f_local on perturbed input\n",
    "    def f_local_pert(x):\n",
    "        return model(x, edge_index, batch_for(x)).squeeze(0)\n",
    "\n",
    "    # jacobian shape (C, N, F)\n",
    "    try:\n",
    "        J = torch.autograd.functional.jacobian(f_local_pert, x_adv).detach()   # (C, N, F)\n",
    "    except RuntimeError:\n",
    "        # fallback per-output jac (slower)\n",
    "        logits0 = f_local_pert(x_adv).detach()\n",
    "        C = logits0.shape[0]\n",
    "        rows = []\n",
    "        for c in range(C):\n",
    "            def scalar_f(x, cidx=c):\n",
    "                return f_local_pert(x)[cidx]\n",
    "            row = torch.autograd.functional.jacobian(scalar_f, x_adv)\n",
    "            rows.append(row.unsqueeze(0))\n",
    "        J = torch.cat(rows, dim=0)\n",
    "\n",
    "    C = J.shape[0]\n",
    "    d = int(J.shape[1] * J.shape[2])\n",
    "    J_flat = J.reshape(C, d)\n",
    "\n",
    "    # spectral norm via SVD (largest singular value)\n",
    "    try:\n",
    "        _, S, _ = torch.linalg.svd(J_flat, full_matrices=False)\n",
    "        sigma_max = float(S[0].item())\n",
    "    except RuntimeError:\n",
    "        # fallback via eigen on JJT\n",
    "        JJT = (J_flat @ J_flat.T).cpu().numpy()\n",
    "        eigvals = np.linalg.eigvalsh(JJT)\n",
    "        sigma_max = float(np.sqrt(max(eigvals.max(), 0.0)))\n",
    "\n",
    "    # finite-difference relative error\n",
    "    delta_fd = FD_EPS * torch.randn_like(x_adv).to(DEVICE).view(-1)   # length d\n",
    "    pred_change = (J_flat @ delta_fd)                 # (C,)\n",
    "    f0 = f_local_pert(x_adv).detach()\n",
    "    f0p = f_local_pert((x_adv + delta_fd.view_as(x_adv))).detach()\n",
    "    actual_change = f0p - f0\n",
    "    fd_rel_err = (torch.norm(pred_change - actual_change) / (torch.norm(actual_change) + 1e-8)).item()\n",
    "\n",
    "    per_sample_info.append((int(idx), label, float(sigma_max), float(fd_rel_err)))\n",
    "\n",
    "# aggregate and print\n",
    "clean_stats = [p for p in per_sample_info if p[1] == 0]\n",
    "troj_stats  = [p for p in per_sample_info if p[1] == 1]\n",
    "\n",
    "def aggs(stats):\n",
    "    if not stats:\n",
    "        return (0.0, 0.0, 0.0, 0.0)\n",
    "    Ls = np.array([s[2] for s in stats])\n",
    "    Es = np.array([s[3] for s in stats])\n",
    "    return (Ls.mean(), Ls.std(), Es.mean(), Es.std())\n",
    "\n",
    "cL_mean, cL_std, cE_mean, cE_std = aggs(clean_stats)\n",
    "tL_mean, tL_std, tE_mean, tE_std = aggs(troj_stats)\n",
    "\n",
    "print(\"\\n--- Local Lipschitz Constants (on perturbed subgraphs) ---\")\n",
    "print(f\" Clean:  avg_L={cL_mean:.4f} ± {cL_std:.4f}, avg_FDrel={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_L={tL_mean:.4f} ± {tL_std:.4f}, avg_FDrel={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "\n",
    "print(\"\\nSample preview (first 6): (idx,label,L,FD_rel_err)\")\n",
    "for p in per_sample_info[:6]:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9afa21a-41a6-4a09-8013-5d6ca81afa37",
   "metadata": {},
   "source": [
    "#### Hessian-based Curvature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea548c07-f25d-43c9-b2fb-7b8a216ab4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected pool: clean=11, trojan=20\n",
      "\n",
      "Computing Hessian curvature proxies on selected subgraphs...\n",
      "\n",
      "Constructing Hessian-aligned perturbations...\n",
      "\n",
      "================ Robustness Evaluation (Full Test Set: perturbed+clean) ===============\n",
      "Accuracy: 93.14%\n",
      "Precision: 0.9289, Recall: 0.9314, F1: 0.9299\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.7000    0.6364    0.6667        11\n",
      "      trojan     0.9565    0.9670    0.9617        91\n",
      "\n",
      "    accuracy                         0.9314       102\n",
      "   macro avg     0.8283    0.8017    0.8142       102\n",
      "weighted avg     0.9289    0.9314    0.9299       102\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  4]\n",
      " [ 3 88]]\n",
      "\n",
      "Selected subgraphs: 31. Flipped after perturbation: 6 (19.35%).\n",
      "\n",
      "--- Hessian Curvature Stats (grad outer-product proxy) ---\n",
      " Clean:  avg_lambda=0.0001 ± 0.0003, avg_FDrel=9.4980e-01 ± 3.6951e-02\n",
      " Trojan: avg_lambda=0.0001 ± 0.0003, avg_FDrel=5.0204e-01 ± 4.5488e-01\n",
      "\n",
      "Sample preview (first 6): (idx,label,lambda,FD_rel_err)\n",
      "(14, 0, 3.5693579686088897e-06, 0.9636353130872353)\n",
      "(33, 0, 1.0263525662213891e-06, 0.939115960334291)\n",
      "(63, 0, 1.4761330133378008e-05, 0.9360671887854106)\n",
      "(12, 0, 3.841061847433136e-08, 0.9755780132860312)\n",
      "(18, 0, 0.0009466093951016365, 1.001560334008069)\n",
      "(36, 0, 6.211273803136792e-06, 0.9296848185655465)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- Hessian-Based Curvature (Subgraph-Level) -----------------------\n",
    "import torch, numpy as np, torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# ----- parameters -----\n",
    "PER_CLASS = 20        # subgraphs per class\n",
    "FD_EPS = 5e-3         # finite diff epsilon\n",
    "TRIALS_PER_GRAPH = 5  # #trials for FD error\n",
    "PERT_P = 10.0          # L2 magnitude for Hessian-aligned perturbation\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "if 'model' not in globals() or 'test_loader' not in globals():\n",
    "    raise RuntimeError(\"Need `model` and `test_loader` in environment.\")\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "dataset = test_loader.dataset\n",
    "n_test = len(dataset)\n",
    "labels_np = np.array([int(d.y.item()) for d in dataset])\n",
    "\n",
    "# ----- select PER_CLASS subgraphs per class -----\n",
    "rng = np.random.default_rng(SEED)\n",
    "selected = []\n",
    "for cls in [0, 1]:\n",
    "    idxs = np.where(labels_np == cls)[0].tolist()\n",
    "    k = min(PER_CLASS, len(idxs))\n",
    "    chosen = rng.choice(idxs, size=k, replace=False).tolist()\n",
    "    selected.extend(chosen)\n",
    "selected = np.array(selected, dtype=np.int64)\n",
    "print(f\"Selected pool: clean={int((labels_np[selected]==0).sum())}, trojan={int((labels_np[selected]==1).sum())}\")\n",
    "\n",
    "# ----- base predictions -----\n",
    "def batch_for(x): return torch.zeros(x.size(0), dtype=torch.long, device=DEVICE)\n",
    "with torch.no_grad():\n",
    "    base_preds = []\n",
    "    for data in dataset:\n",
    "        logits = model(data.x.to(DEVICE), data.edge_index.to(DEVICE), batch_for(data.x.to(DEVICE)))\n",
    "        base_preds.append(int(logits.argmax()))\n",
    "base_preds = np.array(base_preds)\n",
    "\n",
    "# ----- compute gradient norms + FD relative errors -----\n",
    "per_sample_info = []  # (idx, label, lambda_max, avg_rel_err)\n",
    "\n",
    "print(\"\\nComputing Hessian curvature proxies on selected subgraphs...\")\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x0 = data.x.detach().clone().to(DEVICE).requires_grad_(True)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "\n",
    "    # predicted class at x0\n",
    "    with torch.no_grad():\n",
    "        logits = model(x0, edge_index, batch_for(x0))\n",
    "    pred_class = int(logits.argmax().item())\n",
    "\n",
    "    def h(x):\n",
    "        return F.log_softmax(model(x, edge_index, batch_for(x)).squeeze(0), dim=0)[pred_class]\n",
    "\n",
    "    h0 = h(x0)\n",
    "    g = torch.autograd.grad(h0, x0, retain_graph=False, create_graph=False)[0].detach()\n",
    "\n",
    "    lambda_max = float(g.norm(p=2).item() ** 2)\n",
    "\n",
    "    # FD relative error\n",
    "    errs = []\n",
    "    for _ in range(TRIALS_PER_GRAPH):\n",
    "        delta = FD_EPS * torch.randn_like(x0).to(DEVICE)\n",
    "        gt_delta = float((g * delta).sum().item())\n",
    "        pred_second = 0.5 * (gt_delta ** 2)\n",
    "        actual_second = float((h(x0 + delta) - h0 - (g * delta).sum()).item())\n",
    "        rel_err = abs(pred_second - actual_second) / (abs(actual_second) + 1e-8)\n",
    "        errs.append(rel_err)\n",
    "    avg_rel_err = float(np.mean(errs))\n",
    "\n",
    "    per_sample_info.append((int(idx), int(data.y.item()), lambda_max, avg_rel_err))\n",
    "\n",
    "# ----- build Hessian-aligned perturbations -----\n",
    "print(\"\\nConstructing Hessian-aligned perturbations...\")\n",
    "perturbed_map = {}\n",
    "for (idx, label, lambda_val, avg_rel_err) in per_sample_info:\n",
    "    data = dataset[int(idx)]\n",
    "    x0 = data.x.detach().clone().to(DEVICE).requires_grad_(True)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "\n",
    "    def h(x):\n",
    "        return F.log_softmax(model(x, edge_index, batch_for(x)).squeeze(0), dim=0)[int(data.y.item())]\n",
    "\n",
    "    g = torch.autograd.grad(h(x0), x0, retain_graph=False, create_graph=False)[0].detach()\n",
    "    gnorm = g.norm().item()\n",
    "    if gnorm < 1e-12:\n",
    "        dir_vec = torch.randn_like(x0).to(DEVICE)\n",
    "    else:\n",
    "        dir_vec = - g / (gnorm + 1e-12)\n",
    "\n",
    "    delta = (PERT_P * dir_vec).detach()\n",
    "    perturbed_map[int(idx)] = (x0 + delta).detach()\n",
    "\n",
    "# ----- evaluate on full test set -----\n",
    "print(\"\\n================ Robustness Evaluation (Full Test Set: perturbed+clean) ===============\")\n",
    "preds_all, labels_all = [], []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dataset):\n",
    "        x = data.x.to(DEVICE)\n",
    "        if int(i) in perturbed_map:\n",
    "            x_eval = perturbed_map[int(i)]\n",
    "        else:\n",
    "            x_eval = x\n",
    "        logits = model(x_eval, data.edge_index.to(DEVICE), batch_for(x_eval))\n",
    "        preds_all.append(int(logits.argmax()))\n",
    "        labels_all.append(int(data.y.item()))\n",
    "\n",
    "preds_all = np.array(preds_all)\n",
    "labels_all = np.array(labels_all)\n",
    "\n",
    "acc = (preds_all == labels_all).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_all, preds_all, average='weighted', zero_division=0)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(labels_all, preds_all, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "\n",
    "# ----- flip stats -----\n",
    "orig_sel_preds = base_preds[selected]\n",
    "adv_sel_preds = np.array([preds_all[i] for i in selected])\n",
    "num_flips = int((orig_sel_preds != adv_sel_preds).sum())\n",
    "print(f\"\\nSelected subgraphs: {len(selected)}. Flipped after perturbation: {num_flips} ({100.0*num_flips/len(selected):.2f}%).\")\n",
    "\n",
    "# ----- aggregate curvature stats -----\n",
    "clean_stats = [p for p in per_sample_info if p[1] == 0]\n",
    "troj_stats  = [p for p in per_sample_info if p[1] == 1]\n",
    "\n",
    "def summarize(stats):\n",
    "    if not stats: return (0.0,0.0,0.0,0.0)\n",
    "    Ls = np.array([s[2] for s in stats])\n",
    "    Es = np.array([s[3] for s in stats])\n",
    "    return (Ls.mean(), Ls.std(), Es.mean(), Es.std())\n",
    "\n",
    "cL_mean, cL_std, cE_mean, cE_std = summarize(clean_stats)\n",
    "tL_mean, tL_std, tE_mean, tE_std = summarize(troj_stats)\n",
    "\n",
    "print(\"\\n--- Hessian Curvature Stats (grad outer-product proxy) ---\")\n",
    "print(f\" Clean:  avg_lambda={cL_mean:.4f} ± {cL_std:.4f}, avg_FDrel={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_lambda={tL_mean:.4f} ± {tL_std:.4f}, avg_FDrel={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "\n",
    "print(\"\\nSample preview (first 6): (idx,label,lambda,FD_rel_err)\")\n",
    "for p in per_sample_info[:6]:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc7cd75-26a8-4c6f-a206-0ba4c88cf505",
   "metadata": {},
   "source": [
    "#### Prediction Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c0ca400-e1dc-455c-be9a-4a0a56fb5f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected pool: clean=11, trojan=20\n",
      "\n",
      "Running PGD perturbations on selected subgraphs...\n",
      "? Finished perturbations.\n",
      "\n",
      "================ Robustness Evaluation (Full Test Set: perturbed+clean) ===============\n",
      "Accuracy: 96.08%\n",
      "Precision: 0.9651, Recall: 0.9608, F1: 0.9622\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.7692    0.9091    0.8333        11\n",
      "      trojan     0.9888    0.9670    0.9778        91\n",
      "\n",
      "    accuracy                         0.9608       102\n",
      "   macro avg     0.8790    0.9381    0.9056       102\n",
      "weighted avg     0.9651    0.9608    0.9622       102\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  1]\n",
      " [ 3 88]]\n",
      "\n",
      "Selected subgraphs: 31. Flipped after perturbation: 3 (9.68%).\n",
      "\n",
      "--- Prediction Margin Stats (on perturbed subgraphs) ---\n",
      " Clean:  avg_margin=2.8802 ± 0.9243, avg_FDrel=2.6496e-04 ± 4.0346e-04\n",
      " Trojan: avg_margin=88.2754 ± 267.9658, avg_FDrel=6.3873e-05 ± 8.6440e-05\n",
      "\n",
      "Sample preview (first 6): (idx,label,margin,FD_rel_err)\n",
      "(14, 0, 3.277017593383789, 0.00011118161021237533)\n",
      "(33, 0, 3.455471992492676, 8.099638524306989e-05)\n",
      "(63, 0, 2.385219097137451, 9.291836594227597e-05)\n",
      "(12, 0, 4.832814931869507, 3.1079865486335743e-06)\n",
      "(18, 0, 1.8277963995933533, 0.0008943469939265855)\n",
      "(36, 0, 1.3633912205696106, 0.0013017762824476388)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- Prediction Margin (Subgraph-Level) -----------------------\n",
    "import torch, numpy as np, torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# ----- parameters -----\n",
    "PER_CLASS = 20        # subgraphs per class\n",
    "EPSILON = 5.0         # perturbation budget (strong)\n",
    "ALPHA = 0.4           # PGD step size\n",
    "NUM_ITERS = 15        # PGD iterations\n",
    "FD_EPS = 1e-3         # finite-difference perturbation\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "if 'model' not in globals() or 'test_loader' not in globals():\n",
    "    raise RuntimeError(\"Need `model` and `test_loader` in environment.\")\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "dataset = test_loader.dataset\n",
    "n_test = len(dataset)\n",
    "labels_np = np.array([int(d.y.item()) for d in dataset])\n",
    "\n",
    "# ----- select PER_CLASS subgraphs per class -----\n",
    "rng = np.random.default_rng(SEED)\n",
    "selected = []\n",
    "for cls in [0, 1]:\n",
    "    idxs = np.where(labels_np == cls)[0].tolist()\n",
    "    k = min(PER_CLASS, len(idxs))\n",
    "    chosen = rng.choice(idxs, size=k, replace=False).tolist()\n",
    "    selected.extend(chosen)\n",
    "selected = np.array(selected, dtype=np.int64)\n",
    "print(f\"Selected pool: clean={int((labels_np[selected]==0).sum())}, trojan={int((labels_np[selected]==1).sum())}\")\n",
    "\n",
    "# helper for batching\n",
    "def batch_for(x): \n",
    "    return torch.zeros(x.size(0), dtype=torch.long, device=DEVICE)\n",
    "\n",
    "# ----- base predictions -----\n",
    "with torch.no_grad():\n",
    "    base_preds = []\n",
    "    for data in dataset:\n",
    "        logits = model(data.x.to(DEVICE), data.edge_index.to(DEVICE), batch_for(data.x.to(DEVICE)))\n",
    "        base_preds.append(int(logits.argmax()))\n",
    "base_preds = np.array(base_preds)\n",
    "\n",
    "# ----- adversarial perturbations (PGD) -----\n",
    "perturbed_map = {}\n",
    "\n",
    "print(\"\\nRunning PGD perturbations on selected subgraphs...\")\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x_orig = data.x.detach().clone().to(DEVICE)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    y_scalar = int(data.y.item())\n",
    "    target = torch.tensor([y_scalar], dtype=torch.long, device=DEVICE)  # shape (1,)\n",
    "\n",
    "    # random init inside epsilon-ball\n",
    "    delta = torch.randn_like(x_orig).to(DEVICE)\n",
    "    delta = EPSILON * delta / (delta.norm() + 1e-12)\n",
    "    x_adv = (x_orig + delta).detach().clone().requires_grad_(True)\n",
    "\n",
    "    for it in range(NUM_ITERS):\n",
    "        logits = model(x_adv, edge_index, batch_for(x_adv))  # shape (1, C)\n",
    "        loss = F.cross_entropy(logits, target)               # target shape (1,)\n",
    "        grad = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "\n",
    "        step = ALPHA * grad / (grad.norm() + 1e-12)\n",
    "        x_adv = (x_adv + step).detach()\n",
    "        delta = x_adv - x_orig\n",
    "        if delta.norm() > EPSILON:\n",
    "            delta = delta * (EPSILON / (delta.norm() + 1e-12))\n",
    "            x_adv = (x_orig + delta).detach()\n",
    "        x_adv = x_adv.requires_grad_(True)\n",
    "\n",
    "    perturbed_map[int(idx)] = x_adv.detach()\n",
    "\n",
    "print(\"? Finished perturbations.\")\n",
    "\n",
    "# ----- evaluate on full test set (perturbed + clean) -----\n",
    "print(\"\\n================ Robustness Evaluation (Full Test Set: perturbed+clean) ===============\")\n",
    "preds_all, labels_all = [], []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dataset):\n",
    "        x = data.x.to(DEVICE)\n",
    "        if int(i) in perturbed_map:\n",
    "            x_eval = perturbed_map[int(i)]\n",
    "        else:\n",
    "            x_eval = x\n",
    "        logits = model(x_eval, data.edge_index.to(DEVICE), batch_for(x_eval))\n",
    "        preds_all.append(int(logits.argmax()))\n",
    "        labels_all.append(int(data.y.item()))\n",
    "\n",
    "preds_all = np.array(preds_all)\n",
    "labels_all = np.array(labels_all)\n",
    "\n",
    "acc = (preds_all == labels_all).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_all, preds_all, average='weighted', zero_division=0)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(labels_all, preds_all, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "\n",
    "# ----- flip stats -----\n",
    "orig_sel_preds = base_preds[selected]\n",
    "adv_sel_preds = np.array([preds_all[i] for i in selected])\n",
    "num_flips = int((orig_sel_preds != adv_sel_preds).sum())\n",
    "print(f\"\\nSelected subgraphs: {len(selected)}. Flipped after perturbation: {num_flips} ({100.0*num_flips/len(selected):.2f}%).\")\n",
    "\n",
    "# ----- compute prediction margin + FD relative error -----\n",
    "per_sample_info = []  # (idx, label, margin, FD_rel_err)\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x_eval = perturbed_map[int(idx)]\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x_eval, edge_index, batch_for(x_eval)).squeeze(0)\n",
    "    pred_class = int(logits.argmax().item())\n",
    "    pred_logit = logits[pred_class].item()\n",
    "    other_logits = logits.clone()\n",
    "    other_logits[pred_class] = -float('inf')\n",
    "    second_max = other_logits.max().item()\n",
    "    margin = pred_logit - second_max\n",
    "\n",
    "    # finite difference check\n",
    "    delta = FD_EPS * torch.randn_like(x_eval).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits_p = model(x_eval + delta, edge_index, batch_for(x_eval)).squeeze(0)\n",
    "    pred_logit_p = logits_p[pred_class].item()\n",
    "    other_logits_p = logits_p.clone()\n",
    "    other_logits_p[pred_class] = -float('inf')\n",
    "    second_max_p = other_logits_p.max().item()\n",
    "    margin_p = pred_logit_p - second_max_p\n",
    "\n",
    "    rel_err = abs(margin - margin_p) / (abs(margin_p) + 1e-12)\n",
    "    per_sample_info.append((int(idx), int(data.y.item()), float(margin), float(rel_err)))\n",
    "\n",
    "# ----- aggregate stats -----\n",
    "clean_stats = [p for p in per_sample_info if p[1] == 0]\n",
    "troj_stats  = [p for p in per_sample_info if p[1] == 1]\n",
    "\n",
    "def summarize(stats):\n",
    "    if not stats: return (0.0,0.0,0.0,0.0)\n",
    "    Ms = np.array([s[2] for s in stats])\n",
    "    Es = np.array([s[3] for s in stats])\n",
    "    return (Ms.mean(), Ms.std(), Es.mean(), Es.std())\n",
    "\n",
    "cM_mean, cM_std, cE_mean, cE_std = summarize(clean_stats)\n",
    "tM_mean, tM_std, tE_mean, tE_std = summarize(troj_stats)\n",
    "\n",
    "print(\"\\n--- Prediction Margin Stats (on perturbed subgraphs) ---\")\n",
    "print(f\" Clean:  avg_margin={cM_mean:.4f} ± {cM_std:.4f}, avg_FDrel={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_margin={tM_mean:.4f} ± {tM_std:.4f}, avg_FDrel={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "\n",
    "print(\"\\nSample preview (first 6): (idx,label,margin,FD_rel_err)\")\n",
    "for p in per_sample_info[:6]:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18752b3f-6403-4881-8d1e-adf2d3e03f33",
   "metadata": {},
   "source": [
    "#### Adversarial Robustness Radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6561ddc0-ac9e-4751-bed6-4b7c65cdb85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing Adversarial Robustness Radius (ARR) for selected perturbed subgraphs...\n",
      "  processed 20/31 subgraphs...\n",
      "? Done ARR computation. Time elapsed: 23.6s\n",
      "\n",
      "--- Adversarial Robustness Radius (ARR) Stats ---\n",
      "Class      Avg Radius ± Std   Avg Rel. Error ± Std\n",
      "----------------------------------------------------\n",
      "clean      20.0000 ± 0.0000      0.0000e+00 ± 0.0000e+00\n",
      "trojan     20.0000 ± 0.0000      0.0000e+00 ± 0.0000e+00\n",
      "\n",
      "Overall ARR: Avg Radius: 20.0000 ± 0.0000\n",
      "Overall ARR: Avg Relative Error: 0.0000e+00 ± 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- Adversarial Robustness Radius (Subgraph-Level) -----------------------\n",
    "import time\n",
    "\n",
    "# ----- helpers -----\n",
    "def f_for_subgraph(x_tensor, data):\n",
    "    \"\"\"Return logits for given subgraph with node features replaced by x_tensor.\"\"\"\n",
    "    x_tensor = x_tensor.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        out = model(x_tensor, data.edge_index.to(DEVICE), batch_for(x_tensor))\n",
    "    return out.squeeze(0)\n",
    "\n",
    "def adversarial_radius_for_subgraph(data, x0, initial_epsilon=1e-3, growth_factor=1.25,\n",
    "                                    max_epsilon=20.0, bs_iters=10, num_trials=6):\n",
    "    \"\"\"Estimate minimal perturbation radius that flips prediction (around perturbed point).\"\"\"\n",
    "    with torch.no_grad():\n",
    "        base_out = model(x0, data.edge_index.to(DEVICE), batch_for(x0))\n",
    "        y0 = int(base_out.argmax().item())\n",
    "\n",
    "    def is_same(x):\n",
    "        out = f_for_subgraph(x, data)\n",
    "        return int(out.argmax().item()) == y0\n",
    "\n",
    "    radii = []\n",
    "    for _ in range(num_trials):\n",
    "        d = torch.randn_like(x0)\n",
    "        d = d / (d.norm() + 1e-12)\n",
    "\n",
    "        eps = initial_epsilon\n",
    "        while eps < max_epsilon and is_same(x0 + eps * d):\n",
    "            eps *= growth_factor\n",
    "\n",
    "        if eps >= max_epsilon:\n",
    "            candidate = max_epsilon\n",
    "        else:\n",
    "            low, high = eps / growth_factor, eps\n",
    "            for _ in range(bs_iters):\n",
    "                mid = 0.5 * (low + high)\n",
    "                if is_same(x0 + mid * d):\n",
    "                    low = mid\n",
    "                else:\n",
    "                    high = mid\n",
    "            candidate = float(high)\n",
    "        radii.append(candidate)\n",
    "    return float(min(radii))\n",
    "\n",
    "def adversarial_radius_relerr(data, x0):\n",
    "    r1 = adversarial_radius_for_subgraph(data, x0, growth_factor=2.25, bs_iters=10, num_trials=6)\n",
    "    r2 = adversarial_radius_for_subgraph(data, x0, growth_factor=1.4, bs_iters=12, num_trials=6)\n",
    "    rel_err = abs(r1 - r2) / (abs(r2) + 1e-12)\n",
    "    return r1, rel_err\n",
    "\n",
    "# ----- ARR computation on selected perturbed subgraphs -----\n",
    "class_names = ['clean', 'trojan']\n",
    "class_adv_radius = {cn: [] for cn in class_names}\n",
    "class_rel_errors = {cn: [] for cn in class_names}\n",
    "all_radii, all_rel_errs = [], []\n",
    "\n",
    "t0 = time.time()\n",
    "print(\"\\nComputing Adversarial Robustness Radius (ARR) for selected perturbed subgraphs...\")\n",
    "for i, idx in enumerate(selected):\n",
    "    idx = int(idx)\n",
    "    data = dataset[idx]\n",
    "    label = int(data.y.item())\n",
    "    cn = class_names[label]\n",
    "\n",
    "    x0 = perturbed_map[idx].clone().detach().to(DEVICE)  # start from perturbed features\n",
    "    r, rel = adversarial_radius_relerr(data, x0)\n",
    "\n",
    "    class_adv_radius[cn].append(r)\n",
    "    class_rel_errors[cn].append(rel)\n",
    "    all_radii.append(r)\n",
    "    all_rel_errs.append(rel)\n",
    "\n",
    "    if (i+1) % 20 == 0:\n",
    "        print(f\"  processed {i+1}/{len(selected)} subgraphs...\")\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"? Done ARR computation. Time elapsed: {t1-t0:.1f}s\")\n",
    "\n",
    "# ----- Reporting ARR aggregates -----\n",
    "print(\"\\n--- Adversarial Robustness Radius (ARR) Stats ---\")\n",
    "print(\"{:<10s} {:>14s} {:>22s}\".format(\"Class\", \"Avg Radius ± Std\", \"Avg Rel. Error ± Std\"))\n",
    "print(\"-\"*52)\n",
    "for cn in class_names:\n",
    "    if class_adv_radius[cn]:\n",
    "        print(\"{:<10s} {:>7.4f} ± {:<7.4f} {:>14.4e} ± {:<10.4e}\".format(\n",
    "            cn, np.mean(class_adv_radius[cn]), np.std(class_adv_radius[cn]),\n",
    "            np.mean(class_rel_errors[cn]), np.std(class_rel_errors[cn])\n",
    "        ))\n",
    "    else:\n",
    "        print(\"{:<10s} {:>10s}\".format(cn, \"-\"))\n",
    "\n",
    "print(\"\\nOverall ARR: Avg Radius: {:.4f} ± {:.4f}\".format(np.mean(all_radii), np.std(all_radii)))\n",
    "print(\"Overall ARR: Avg Relative Error: {:.4e} ± {:.4e}\".format(np.mean(all_rel_errs), np.std(all_rel_errs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b64808f7-be8e-4001-be6d-6fcc06b888fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Robustness Evaluation (Full Test Set: perturbed selected subgraphs + others unperturbed) =============\n",
      "Accuracy: 96.08%\n",
      "Precision: 0.9651, Recall: 0.9608, F1: 0.9622\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.7692    0.9091    0.8333        11\n",
      "      trojan     0.9888    0.9670    0.9778        91\n",
      "\n",
      "    accuracy                         0.9608       102\n",
      "   macro avg     0.8790    0.9381    0.9056       102\n",
      "weighted avg     0.9651    0.9608    0.9622       102\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  1]\n",
      " [ 3 88]]\n",
      "\n",
      "Selected subgraphs: 31. Flipped after perturbation: 3 (9.68%).\n"
     ]
    }
   ],
   "source": [
    "# ------------------ Evaluate model on full test set (200 perturbed + rest unperturbed) ------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    for i, data in enumerate(dataset):\n",
    "        x_in = perturbed_map[i].to(DEVICE) if i in perturbed_map else data.x.to(DEVICE)\n",
    "        logits = model(x_in, data.edge_index.to(DEVICE), batch_for(x_in))\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_labels.append(int(data.y.item()))\n",
    "\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    preds_all = all_logits.argmax(dim=1).numpy()\n",
    "    labels_all = np.array(all_labels)\n",
    "\n",
    "acc = (preds_all == labels_all).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_all, preds_all, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n============= Robustness Evaluation (Full Test Set: perturbed selected subgraphs + others unperturbed) =============\")\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(labels_all, preds_all, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "\n",
    "# ------------------ Flip statistics for selected subgraphs ------------------\n",
    "with torch.no_grad():\n",
    "    orig_preds = []\n",
    "    for data in dataset:\n",
    "        x_in = data.x.to(DEVICE)\n",
    "        logits = model(x_in, data.edge_index.to(DEVICE), batch_for(x_in))\n",
    "        orig_preds.append(logits.cpu())\n",
    "    orig_preds = torch.cat(orig_preds, dim=0).argmax(dim=1).numpy()\n",
    "\n",
    "adv_sel_preds = preds_all[selected]\n",
    "num_flips = int((orig_preds[selected] != adv_sel_preds).sum())\n",
    "print(f\"\\nSelected subgraphs: {len(selected)}. Flipped after perturbation: {num_flips} ({100.0 * num_flips/len(selected):.2f}%).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898d06a3-8f20-42de-9ae8-2cdbb6cd60ca",
   "metadata": {},
   "source": [
    "#### Stability Under Input Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b6abf18-a02e-4155-a9a1-27db8381fab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Stability Under Input Noise (PGD-first, then metric) ---\n",
      "Selected subgraphs: clean=11, trojan=20\n",
      "\n",
      "============= Robustness Evaluation (Full Test Set: perturbed selected + others unperturbed) =============\n",
      "Accuracy: 96.08%\n",
      "Precision: 0.9651, Recall: 0.9608, F1: 0.9622\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.7692    0.9091    0.8333        11\n",
      "      trojan     0.9888    0.9670    0.9778        91\n",
      "\n",
      "    accuracy                         0.9608       102\n",
      "   macro avg     0.8790    0.9381    0.9056       102\n",
      "weighted avg     0.9651    0.9608    0.9622       102\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  1]\n",
      " [ 3 88]]\n",
      "\n",
      "Selected subgraphs: 31. Flipped after perturbation: 3 (9.68%).\n",
      "\n",
      "Computing Stability Under Input Noise (this may take a while)...\n",
      "  processed 10/31 subgraphs...\n",
      "  processed 20/31 subgraphs...\n",
      "  processed 30/31 subgraphs...\n",
      "Done SUIN computation. Time elapsed: 17.2s\n",
      "\n",
      "--- Stability Under Input Noise (on perturbed subgraphs) ---\n",
      " Clean:  avg_stability=4.4768 ± 1.8360, avg_relerr=2.5896e-02 ± 1.7661e-02\n",
      " Trojan: avg_stability=5.4528 ± 4.0126, avg_relerr=3.6409e-02 ± 6.5924e-02\n",
      "\n",
      "Sample preview (first 6): (idx, label, stability, rel_err)\n",
      "(14, 0, 4.613297688961029, 0.017762431029235415)\n",
      "(33, 0, 1.6698134571313858, 0.00504185254342345)\n",
      "(63, 0, 5.987209582328797, 0.006015780281168827)\n",
      "(12, 0, 7.554403066635132, 0.004729043223996363)\n",
      "(18, 0, 6.4326952457427975, 0.006646189204557296)\n",
      "(36, 0, 3.977954363822937, 0.04340885478066942)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Stability Under Input Noise (SUIN) - Subgraph classification\n",
    "# ============================================================\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import time\n",
    "\n",
    "# --- Parameters ---\n",
    "NOISE_SIGMA        = 0.5   # Gaussian noise stddev for stability metric\n",
    "NUM_NOISE_SAMPLES  = 20     # Monte Carlo samples per subgraph\n",
    "RELERR_RESAMPLES   = 5      # repeats to estimate relative error\n",
    "\n",
    "print(\"\\n--- Stability Under Input Noise (PGD-first, then metric) ---\")\n",
    "print(f\"Selected subgraphs: clean={(labels_np[selected]==0).sum()}, trojan={(labels_np[selected]==1).sum()}\")\n",
    "\n",
    "# ============================================================\n",
    "# Step 1: Evaluate model on full dataset (perturbed + original)\n",
    "# ============================================================\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_logits, all_labels = [], []\n",
    "    for i, data in enumerate(dataset):\n",
    "        x_in = perturbed_map[i].to(DEVICE) if i in perturbed_map else data.x.to(DEVICE)\n",
    "        logits = model(x_in, data.edge_index.to(DEVICE), batch_for(x_in))\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_labels.append(int(data.y.item()))\n",
    "\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    preds_all  = all_logits.argmax(dim=1).numpy()\n",
    "    labels_all = np.array(all_labels)\n",
    "\n",
    "acc = (preds_all == labels_all).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_all, preds_all, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n============= Robustness Evaluation (Full Test Set: perturbed selected + others unperturbed) =============\")\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(labels_all, preds_all, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "\n",
    "# Flip statistics for selected subgraphs\n",
    "with torch.no_grad():\n",
    "    orig_preds = []\n",
    "    for data in dataset:\n",
    "        x_in = data.x.to(DEVICE)\n",
    "        logits = model(x_in, data.edge_index.to(DEVICE), batch_for(x_in))\n",
    "        orig_preds.append(logits.cpu())\n",
    "    orig_preds = torch.cat(orig_preds, dim=0).argmax(dim=1).numpy()\n",
    "\n",
    "adv_sel_preds = preds_all[selected]\n",
    "num_flips = int((orig_preds[selected] != adv_sel_preds).sum())\n",
    "print(f\"\\nSelected subgraphs: {len(selected)}. Flipped after perturbation: {num_flips} ({100.0*num_flips/len(selected):.2f}%).\")\n",
    "\n",
    "# ============================================================\n",
    "# Step 2: Stability Under Input Noise (on perturbed subgraphs)\n",
    "# ============================================================\n",
    "def stability_for_subgraph(idx, sigma, num_samples):\n",
    "    \"\"\"Compute avg L2 change in logits for noisy perturbations around perturbed subgraph.\"\"\"\n",
    "    data = dataset[idx]\n",
    "    base_x = perturbed_map[idx].to(DEVICE)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    batch = batch_for(base_x)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        f_orig = model(base_x, edge_index, batch).squeeze()\n",
    "\n",
    "    diffs = []\n",
    "    for _ in range(num_samples):\n",
    "        noise = sigma * torch.randn_like(base_x).to(DEVICE)\n",
    "        f_noisy = model(base_x + noise, edge_index, batch).squeeze()\n",
    "        diffs.append(torch.norm(f_noisy - f_orig).item())\n",
    "    return float(np.mean(diffs))\n",
    "\n",
    "print(\"\\nComputing Stability Under Input Noise (this may take a while)...\")\n",
    "t0 = time.time()\n",
    "per_sample_info = []  # (idx, label, stability, rel_err)\n",
    "for i, idx in enumerate(selected):\n",
    "    s_val = stability_for_subgraph(idx, NOISE_SIGMA, NUM_NOISE_SAMPLES)\n",
    "    re_vals = [stability_for_subgraph(idx, NOISE_SIGMA, NUM_NOISE_SAMPLES) for _ in range(RELERR_RESAMPLES)]\n",
    "    s_ref = float(np.mean(re_vals))\n",
    "    rel_err = abs(s_val - s_ref) / (abs(s_ref) + 1e-12)\n",
    "    per_sample_info.append((int(idx), int(labels_np[idx]), s_val, rel_err))\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\"  processed {i+1}/{len(selected)} subgraphs...\")\n",
    "t1 = time.time()\n",
    "print(f\"Done SUIN computation. Time elapsed: {t1-t0:.1f}s\")\n",
    "\n",
    "# ============================================================\n",
    "# Step 3: Aggregate and report\n",
    "# ============================================================\n",
    "clean_stats = [(i, s, e) for (i, l, s, e) in per_sample_info if l == 0]\n",
    "troj_stats  = [(i, s, e) for (i, l, s, e) in per_sample_info if l == 1]\n",
    "\n",
    "def aggs(stats):\n",
    "    if not stats:\n",
    "        return (0.0, 0.0, 0.0, 0.0)\n",
    "    Ss = np.array([s for (_, s, _) in stats])\n",
    "    Es = np.array([e for (_, _, e) in stats])\n",
    "    return (Ss.mean(), Ss.std(), Es.mean(), Es.std())\n",
    "\n",
    "cS_mean, cS_std, cE_mean, cE_std = aggs(clean_stats)\n",
    "tS_mean, tS_std, tE_mean, tE_std = aggs(troj_stats)\n",
    "\n",
    "print(\"\\n--- Stability Under Input Noise (on perturbed subgraphs) ---\")\n",
    "print(f\" Clean:  avg_stability={cS_mean:.4f} ± {cS_std:.4f}, avg_relerr={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_stability={tS_mean:.4f} ± {tS_std:.4f}, avg_relerr={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "\n",
    "print(\"\\nSample preview (first 6): (idx, label, stability, rel_err)\")\n",
    "for p in per_sample_info[:6]:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ef087-787a-4619-9821-37653ff3fb50",
   "metadata": {},
   "source": [
    "#### All in One, same perturbation across all metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "283f8365-b671-488a-a20a-03156a14745d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test subgraphs: 102; class counts: [11 91]\n",
      "Selected perturbation pool counts: {0: 11, 1: 20}\n",
      "\n",
      "--- Step A: Creating shared PGD perturbations for selected subgraphs ---\n",
      "? PGD perturbations done. Time: 15.0s\n",
      "Selected subgraphs: 31. Flipped after PGD: 3 (9.68%).\n",
      "\n",
      "Classification on PERTURBED samples only (selected set):\n",
      "Accuracy (perturbed selected): 90.32%\n",
      "Precision: 0.9069, Recall: 0.9032, F1: 0.9041\n",
      "Classification report (perturbed selected):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.8333    0.9091    0.8696        11\n",
      "      trojan     0.9474    0.9000    0.9231        20\n",
      "\n",
      "    accuracy                         0.9032        31\n",
      "   macro avg     0.8904    0.9045    0.8963        31\n",
      "weighted avg     0.9069    0.9032    0.9041        31\n",
      "\n",
      "Confusion matrix (perturbed selected):\n",
      "[[10  1]\n",
      " [ 2 18]]\n",
      "\n",
      "\n",
      "================ Metric: Jacobian Frobenius Norm + FD Relative Error (on perturbed inputs) ================\n",
      "\n",
      "Jacobian Frobenius norms & FD relative errors (aggregated) ON PERTURBED SAMPLES:\n",
      " Clean subgraphs:  avg_norm=0.4876 ± 0.1973, avg_FDrel=2.7351e-02 ± 5.7933e-02\n",
      " Trojan subgraphs: avg_norm=0.9912 ± 2.6177, avg_FDrel=7.6477e-01 ± 2.4422e+00\n",
      "\n",
      "Sample preview (first 6): (idx,label,jacobian_frob,FD_rel_err)\n",
      "(5, 1, 0.5232011079788208, 0.00687493511015575)\n",
      "(7, 1, 12.308995246887207, 0.01924426214708078)\n",
      "(12, 0, 0.1714828461408615, 0.012244403221647665)\n",
      "(14, 0, 0.3758105933666229, 0.00941424103631739)\n",
      "(15, 1, 0.36891114711761475, 0.001470681263103624)\n",
      "(18, 0, 0.9355684518814087, 0.012257601557243923)\n",
      "\n",
      "Classification (perturbed selected) - Jacobian stage (re-used perturbed set):\n",
      "Accuracy: 90.32%\n",
      "Precision: 0.9069, Recall: 0.9032, F1: 0.9041\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.8333    0.9091    0.8696        11\n",
      "      trojan     0.9474    0.9000    0.9231        20\n",
      "\n",
      "    accuracy                         0.9032        31\n",
      "   macro avg     0.8904    0.9045    0.8963        31\n",
      "weighted avg     0.9069    0.9032    0.9041        31\n",
      "\n",
      "Confusion matrix:\n",
      "[[10  1]\n",
      " [ 2 18]]\n",
      "\n",
      "\n",
      "================ Metric: Local Lipschitz (spectral norm) + FD Relative Error ================\n",
      "\n",
      "Local Lipschitz (spectral) & FD relative errors (on PERTURBED samples):\n",
      " Clean:  avg_L=0.4876 ± 0.1973, avg_FDrel=4.1249e-02 ± 6.9273e-02\n",
      " Trojan: avg_L=0.9912 ± 2.6177, avg_FDrel=3.8738e-01 ± 5.6893e-01\n",
      "\n",
      "Sample preview (first 6): (idx,label,sigma_max,fd_rel_err)\n",
      "(5, 1, 0.5231789946556091, 0.016806066721052632)\n",
      "(7, 1, 12.308971405029297, 0.2615822715255019)\n",
      "(12, 0, 0.17145434021949768, 0.003658971622320127)\n",
      "(14, 0, 0.37577712535858154, 0.012634476297960433)\n",
      "(15, 1, 0.3688538074493408, 0.005185287434467601)\n",
      "(18, 0, 0.9355220198631287, 0.016458633592701184)\n",
      "\n",
      "Classification (perturbed selected) - Local Lipschitz stage:\n",
      "Accuracy: 90.32% | Precision: 0.9069, Recall: 0.9032, F1: 0.9041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.8333    0.9091    0.8696        11\n",
      "      trojan     0.9474    0.9000    0.9231        20\n",
      "\n",
      "    accuracy                         0.9032        31\n",
      "   macro avg     0.8904    0.9045    0.8963        31\n",
      "weighted avg     0.9069    0.9032    0.9041        31\n",
      "\n",
      "[[10  1]\n",
      " [ 2 18]]\n",
      "\n",
      "\n",
      "================ Metric: Hessian curvature proxy (||g||^2) + FD Relative Error ================\n",
      "\n",
      "Hessian-curvature proxy (||g||^2) & FD relative errors (on PERTURBED samples):\n",
      " Clean:  avg_lambda=0.0085 ± 0.0151, avg_FDrel=9.0686e-01 ± 1.1768e-01\n",
      " Trojan: avg_lambda=0.0001 ± 0.0002, avg_FDrel=4.2549e-01 ± 4.0532e-01\n",
      "\n",
      "Sample preview (first 6): (idx,label,lambda,FD_rel_err)\n",
      "(5, 1, 7.511520424665939e-41, 6.683643504349376e-16)\n",
      "(7, 1, 0.0, 0.0)\n",
      "(12, 0, 3.6561656169732e-06, 0.6818280829497559)\n",
      "(14, 0, 0.0010631834302127358, 0.9797317499870175)\n",
      "(15, 1, 2.7667467790159573e-05, 0.5989520138371296)\n",
      "(18, 0, 0.0403895733917361, 0.9759797279383446)\n",
      "\n",
      "Classification (perturbed selected) - Hessian stage:\n",
      "Accuracy: 90.32% | Precision: 0.9069, Recall: 0.9032, F1: 0.9041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.8333    0.9091    0.8696        11\n",
      "      trojan     0.9474    0.9000    0.9231        20\n",
      "\n",
      "    accuracy                         0.9032        31\n",
      "   macro avg     0.8904    0.9045    0.8963        31\n",
      "weighted avg     0.9069    0.9032    0.9041        31\n",
      "\n",
      "[[10  1]\n",
      " [ 2 18]]\n",
      "\n",
      "\n",
      "================ Metric: Prediction Margin + FD Relative Error ================\n",
      "\n",
      "Prediction Margin stats (on PERTURBED samples):\n",
      " Clean:  avg_margin=2.7679 ± 0.9341, avg_FDrel=2.1688e-04 ± 2.3452e-04\n",
      " Trojan: avg_margin=87.7748 ± 265.9565, avg_FDrel=8.2960e-05 ± 9.6441e-05\n",
      "\n",
      "Sample preview (first 6): (idx,label,margin,fd_rel_err)\n",
      "(5, 1, 45.154043197631836, 3.041337478845213e-06)\n",
      "(7, 1, 1235.9407958984375, 1.664198270507872e-05)\n",
      "(12, 0, 4.834082841873169, 3.5114844529265174e-05)\n",
      "(14, 0, 2.7269054651260376, 6.339215994617823e-05)\n",
      "(15, 1, 4.5858776569366455, 0.00013453134151396705)\n",
      "(18, 0, 1.7189950346946716, 0.000925115815284752)\n",
      "\n",
      "Classification (perturbed selected) - Prediction Margin stage:\n",
      "Accuracy: 90.32% | Precision: 0.9069, Recall: 0.9032, F1: 0.9041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.8333    0.9091    0.8696        11\n",
      "      trojan     0.9474    0.9000    0.9231        20\n",
      "\n",
      "    accuracy                         0.9032        31\n",
      "   macro avg     0.8904    0.9045    0.8963        31\n",
      "weighted avg     0.9069    0.9032    0.9041        31\n",
      "\n",
      "[[10  1]\n",
      " [ 2 18]]\n",
      "\n",
      "\n",
      "================ Metric: Adversarial Robustness Radius (ARR) ================\n",
      " processed 10/31 ...\n",
      " processed 20/31 ...\n",
      " processed 30/31 ...\n",
      "? ARR computation done. Time elapsed: 150.3s\n",
      "\n",
      "ARR (Adversarial Robustness Radius) Stats (on perturbed selected samples):\n",
      " clean : avg_radius=20.0000 ± 0.0000, avg_relerr=0.0000e+00 ± 0.0000e+00\n",
      " trojan: avg_radius=20.0000 ± 0.0000, avg_relerr=0.0000e+00 ± 0.0000e+00\n",
      " Overall: avg_radius=20.0000 ± 0.0000; avg_relerr=0.0000e+00 ± 0.0000e+00\n",
      "\n",
      "Classification (perturbed selected) - ARR stage:\n",
      "Accuracy: 90.32% | Precision: 0.9069, Recall: 0.9032, F1: 0.9041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.8333    0.9091    0.8696        11\n",
      "      trojan     0.9474    0.9000    0.9231        20\n",
      "\n",
      "    accuracy                         0.9032        31\n",
      "   macro avg     0.8904    0.9045    0.8963        31\n",
      "weighted avg     0.9069    0.9032    0.9041        31\n",
      "\n",
      "[[10  1]\n",
      " [ 2 18]]\n",
      "\n",
      "\n",
      "================ Metric: Stability Under Input Noise (SUIN) ================\n",
      " processed 10/31 ...\n",
      " processed 20/31 ...\n",
      " processed 30/31 ...\n",
      "? SUIN done. Time elapsed: 45.2s\n",
      "\n",
      "Stability Under Input Noise (on perturbed selected samples):\n",
      " Clean: avg_stability=4.6820 ± 1.9321, avg_relerr=3.4439e-02 ± 2.4240e-02\n",
      " Trojan:avg_stability=5.4611 ± 4.0297, avg_relerr=3.9504e-02 ± 4.1995e-02\n",
      "\n",
      "Sample preview (first 6): (idx,label,stability,rel_err)\n",
      "(5, 1, 4.064865756034851, 0.05643058964754945)\n",
      "(7, 1, 4.830007572472096, 0.10246266238169134)\n",
      "(12, 0, 7.635094738006591, 0.004330393125952658)\n",
      "(14, 0, 5.701809883117676, 0.04836504316916696)\n",
      "(15, 1, 0.7627831846475601, 0.06882183867393173)\n",
      "(18, 0, 6.508411407470703, 0.018768500763049305)\n",
      "\n",
      "Classification (perturbed selected) - SUIN stage:\n",
      "Accuracy: 90.32% | Precision: 0.9069, Recall: 0.9032, F1: 0.9041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.8333    0.9091    0.8696        11\n",
      "      trojan     0.9474    0.9000    0.9231        20\n",
      "\n",
      "    accuracy                         0.9032        31\n",
      "   macro avg     0.8904    0.9045    0.8963        31\n",
      "weighted avg     0.9069    0.9032    0.9041        31\n",
      "\n",
      "[[10  1]\n",
      " [ 2 18]]\n",
      "\n",
      "\n",
      "All metrics computed on the SAME selected subgraphs and the SAME PGD perturbations (perturbed_map).\n",
      "You can adjust PER_CLASS, EPSILON_PGD, ALPHA_PGD, NUM_ITERS_PGD to change attack strength.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# Subgraph-level: unified end-to-end robustness evaluation reusing one PGD\n",
    "# =====================================================================\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# -------------------------\n",
    "# Parameters (tweak here)\n",
    "# -------------------------\n",
    "PER_CLASS        = 20        # number of subgraphs per class to perturb\n",
    "EPSILON_PGD      = 4.0       # L2 radius for the PGD perturbation applied once and reused\n",
    "ALPHA_PGD        = 1.0       # PGD step size\n",
    "NUM_ITERS_PGD    = 30        # PGD iterations\n",
    "FD_EPS           = 1e-3      # finite-difference epsilon\n",
    "ARR_INITIAL_EPS  = 1e-3      # initial epsilon for ARR search\n",
    "ARR_GROW1        = 1.25\n",
    "ARR_GROW2        = 1.4\n",
    "ARR_MAX_EPS      = 20.0\n",
    "ARR_BS_ITERS     = 10\n",
    "ARR_TRIALS       = 6\n",
    "STAB_SIGMA       = 0.5       # stability noise sigma\n",
    "STAB_SAMPLES     = 20\n",
    "STAB_RELERR_RPTS = 5\n",
    "SEED             = 42\n",
    "\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# -------------------------\n",
    "# Sanity\n",
    "# -------------------------\n",
    "required = [\"model\", \"test_loader\", \"DEVICE\"]\n",
    "for r in required:\n",
    "    if r not in globals():\n",
    "        raise RuntimeError(f\"Required variable '{r}' not found in the environment (must be defined earlier).\")\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# -------------------------\n",
    "# Extract test dataset list & labels (preserve loader order)\n",
    "# -------------------------\n",
    "dataset = list(test_loader.dataset) if hasattr(test_loader, \"dataset\") else list(test_loader)\n",
    "n_test = len(dataset)\n",
    "labels_all = np.array([int(d.y.item()) for d in dataset])\n",
    "print(f\"Total test subgraphs: {n_test}; class counts: {np.bincount(labels_all)}\")\n",
    "\n",
    "# -------------------------\n",
    "# Select indices (same pool for all metrics)\n",
    "# -------------------------\n",
    "rng = np.random.default_rng(SEED)\n",
    "selected = []\n",
    "for cls in [0,1]:\n",
    "    idxs = np.where(labels_all == cls)[0]\n",
    "    if len(idxs)==0:\n",
    "        continue\n",
    "    k = min(PER_CLASS, len(idxs))\n",
    "    chosen = rng.choice(idxs, size=k, replace=False)\n",
    "    selected.extend(chosen.tolist())\n",
    "selected = np.array(sorted(selected), dtype=np.int64)\n",
    "print(\"Selected perturbation pool counts:\", {0:int((labels_all[selected]==0).sum()), 1:int((labels_all[selected]==1).sum())})\n",
    "\n",
    "# small helper for single-graph batch vectors\n",
    "def batch_for(x):\n",
    "    return torch.zeros(x.size(0), dtype=torch.long, device=DEVICE)\n",
    "\n",
    "# -------------------------\n",
    "# Build one shared PGD perturbation map (perturbed_map)\n",
    "# - perturb each selected subgraph's node features (x) via PGD (L2 constrained)\n",
    "# - store perturbed_map[idx] -> perturbed x (on DEVICE)\n",
    "# -------------------------\n",
    "perturbed_map = {}\n",
    "orig_preds_selected = []\n",
    "adv_preds_selected = []\n",
    "\n",
    "print(\"\\n--- Step A: Creating shared PGD perturbations for selected subgraphs ---\")\n",
    "t0 = time.time()\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x_orig = data.x.detach().clone().to(DEVICE)    # (N_nodes, feat_dim)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    n_nodes, feat_dim = x_orig.shape\n",
    "    y_true = torch.tensor([int(data.y.item())], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    # random initialization inside L2-ball (on flattened features)\n",
    "    delta = torch.randn_like(x_orig, device=DEVICE)\n",
    "    delta = delta * (EPSILON_PGD / (delta.view(-1).norm() + 1e-12))\n",
    "    x_adv = (x_orig + delta).detach().clone().requires_grad_(True)\n",
    "\n",
    "    # PGD loop (maximize CE loss to cause misclassification)\n",
    "    for it in range(NUM_ITERS_PGD):\n",
    "        out = model(x_adv, edge_index, batch_for(x_adv))           # [1, C]\n",
    "        loss = F.cross_entropy(out, y_true)\n",
    "        grad_x = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "        gnorm = grad_x.view(-1).norm().item()\n",
    "        if gnorm == 0:\n",
    "            break\n",
    "        step = (ALPHA_PGD * grad_x) / (gnorm + 1e-12)\n",
    "        x_adv = (x_adv + step).detach()\n",
    "        # project back to L2 ball (flattened)\n",
    "        delta = x_adv - x_orig\n",
    "        dnorm = delta.view(-1).norm().item()\n",
    "        if dnorm > EPSILON_PGD:\n",
    "            delta = delta * (EPSILON_PGD / (dnorm + 1e-12))\n",
    "            x_adv = (x_orig + delta).detach()\n",
    "        x_adv = x_adv.requires_grad_(True)\n",
    "\n",
    "    x_adv_final = x_adv.detach().clone()\n",
    "    perturbed_map[int(idx)] = x_adv_final\n",
    "\n",
    "    # store flip stats\n",
    "    with torch.no_grad():\n",
    "        out_orig = model(x_orig, edge_index, batch_for(x_orig))\n",
    "        out_adv  = model(x_adv_final, edge_index, batch_for(x_adv_final))\n",
    "        orig_preds_selected.append(int(out_orig.argmax(dim=1).item()))\n",
    "        adv_preds_selected.append(int(out_adv.argmax(dim=1).item()))\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"? PGD perturbations done. Time: {t1-t0:.1f}s\")\n",
    "orig_preds_selected = np.array(orig_preds_selected)\n",
    "adv_preds_selected  = np.array(adv_preds_selected)\n",
    "num_flips = int((orig_preds_selected != adv_preds_selected).sum())\n",
    "print(f\"Selected subgraphs: {len(selected)}. Flipped after PGD: {num_flips} ({100.0 * num_flips / len(selected):.2f}%).\")\n",
    "\n",
    "# Also compute and show perturbed-only classifier behavior (for selected set)\n",
    "with torch.no_grad():\n",
    "    labels_sel = labels_all[selected]\n",
    "    preds_perturbed = []\n",
    "    for idx in selected:\n",
    "        data = dataset[int(idx)]\n",
    "        logits = model(perturbed_map[int(idx)], data.edge_index.to(DEVICE), batch_for(perturbed_map[int(idx)]))\n",
    "        preds_perturbed.append(int(logits.argmax(dim=1).item()))\n",
    "    preds_perturbed = np.array(preds_perturbed)\n",
    "\n",
    "print(\"\\nClassification on PERTURBED samples only (selected set):\")\n",
    "acc_sel = (preds_perturbed == labels_sel).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_sel, preds_perturbed, average='weighted', zero_division=0)\n",
    "print(f\"Accuracy (perturbed selected): {acc_sel*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\")\n",
    "print(\"Classification report (perturbed selected):\")\n",
    "print(classification_report(labels_sel, preds_perturbed, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion matrix (perturbed selected):\")\n",
    "print(confusion_matrix(labels_sel, preds_perturbed, labels=[0,1]))\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Utility: evaluate on perturbed selected set only (used by metrics to print)\n",
    "# -------------------------------------------------------------------------\n",
    "def eval_perturbed_selected(perturbed_map, selected_idxs):\n",
    "    with torch.no_grad():\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for idx in selected_idxs:\n",
    "            data = dataset[int(idx)]\n",
    "            lab = int(data.y.item())\n",
    "            x_eval = perturbed_map[int(idx)]\n",
    "            logits = model(x_eval, data.edge_index.to(DEVICE), batch_for(x_eval))\n",
    "            y_true.append(lab)\n",
    "            y_pred.append(int(logits.argmax(dim=1).item()))\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    acc = (y_true == y_pred).mean()\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    return y_true, y_pred, acc, prec, rec, f1\n",
    "\n",
    "# -------------------------\n",
    "# Metric 1: Jacobian Frobenius norm + FD relative error\n",
    "# (computed at the perturbed inputs; flattened features)\n",
    "# -------------------------\n",
    "print(\"\\n\\n================ Metric: Jacobian Frobenius Norm + FD Relative Error (on perturbed inputs) ================\")\n",
    "per_sample_jac = []   # (idx,label, jac_frob, fd_rel_err)\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x_adv = perturbed_map[int(idx)].detach().clone().to(DEVICE).requires_grad_(True)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    n_nodes, feat_dim = x_adv.shape\n",
    "    d = n_nodes * feat_dim\n",
    "\n",
    "    # flatten\n",
    "    x_flat = x_adv.view(-1).detach().clone().requires_grad_(True)\n",
    "\n",
    "    def f_flat(x_in):\n",
    "        x_mat = x_in.view_as(x_adv)\n",
    "        out = model(x_mat, edge_index, batch_for(x_mat))   # [1, C]\n",
    "        return out.squeeze(0)                              # (C,)\n",
    "\n",
    "    # Jacobian: shape (C, d)\n",
    "    try:\n",
    "        J = torch.autograd.functional.jacobian(f_flat, x_flat)   # (C, d)\n",
    "    except RuntimeError:\n",
    "        # fallback: compute per-output jac rows\n",
    "        logits0 = f_flat(x_flat).detach()\n",
    "        C = logits0.shape[0]\n",
    "        rows = []\n",
    "        for c in range(C):\n",
    "            def scalar_f(z, cidx=c):\n",
    "                return f_flat(z)[cidx]\n",
    "            r = torch.autograd.functional.jacobian(scalar_f, x_flat)\n",
    "            rows.append(r.unsqueeze(0))\n",
    "        J = torch.cat(rows, dim=0)\n",
    "\n",
    "    J = J.detach()\n",
    "    jac_frob = float(torch.norm(J, p='fro').item())\n",
    "\n",
    "    # FD relative error\n",
    "    delta_fd = FD_EPS * torch.randn(d, device=DEVICE)\n",
    "    pred_change = (J @ delta_fd)                      # (C,)\n",
    "    f0 = f_flat(x_flat).detach()\n",
    "    f0p = f_flat((x_flat + delta_fd)).detach()\n",
    "    actual_change = f0p - f0\n",
    "    if torch.norm(actual_change).item() == 0:\n",
    "        rel_err = 0.0\n",
    "    else:\n",
    "        rel_err = float(torch.norm(pred_change - actual_change).item() / (torch.norm(actual_change).item() + 1e-8))\n",
    "\n",
    "    per_sample_jac.append((int(idx), int(data.y.item()), jac_frob, rel_err))\n",
    "\n",
    "# aggregate & print\n",
    "arr = np.array([[i,l,j,r] for (i,l,j,r) in per_sample_jac], dtype=object)\n",
    "if arr.size:\n",
    "    clean_vals = arr[arr[:,1]==0][:,2].astype(float) if (arr[:,1]==0).any() else np.array([])\n",
    "    troj_vals  = arr[arr[:,1]==1][:,2].astype(float) if (arr[:,1]==1).any() else np.array([])\n",
    "    clean_errs = arr[arr[:,1]==0][:,3].astype(float) if (arr[:,1]==0).any() else np.array([])\n",
    "    troj_errs  = arr[arr[:,1]==1][:,3].astype(float) if (arr[:,1]==1).any() else np.array([])\n",
    "\n",
    "    def mean_std(a): return (a.mean(), a.std()) if len(a)>0 else (0.0,0.0)\n",
    "\n",
    "    c_mean, c_std = mean_std(clean_vals)\n",
    "    t_mean, t_std = mean_std(troj_vals)\n",
    "    ce_mean, ce_std = mean_std(clean_errs)\n",
    "    te_mean, te_std = mean_std(troj_errs)\n",
    "\n",
    "    print(\"\\nJacobian Frobenius norms & FD relative errors (aggregated) ON PERTURBED SAMPLES:\")\n",
    "    print(f\" Clean subgraphs:  avg_norm={c_mean:.4f} ± {c_std:.4f}, avg_FDrel={ce_mean:.4e} ± {ce_std:.4e}\")\n",
    "    print(f\" Trojan subgraphs: avg_norm={t_mean:.4f} ± {t_std:.4f}, avg_FDrel={te_mean:.4e} ± {te_std:.4e}\")\n",
    "    print(\"\\nSample preview (first 6): (idx,label,jacobian_frob,FD_rel_err)\")\n",
    "    for t in per_sample_jac[:6]:\n",
    "        print(t)\n",
    "else:\n",
    "    print(\"No Jacobian samples computed.\")\n",
    "\n",
    "# Print classification performance on perturbed selected set only\n",
    "y_true_sel, y_pred_sel, acc_sel, prec_sel, rec_sel, f1_sel = (*eval_perturbed_selected(perturbed_map, selected),)\n",
    "print(\"\\nClassification (perturbed selected) - Jacobian stage (re-used perturbed set):\")\n",
    "print(f\"Accuracy: {acc_sel*100:.2f}%\")\n",
    "print(f\"Precision: {prec_sel:.4f}, Recall: {rec_sel:.4f}, F1: {f1_sel:.4f}\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_true_sel, y_pred_sel, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_true_sel, y_pred_sel, labels=[0,1]))\n",
    "\n",
    "# -------------------------\n",
    "# Metric 2: Local Lipschitz (spectral norm of Jacobian) + FD relative error\n",
    "# (Compute at perturbed inputs; flatten J to (C,d) and compute top singular value)\n",
    "# -------------------------\n",
    "print(\"\\n\\n================ Metric: Local Lipschitz (spectral norm) + FD Relative Error ================\")\n",
    "per_sample_lip = []  # (idx,label,sigma_max, fd_rel_err)\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x_adv = perturbed_map[int(idx)].detach().clone().to(DEVICE).requires_grad_(True)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    n_nodes, feat_dim = x_adv.shape\n",
    "    d = n_nodes * feat_dim\n",
    "\n",
    "    def f_local(x):\n",
    "        return model(x, edge_index, batch_for(x)).squeeze(0)\n",
    "\n",
    "    # Jacobian shape (C, N, F)\n",
    "    try:\n",
    "        J = torch.autograd.functional.jacobian(f_local, x_adv).detach()   # (C, N, F)\n",
    "    except RuntimeError:\n",
    "        # fallback per-output (slower)\n",
    "        logits0 = f_local(x_adv).detach()\n",
    "        C = logits0.shape[0]\n",
    "        rows = []\n",
    "        for c in range(C):\n",
    "            def scalar_f(z, cidx=c):\n",
    "                return f_local(z)[cidx]\n",
    "            row = torch.autograd.functional.jacobian(scalar_f, x_adv)\n",
    "            rows.append(row.unsqueeze(0))\n",
    "        J = torch.cat(rows, dim=0)\n",
    "\n",
    "    C = J.shape[0]\n",
    "    J_flat = J.reshape(C, d)   # (C, d)\n",
    "\n",
    "    # spectral norm via SVD (largest singular value)\n",
    "    try:\n",
    "        _, S, _ = torch.linalg.svd(J_flat, full_matrices=False)\n",
    "        sigma_max = float(S[0].item())\n",
    "    except RuntimeError:\n",
    "        # fallback via eigen\n",
    "        JJT = (J_flat @ J_flat.T).cpu().numpy()\n",
    "        eigvals = np.linalg.eigvalsh(JJT)\n",
    "        sigma_max = float(np.sqrt(max(eigvals.max(), 0.0)))\n",
    "\n",
    "    # FD relative error\n",
    "    delta_fd = FD_EPS * torch.randn(d, device=DEVICE)\n",
    "    pred_change = (J_flat @ delta_fd)               # (C,)\n",
    "    f0 = f_local(x_adv).detach()\n",
    "    f0p = f_local(x_adv + delta_fd.view_as(x_adv)).detach()\n",
    "    actual_change = f0p - f0\n",
    "    if torch.norm(actual_change).item() == 0:\n",
    "        fd_rel = 0.0\n",
    "    else:\n",
    "        fd_rel = float(torch.norm(pred_change - actual_change).item() / (torch.norm(actual_change).item() + 1e-8))\n",
    "\n",
    "    per_sample_lip.append((int(idx), int(data.y.item()), float(sigma_max), float(fd_rel)))\n",
    "\n",
    "# aggregate & print\n",
    "clean_stats = [p for p in per_sample_lip if p[1]==0]\n",
    "troj_stats  = [p for p in per_sample_lip if p[1]==1]\n",
    "def aggs(stats):\n",
    "    if not stats: return (0.0,0.0,0.0,0.0)\n",
    "    Ls = np.array([s[2] for s in stats]); Es = np.array([s[3] for s in stats])\n",
    "    return (Ls.mean(), Ls.std(), Es.mean(), Es.std())\n",
    "\n",
    "cL_mean, cL_std, cE_mean, cE_std = aggs(clean_stats)\n",
    "tL_mean, tL_std, tE_mean, tE_std = aggs(troj_stats)\n",
    "\n",
    "print(\"\\nLocal Lipschitz (spectral) & FD relative errors (on PERTURBED samples):\")\n",
    "print(f\" Clean:  avg_L={cL_mean:.4f} ± {cL_std:.4f}, avg_FDrel={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_L={tL_mean:.4f} ± {tL_std:.4f}, avg_FDrel={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "print(\"\\nSample preview (first 6): (idx,label,sigma_max,fd_rel_err)\")\n",
    "for p in per_sample_lip[:6]:\n",
    "    print(p)\n",
    "\n",
    "# classification on perturbed selected\n",
    "y_true_sel, y_pred_sel, acc_sel, prec_sel, rec_sel, f1_sel = (*eval_perturbed_selected(perturbed_map, selected),)\n",
    "print(\"\\nClassification (perturbed selected) - Local Lipschitz stage:\")\n",
    "print(f\"Accuracy: {acc_sel*100:.2f}% | Precision: {prec_sel:.4f}, Recall: {rec_sel:.4f}, F1: {f1_sel:.4f}\")\n",
    "print(classification_report(y_true_sel, y_pred_sel, target_names=['clean','trojan'], digits=4))\n",
    "print(confusion_matrix(y_true_sel, y_pred_sel, labels=[0,1]))\n",
    "\n",
    "# -------------------------\n",
    "# Metric 3: Hessian curvature proxy (||g||^2) + FD relative error\n",
    "# (Compute gradient of log-prob for predicted class at perturbed inputs)\n",
    "# -------------------------\n",
    "print(\"\\n\\n================ Metric: Hessian curvature proxy (||g||^2) + FD Relative Error ================\")\n",
    "TRIALS_HESS_FD = 5\n",
    "per_sample_hess = []   # (idx,label, lambda_proxy=||g||^2, avg_fd_rel_err)\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x_adv = perturbed_map[int(idx)].detach().clone().to(DEVICE).requires_grad_(True)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "\n",
    "    # forward & predicted class (allow grad)\n",
    "    logits = model(x_adv, edge_index, batch_for(x_adv)).squeeze(0)\n",
    "    pred_class = int(logits.argmax().item())\n",
    "\n",
    "    # compute log-prob of predicted class\n",
    "    logp = F.log_softmax(logits, dim=0)[pred_class]\n",
    "    # gradient wrt x_adv\n",
    "    g = torch.autograd.grad(logp, x_adv, retain_graph=False, create_graph=False, allow_unused=False)[0].detach()\n",
    "    lambda_proxy = float(g.norm(p=2).item() ** 2)\n",
    "\n",
    "    # FD relative errors (multiple small deltas)\n",
    "    rels = []\n",
    "    for _ in range(TRIALS_HESS_FD):\n",
    "        delta = FD_EPS * torch.randn_like(x_adv).to(DEVICE)\n",
    "        gt_delta = float((g * delta).sum().item())\n",
    "        pred_second = 0.5 * (gt_delta ** 2)\n",
    "        # recompute logp at perturbed input\n",
    "        logits_p = model((x_adv + delta).detach(), edge_index, batch_for(x_adv + delta)).squeeze(0)\n",
    "        logp_p = F.log_softmax(logits_p, dim=0)[pred_class]\n",
    "        actual_second = float((logp_p - F.log_softmax(logits, dim=0)[pred_class]).item() - gt_delta)\n",
    "        rel_err = abs(pred_second - actual_second) / (abs(actual_second) + 1e-8)\n",
    "        rels.append(rel_err)\n",
    "    avg_rel_err = float(np.mean(rels))\n",
    "    per_sample_hess.append((int(idx), int(data.y.item()), lambda_proxy, avg_rel_err))\n",
    "\n",
    "# aggregate & print\n",
    "clean_stats = [t for t in per_sample_hess if t[1]==0]\n",
    "troj_stats  = [t for t in per_sample_hess if t[1]==1]\n",
    "def summarize(stats):\n",
    "    if not stats: return (0.0,0.0,0.0,0.0)\n",
    "    Ls = np.array([s[2] for s in stats]); Es = np.array([s[3] for s in stats])\n",
    "    return (Ls.mean(), Ls.std(), Es.mean(), Es.std())\n",
    "\n",
    "cL_mean, cL_std, cE_mean, cE_std = summarize(clean_stats)\n",
    "tL_mean, tL_std, tE_mean, tE_std = summarize(troj_stats)\n",
    "print(\"\\nHessian-curvature proxy (||g||^2) & FD relative errors (on PERTURBED samples):\")\n",
    "print(f\" Clean:  avg_lambda={cL_mean:.4f} ± {cL_std:.4f}, avg_FDrel={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_lambda={tL_mean:.4f} ± {tL_std:.4f}, avg_FDrel={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "print(\"\\nSample preview (first 6): (idx,label,lambda,FD_rel_err)\")\n",
    "for p in per_sample_hess[:6]:\n",
    "    print(p)\n",
    "\n",
    "# classification on perturbed selected\n",
    "y_true_sel, y_pred_sel, acc_sel, prec_sel, rec_sel, f1_sel = (*eval_perturbed_selected(perturbed_map, selected),)\n",
    "print(\"\\nClassification (perturbed selected) - Hessian stage:\")\n",
    "print(f\"Accuracy: {acc_sel*100:.2f}% | Precision: {prec_sel:.4f}, Recall: {rec_sel:.4f}, F1: {f1_sel:.4f}\")\n",
    "print(classification_report(y_true_sel, y_pred_sel, target_names=['clean','trojan'], digits=4))\n",
    "print(confusion_matrix(y_true_sel, y_pred_sel, labels=[0,1]))\n",
    "\n",
    "# -------------------------\n",
    "# Metric 4: Prediction Margin + FD relative error (on perturbed inputs)\n",
    "# -------------------------\n",
    "print(\"\\n\\n================ Metric: Prediction Margin + FD Relative Error ================\")\n",
    "per_sample_margin = []   # (idx,label, margin, fd_rel_err)\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x_adv = perturbed_map[int(idx)].detach().clone().to(DEVICE)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x_adv, edge_index, batch_for(x_adv)).squeeze(0)\n",
    "    pred_class = int(logits.argmax().item())\n",
    "    pred_logit = float(logits[pred_class].item())\n",
    "    other_logits = logits.clone()\n",
    "    other_logits[pred_class] = -float('inf')\n",
    "    second_max = float(other_logits.max().item())\n",
    "    margin = pred_logit - second_max\n",
    "\n",
    "    # FD check\n",
    "    delta = FD_EPS * torch.randn_like(x_adv).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits_p = model(x_adv + delta, edge_index, batch_for(x_adv)).squeeze(0)\n",
    "    pred_logit_p = float(logits_p[pred_class].item())\n",
    "    other_logits_p = logits_p.clone()\n",
    "    other_logits_p[pred_class] = -float('inf')\n",
    "    second_max_p = float(other_logits_p.max().item())\n",
    "    margin_p = pred_logit_p - second_max_p\n",
    "    rel_err = abs(margin - margin_p) / (abs(margin_p) + 1e-12)\n",
    "    per_sample_margin.append((int(idx), int(data.y.item()), float(margin), float(rel_err)))\n",
    "\n",
    "# aggregate & print\n",
    "clean_stats = [p for p in per_sample_margin if p[1]==0]\n",
    "troj_stats  = [p for p in per_sample_margin if p[1]==1]\n",
    "def aggs_m(stats):\n",
    "    if not stats: return (0.0,0.0,0.0,0.0)\n",
    "    Ms = np.array([s[2] for s in stats]); Es = np.array([s[3] for s in stats])\n",
    "    return (Ms.mean(), Ms.std(), Es.mean(), Es.std())\n",
    "\n",
    "cM_mean, cM_std, cE_mean, cE_std = aggs_m(clean_stats)\n",
    "tM_mean, tM_std, tE_mean, tE_std = aggs_m(troj_stats)\n",
    "print(\"\\nPrediction Margin stats (on PERTURBED samples):\")\n",
    "print(f\" Clean:  avg_margin={cM_mean:.4f} ± {cM_std:.4f}, avg_FDrel={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_margin={tM_mean:.4f} ± {tM_std:.4f}, avg_FDrel={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "print(\"\\nSample preview (first 6): (idx,label,margin,fd_rel_err)\")\n",
    "for p in per_sample_margin[:6]:\n",
    "    print(p)\n",
    "\n",
    "# classification on perturbed selected\n",
    "y_true_sel, y_pred_sel, acc_sel, prec_sel, rec_sel, f1_sel = (*eval_perturbed_selected(perturbed_map, selected),)\n",
    "print(\"\\nClassification (perturbed selected) - Prediction Margin stage:\")\n",
    "print(f\"Accuracy: {acc_sel*100:.2f}% | Precision: {prec_sel:.4f}, Recall: {rec_sel:.4f}, F1: {f1_sel:.4f}\")\n",
    "print(classification_report(y_true_sel, y_pred_sel, target_names=['clean','trojan'], digits=4))\n",
    "print(confusion_matrix(y_true_sel, y_pred_sel, labels=[0,1]))\n",
    "\n",
    "# -------------------------\n",
    "# Metric 5: Adversarial Robustness Radius (ARR) around perturbed points\n",
    "# -------------------------\n",
    "print(\"\\n\\n================ Metric: Adversarial Robustness Radius (ARR) ================\")\n",
    "def f_for_subgraph(x_tensor, data):\n",
    "    with torch.no_grad():\n",
    "        out = model(x_tensor, data.edge_index.to(DEVICE), batch_for(x_tensor))\n",
    "    return out.squeeze(0)\n",
    "\n",
    "def adversarial_radius_for_subgraph(data, x0, initial_epsilon=ARR_INITIAL_EPS, growth_factor=ARR_GROW1,\n",
    "                                    max_epsilon=ARR_MAX_EPS, bs_iters=ARR_BS_ITERS, num_trials=ARR_TRIALS):\n",
    "    \"\"\"Estimate minimal L2 norm that flips prediction around x0.\"\"\"\n",
    "    x0 = x0.clone().detach().to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        base_out = model(x0, data.edge_index.to(DEVICE), batch_for(x0))\n",
    "        y0 = int(base_out.argmax().item())\n",
    "\n",
    "    def is_same(x):\n",
    "        out = f_for_subgraph(x, data)\n",
    "        return int(out.argmax().item()) == y0\n",
    "\n",
    "    radii = []\n",
    "    for _ in range(num_trials):\n",
    "        d = torch.randn_like(x0).to(DEVICE)\n",
    "        d = d / (d.view(-1).norm() + 1e-12)\n",
    "        eps = initial_epsilon\n",
    "        while eps < max_epsilon and is_same(x0 + eps * d):\n",
    "            eps *= growth_factor\n",
    "        if eps >= max_epsilon:\n",
    "            radii.append(float(max_epsilon))\n",
    "            continue\n",
    "        low, high = eps / growth_factor, eps\n",
    "        for _ in range(bs_iters):\n",
    "            mid = 0.5 * (low + high)\n",
    "            if is_same(x0 + mid * d):\n",
    "                low = mid\n",
    "            else:\n",
    "                high = mid\n",
    "        radii.append(float(high))\n",
    "    return float(min(radii))\n",
    "\n",
    "def adversarial_radius_relerr(data, x0):\n",
    "    r1 = adversarial_radius_for_subgraph(data, x0, growth_factor=ARR_GROW1, num_trials=ARR_TRIALS)\n",
    "    r2 = adversarial_radius_for_subgraph(data, x0, growth_factor=ARR_GROW2, num_trials=ARR_TRIALS)\n",
    "    rel_err = abs(r1 - r2) / (abs(r2) + 1e-12)\n",
    "    return r1, rel_err\n",
    "\n",
    "class_names = ['clean','trojan']\n",
    "class_adv_radius = {cn: [] for cn in class_names}\n",
    "class_rel_errors = {cn: [] for cn in class_names}\n",
    "all_rads = []; all_relerrs = []\n",
    "\n",
    "t0 = time.time()\n",
    "for i, idx in enumerate(selected):\n",
    "    data = dataset[int(idx)]\n",
    "    x0 = perturbed_map[int(idx)].clone().detach().to(DEVICE)\n",
    "    r, rel = adversarial_radius_relerr(data, x0)\n",
    "    lab = int(data.y.item())\n",
    "    class_adv_radius[class_names[lab]].append(r)\n",
    "    class_rel_errors[class_names[lab]].append(rel)\n",
    "    all_rads.append(r); all_relerrs.append(rel)\n",
    "    if (i+1)%10 == 0:\n",
    "        print(f\" processed {i+1}/{len(selected)} ...\")\n",
    "t1 = time.time()\n",
    "print(f\"? ARR computation done. Time elapsed: {t1-t0:.1f}s\")\n",
    "\n",
    "# reporting ARR\n",
    "print(\"\\nARR (Adversarial Robustness Radius) Stats (on perturbed selected samples):\")\n",
    "for cn in class_names:\n",
    "    vals = class_adv_radius[cn]\n",
    "    errs = class_rel_errors[cn]\n",
    "    if vals:\n",
    "        print(f\" {cn:6s}: avg_radius={np.mean(vals):.4f} ± {np.std(vals):.4f}, avg_relerr={np.mean(errs):.4e} ± {np.std(errs):.4e}\")\n",
    "    else:\n",
    "        print(f\" {cn:6s}: -\")\n",
    "print(f\" Overall: avg_radius={np.mean(all_rads):.4f} ± {np.std(all_rads):.4f}; avg_relerr={np.mean(all_relerrs):.4e} ± {np.std(all_relerrs):.4e}\")\n",
    "\n",
    "# classification on perturbed selected\n",
    "y_true_sel, y_pred_sel, acc_sel, prec_sel, rec_sel, f1_sel = (*eval_perturbed_selected(perturbed_map, selected),)\n",
    "print(\"\\nClassification (perturbed selected) - ARR stage:\")\n",
    "print(f\"Accuracy: {acc_sel*100:.2f}% | Precision: {prec_sel:.4f}, Recall: {rec_sel:.4f}, F1: {f1_sel:.4f}\")\n",
    "print(classification_report(y_true_sel, y_pred_sel, target_names=['clean','trojan'], digits=4))\n",
    "print(confusion_matrix(y_true_sel, y_pred_sel, labels=[0,1]))\n",
    "\n",
    "# -------------------------\n",
    "# Metric 6: Stability Under Input Noise (SUIN) on perturbed subgraphs\n",
    "# -------------------------\n",
    "print(\"\\n\\n================ Metric: Stability Under Input Noise (SUIN) ================\")\n",
    "def stability_for_subgraph(idx, sigma, num_samples):\n",
    "    data = dataset[int(idx)]\n",
    "    base_x = perturbed_map[int(idx)].to(DEVICE)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    batch = batch_for(base_x)\n",
    "    with torch.no_grad():\n",
    "        f_orig = model(base_x, edge_index, batch).squeeze(0)\n",
    "    diffs = []\n",
    "    for _ in range(num_samples):\n",
    "        noise = sigma * torch.randn_like(base_x).to(DEVICE)\n",
    "        f_noisy = model(base_x + noise, edge_index, batch).squeeze(0)\n",
    "        diffs.append(torch.norm(f_noisy - f_orig).item())\n",
    "    return float(np.mean(diffs))\n",
    "\n",
    "t0 = time.time()\n",
    "per_sample_stab = []  # (idx,label, stability, rel_err)\n",
    "for i, idx in enumerate(selected):\n",
    "    s_val = stability_for_subgraph(idx, STAB_SIGMA, STAB_SAMPLES)\n",
    "    # relative error by repeating\n",
    "    re_vals = [stability_for_subgraph(idx, STAB_SIGMA, STAB_SAMPLES) for _ in range(STAB_RELERR_RPTS)]\n",
    "    s_ref = float(np.mean(re_vals))\n",
    "    rel_err = abs(s_val - s_ref) / (abs(s_ref) + 1e-12)\n",
    "    per_sample_stab.append((int(idx), int(labels_all[idx]), float(s_val), float(rel_err)))\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\" processed {i+1}/{len(selected)} ...\")\n",
    "t1 = time.time()\n",
    "print(f\"? SUIN done. Time elapsed: {t1-t0:.1f}s\")\n",
    "\n",
    "# aggregate & print\n",
    "clean_stats = [p for p in per_sample_stab if p[1]==0]\n",
    "troj_stats  = [p for p in per_sample_stab if p[1]==1]\n",
    "def aggs_s(stats):\n",
    "    if not stats: return (0.0,0.0,0.0,0.0)\n",
    "    Ss = np.array([s[2] for s in stats]); Es = np.array([s[3] for s in stats])\n",
    "    return (Ss.mean(), Ss.std(), Es.mean(), Es.std())\n",
    "\n",
    "cS_mean, cS_std, cE_mean, cE_std = aggs_s(clean_stats)\n",
    "tS_mean, tS_std, tE_mean, tE_std = aggs_s(troj_stats)\n",
    "print(\"\\nStability Under Input Noise (on perturbed selected samples):\")\n",
    "print(f\" Clean: avg_stability={cS_mean:.4f} ± {cS_std:.4f}, avg_relerr={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan:avg_stability={tS_mean:.4f} ± {tS_std:.4f}, avg_relerr={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "print(\"\\nSample preview (first 6): (idx,label,stability,rel_err)\")\n",
    "for p in per_sample_stab[:6]:\n",
    "    print(p)\n",
    "\n",
    "# classification on perturbed selected\n",
    "y_true_sel, y_pred_sel, acc_sel, prec_sel, rec_sel, f1_sel = (*eval_perturbed_selected(perturbed_map, selected),)\n",
    "print(\"\\nClassification (perturbed selected) - SUIN stage:\")\n",
    "print(f\"Accuracy: {acc_sel*100:.2f}% | Precision: {prec_sel:.4f}, Recall: {rec_sel:.4f}, F1: {f1_sel:.4f}\")\n",
    "print(classification_report(y_true_sel, y_pred_sel, target_names=['clean','trojan'], digits=4))\n",
    "print(confusion_matrix(y_true_sel, y_pred_sel, labels=[0,1]))\n",
    "\n",
    "print(\"\\n\\nAll metrics computed on the SAME selected subgraphs and the SAME PGD perturbations (perturbed_map).\")\n",
    "print(\"You can adjust PER_CLASS, EPSILON_PGD, ALPHA_PGD, NUM_ITERS_PGD to change attack strength.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6c41b4-92c6-42cc-8c1a-de5bb9829dfc",
   "metadata": {},
   "source": [
    "#### Discard the below run. Not to be used in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fa0eb6-2cac-469b-a5bc-de18ae884ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test graphs: 102; class counts: [11 91]\n",
      "Selected perturbation pool: {0: 11, 1: 20}\n",
      "\n",
      "--- Creating PGD perturbations for selected graphs (shared across metrics) ---\n",
      "  perturbed 10/31\n",
      "  perturbed 20/31\n",
      "  perturbed 30/31\n",
      "  perturbed 31/31\n",
      "Finished PGD perturbations in 49.0s. Perturbed samples: 31\n",
      "\n",
      "Selected graphs: 31. Flipped after perturbation: 3 (9.68%).\n",
      "\n",
      "--- Computing metrics at PERTURBED inputs (this can be slow) ---\n",
      "  computed metrics for 10/31 samples\n"
     ]
    }
   ],
   "source": [
    "# Graph-level robustness evaluation (perturb -> compute metrics -> evaluate perturbed set)\n",
    "# Requires: `model`, `test_loader`, `DEVICE` to already exist in the environment.\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# ---------------------- Tuneable parameters ----------------------\n",
    "PER_CLASS        = 20       # choose up to this many graphs per class to perturb (adjust to dataset size)\n",
    "EPSILON_PGD      = 5.0      # L2 radius for PGD perturbation (applied to flattened features)\n",
    "ALPHA_PGD        = 1.0      # PGD step scaling (we normalize gradient each step)\n",
    "NUM_ITERS_PGD    = 30       # PGD iterations for creating perturbations\n",
    "FD_EPS           = 1e-3     # finite-difference epsilon for Jacobian/fd checks\n",
    "ARR_TRIALS       = 6        # trials per sample for ARR estimation\n",
    "ARR_BS_ITERS     = 10\n",
    "ARR_GROW1        = 1.25\n",
    "ARR_GROW2        = 1.4\n",
    "ARR_MAX_EPS      = 50.0\n",
    "NOISE_SIGMA      = 0.1      # for stability metric (std dev of Gaussian noise)\n",
    "NUM_NOISE_SAMPLES= 20\n",
    "HESS_TRIALS      = 5        # FD trials for Hessian second-order relative error\n",
    "SEED             = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ---------------------- Sanity checks (use variables from training run) ----------------------\n",
    "required = [\"model\", \"test_loader\", \"DEVICE\"]\n",
    "missing = [r for r in required if r not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Required variables missing in current environment: {missing}.\\n\"\n",
    "                       \"Make sure you executed your train/eval notebook first so model, test_loader, DEVICE exist.\")\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# get dataset list (preserve original ordering)\n",
    "dataset = list(test_loader.dataset)\n",
    "n_test = len(dataset)\n",
    "labels_all = np.array([int(d.y.item()) for d in dataset])\n",
    "print(f\"Test graphs: {n_test}; class counts: {np.bincount(labels_all)}\")\n",
    "\n",
    "# ---------------------- Select samples (PER_CLASS per class) ----------------------\n",
    "rng = np.random.default_rng(SEED)\n",
    "selected_idxs = []\n",
    "for cls in sorted(np.unique(labels_all)):\n",
    "    idxs = np.where(labels_all == cls)[0]\n",
    "    if len(idxs) == 0:\n",
    "        continue\n",
    "    k = min(PER_CLASS, len(idxs))\n",
    "    chosen = rng.choice(idxs, size=k, replace=False)\n",
    "    selected_idxs.extend(chosen.tolist())\n",
    "selected_idxs = np.array(sorted(selected_idxs), dtype=np.int64)\n",
    "print(\"Selected perturbation pool:\", {int(cls): int((labels_all[selected_idxs]==cls).sum()) for cls in np.unique(labels_all)})\n",
    "\n",
    "if len(selected_idxs) == 0:\n",
    "    raise RuntimeError(\"No samples selected - check PER_CLASS and the test split.\")\n",
    "\n",
    "# helper to produce batch vector for single graph\n",
    "def batch_for(x): \n",
    "    return torch.zeros(x.size(0), dtype=torch.long, device=DEVICE)\n",
    "\n",
    "# ---------------------- Save original predictions for selected samples ----------------------\n",
    "orig_preds = {}\n",
    "with torch.no_grad():\n",
    "    for idx in selected_idxs:\n",
    "        data = dataset[int(idx)]\n",
    "        x = data.x.to(DEVICE)\n",
    "        out = model(x, data.edge_index.to(DEVICE), batch_for(x))\n",
    "        orig_preds[int(idx)] = int(out.argmax(dim=1).item())\n",
    "\n",
    "# ---------------------- Create one shared set of perturbations via PGD ----------------------\n",
    "print(\"\\n--- Creating PGD perturbations for selected graphs (shared across metrics) ---\")\n",
    "perturbed_map = {}   # idx -> perturbed x tensor (on DEVICE)\n",
    "t0 = time.time()\n",
    "for count, idx in enumerate(selected_idxs, start=1):\n",
    "    data = dataset[int(idx)]\n",
    "    x_orig = data.x.detach().clone().to(DEVICE)            # shape (N, F)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    n_nodes, feat_dim = x_orig.shape\n",
    "    flat_dim = n_nodes * feat_dim\n",
    "\n",
    "    # initialize at random direction scaled to EPSILON_PGD\n",
    "    delta = torch.randn_like(x_orig, device=DEVICE)\n",
    "    delta = delta * (EPSILON_PGD / (delta.view(-1).norm() + 1e-12))\n",
    "    x_adv = (x_orig + delta).detach().clone().requires_grad_(True)\n",
    "    y_true = torch.tensor([int(data.y.item())], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    # PGD loop: maximize CE (untargeted)\n",
    "    for it in range(NUM_ITERS_PGD):\n",
    "        out = model(x_adv, edge_index, batch_for(x_adv))   # shape [1, C]\n",
    "        loss = F.cross_entropy(out, y_true)\n",
    "        grad_x = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "        gnorm = grad_x.view(-1).norm().item()\n",
    "        if gnorm == 0.0:\n",
    "            break\n",
    "        step = (ALPHA_PGD * grad_x) / (gnorm + 1e-12)\n",
    "        x_adv = (x_adv + step).detach()\n",
    "        # project back to L2 ball\n",
    "        delta_now = (x_adv - x_orig).view(-1)\n",
    "        dnorm = delta_now.norm().item()\n",
    "        if dnorm > EPSILON_PGD:\n",
    "            delta_now = delta_now * (EPSILON_PGD / (dnorm + 1e-12))\n",
    "            x_adv = (x_orig + delta_now.view_as(x_orig)).detach()\n",
    "        x_adv = x_adv.requires_grad_(True)\n",
    "\n",
    "    perturbed_map[int(idx)] = x_adv.detach().clone()\n",
    "    if count % 10 == 0 or count == len(selected_idxs):\n",
    "        print(f\"  perturbed {count}/{len(selected_idxs)}\")\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"Finished PGD perturbations in {t1-t0:.1f}s. Perturbed samples: {len(perturbed_map)}\")\n",
    "\n",
    "# ---------------------- Flip statistics after perturbation (selected samples only) ----------------------\n",
    "adv_preds = {}\n",
    "with torch.no_grad():\n",
    "    for idx in selected_idxs:\n",
    "        data = dataset[int(idx)]\n",
    "        x_adv = perturbed_map[int(idx)].to(DEVICE)\n",
    "        out_adv = model(x_adv, data.edge_index.to(DEVICE), batch_for(x_adv))\n",
    "        adv_preds[int(idx)] = int(out_adv.argmax(dim=1).item())\n",
    "\n",
    "orig_array = np.array([orig_preds[int(i)] for i in selected_idxs])\n",
    "adv_array  = np.array([adv_preds[int(i)] for i in selected_idxs])\n",
    "num_flips = int((orig_array != adv_array).sum())\n",
    "print(f\"\\nSelected graphs: {len(selected_idxs)}. Flipped after perturbation: {num_flips} ({100.0 * num_flips/len(selected_idxs):.2f}%).\")\n",
    "\n",
    "# ---------------------- Metric computation ON THE PERTURBED INPUTS ----------------------\n",
    "print(\"\\n--- Computing metrics at PERTURBED inputs (this can be slow) ---\")\n",
    "per_sample_records = []  # list of dicts, one per selected idx\n",
    "\n",
    "def safe_jacobian(f, x):\n",
    "    \"\"\"Try to compute full jacobian; fallback to per-output loop on failure.\"\"\"\n",
    "    try:\n",
    "        J = torch.autograd.functional.jacobian(f, x)   # shape (C, D)\n",
    "    except RuntimeError:\n",
    "        # fallback: compute per-output jacobian rows\n",
    "        out0 = f(x)\n",
    "        C = int(out0.shape[0])\n",
    "        rows = []\n",
    "        for c in range(C):\n",
    "            def scalar_f(z, cidx=c):\n",
    "                return f(z)[cidx]\n",
    "            row = torch.autograd.functional.jacobian(scalar_f, x)\n",
    "            rows.append(row.unsqueeze(0))\n",
    "        J = torch.cat(rows, dim=0)\n",
    "    return J\n",
    "\n",
    "for i, idx in enumerate(selected_idxs):\n",
    "    idx = int(idx)\n",
    "    data = dataset[idx]\n",
    "    x_adv = perturbed_map[idx].detach().clone().to(DEVICE).requires_grad_(True)   # perturbed baseline\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    n_nodes, feat_dim = x_adv.shape\n",
    "    d = n_nodes * feat_dim\n",
    "\n",
    "    # flatten view and safe wrapper\n",
    "    x_flat = x_adv.view(-1).detach().clone().requires_grad_(True)\n",
    "\n",
    "    def f_flat(z):\n",
    "        x_mat = z.view_as(x_adv)\n",
    "        out = model(x_mat, edge_index, batch_for(x_mat))\n",
    "        # model returns shape [1, C]; squeeze to (C,)\n",
    "        return out.squeeze(0)\n",
    "\n",
    "    # Jacobian J (C, D)\n",
    "    try:\n",
    "        J = safe_jacobian(f_flat, x_flat).detach()   # (C, D)\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Jacobian failed for idx={idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Jacobian Frobenius norm\n",
    "    jac_fro = float(torch.norm(J, p='fro').item())\n",
    "\n",
    "    # finite-difference relative error for Jacobian (single trial)\n",
    "    delta_fd = FD_EPS * torch.randn(d, device=DEVICE)\n",
    "    pred_change = (J @ delta_fd)                      # (C,)\n",
    "    f0 = f_flat(x_flat).detach()\n",
    "    f0p = f_flat(x_flat + delta_fd).detach()\n",
    "    actual_change = (f0p - f0)\n",
    "    fd_rel_err_jac = float((torch.norm(pred_change - actual_change) / (torch.norm(actual_change) + 1e-8)).item())\n",
    "\n",
    "    # Local Lipschitz (spectral norm of J)\n",
    "    try:\n",
    "        # prefer SVD on CPU if large to reduce CUDA memory pressure\n",
    "        U, S, Vh = torch.linalg.svd(J, full_matrices=False)\n",
    "        sigma_max = float(S[0].item())\n",
    "    except RuntimeError:\n",
    "        # fallback eigen on J @ J^T\n",
    "        Jcpu = J.cpu()\n",
    "        JJT = (Jcpu @ Jcpu.T).numpy()\n",
    "        eigvals = np.linalg.eigvalsh(JJT)\n",
    "        sigma_max = float(np.sqrt(max(eigvals.max(), 0.0)))\n",
    "\n",
    "    # For Lipschitz we can reuse fd_rel_err_jac (since it's based on J)\n",
    "    fd_rel_err_lip = fd_rel_err_jac\n",
    "\n",
    "    # Hessian curvature proxy (||grad_x log p_pred||^2)\n",
    "    # define h(x_flat) returns log-prob of predicted class at baseline x_flat\n",
    "    with torch.no_grad():\n",
    "        logits_baseline = f_flat(x_flat).detach()\n",
    "    pred_class = int(logits_baseline.argmax().item())\n",
    "\n",
    "    def h_flat(z):\n",
    "        x_mat = z.view_as(x_adv)\n",
    "        out = model(x_mat, edge_index, batch_for(x_mat)).squeeze(0)\n",
    "        logp = F.log_softmax(out, dim=0)\n",
    "        return logp[pred_class]\n",
    "\n",
    "    # compute g = grad h(x_flat) w.r.t x_flat (allow_unused in case graph doesn't use inputs)\n",
    "    h0 = h_flat(x_flat)\n",
    "    g = torch.autograd.grad(h0, x_flat, retain_graph=False, create_graph=False, allow_unused=True)[0]\n",
    "    if g is None:\n",
    "        g = torch.zeros_like(x_flat)\n",
    "    lambda_proxy = float((g.norm().item())**2)\n",
    "\n",
    "    # Hessian FD relative error (average across trials)\n",
    "    h_fd_errs = []\n",
    "    for t in range(HESS_TRIALS):\n",
    "        delta = FD_EPS * torch.randn_like(x_flat).to(DEVICE)\n",
    "        gt_delta = float(torch.dot(g, delta).item())\n",
    "        pred_second = 0.5 * (gt_delta ** 2)\n",
    "        actual_second = float((h_flat(x_flat + delta) - h0 - torch.dot(g, delta)).item())\n",
    "        rel_err = abs(pred_second - actual_second) / (abs(actual_second) + 1e-8)\n",
    "        h_fd_errs.append(rel_err)\n",
    "    fd_rel_err_hess = float(np.mean(h_fd_errs))\n",
    "\n",
    "    # Prediction margin (on perturbed point) using logits (not probs)\n",
    "    logits = f_flat(x_flat).detach()\n",
    "    pred_c = int(logits.argmax().item())\n",
    "    logit_pred = float(logits[pred_c].item())\n",
    "    other_logits = logits.clone()\n",
    "    other_logits[pred_c] = -float('inf')\n",
    "    second_logit = float(other_logits.max().item())\n",
    "    margin_val = float(logit_pred - second_logit)\n",
    "\n",
    "    # FD relative error for margin (single trial)\n",
    "    delta = FD_EPS * torch.randn_like(x_flat).to(DEVICE)\n",
    "    logits_p = f_flat(x_flat + delta).detach()\n",
    "    pred_c_p = int(logits_p.argmax().item())\n",
    "    # compute margin w.r.t the same pred_c (we want marginal change of that predicted class)\n",
    "    pred_logit_p = float(logits_p[pred_c].item()) if pred_c < logits_p.shape[0] else float(logits_p.max().item())\n",
    "    other_p = logits_p.clone()\n",
    "    other_p[pred_c] = -float('inf')\n",
    "    second_p = float(other_p.max().item())\n",
    "    margin_p = float(pred_logit_p - second_p)\n",
    "    fd_rel_err_margin = abs(margin_val - margin_p) / (abs(margin_p) + 1e-12)\n",
    "\n",
    "    # ARR: adversarial radius around perturbed point (estimate)\n",
    "    def is_same_label_at(x_flat_candidate, base_label):\n",
    "        x_mat = x_flat_candidate.view_as(x_adv)\n",
    "        with torch.no_grad():\n",
    "            out = model(x_mat, edge_index, batch_for(x_mat))\n",
    "            return int(out.argmax(dim=1).item()) == base_label\n",
    "\n",
    "    # minimal radius estimation along random directions (binary search)\n",
    "    def adversarial_radius_single(x0_flat, base_label, initial_eps=1e-3, growth=ARR_GROW1,\n",
    "                                  max_eps=ARR_MAX_EPS, bs_iters=ARR_BS_ITERS):\n",
    "        # returns candidate radius (float)\n",
    "        eps = initial_eps\n",
    "        # expand until flip or cap\n",
    "        while eps < max_eps:\n",
    "            direction = torch.randn_like(x0_flat).to(DEVICE)\n",
    "            direction = direction / (direction.norm() + 1e-12)\n",
    "            if not is_same_label_at(x0_flat + eps * direction, base_label):\n",
    "                # found flip at eps along this direction: binary search between eps/growth and eps\n",
    "                low, high = eps / growth, eps\n",
    "                for _ in range(bs_iters):\n",
    "                    mid = 0.5 * (low + high)\n",
    "                    if is_same_label_at(x0_flat + mid * direction, base_label):\n",
    "                        low = mid\n",
    "                    else:\n",
    "                        high = mid\n",
    "                return float(high)\n",
    "            eps *= growth\n",
    "        return float(max_eps)\n",
    "\n",
    "    # combine multiple trials with two growth parameters to compute relative error\n",
    "    base_label = int(pred_c)\n",
    "    radii = []\n",
    "    for trial in range(ARR_TRIALS):\n",
    "        # try with growth1 then growth2 for relerr\n",
    "        r1 = adversarial_radius_single(x_flat, base_label, growth=ARR_GROW1)\n",
    "        r2 = adversarial_radius_single(x_flat, base_label, growth=ARR_GROW2)\n",
    "        r = float(min(r1, r2))\n",
    "        rel = abs(r1 - r2) / (abs(r2) + 1e-12)\n",
    "        radii.append((r, rel))\n",
    "    radii_vals = [rv for rv,_ in radii]\n",
    "    rels_vals = [rel for _,rel in radii]\n",
    "    adv_radius_est = float(np.min(radii_vals))\n",
    "    adv_radius_relerr = float(np.mean(rels_vals))\n",
    "\n",
    "    # Stability under input noise (averaged norm difference in logits)\n",
    "    f_orig = f_flat(x_flat).detach()\n",
    "    noise_diffs = []\n",
    "    for _ in range(NUM_NOISE_SAMPLES):\n",
    "        noise = NOISE_SIGMA * torch.randn_like(x_flat).to(DEVICE)\n",
    "        f_noisy = f_flat(x_flat + noise).detach()\n",
    "        noise_diffs.append(float(torch.norm(f_noisy - f_orig).item()))\n",
    "    stability_val = float(np.mean(noise_diffs))\n",
    "    # relative error for stability (resampling)\n",
    "    revals = []\n",
    "    for _ in range(3):\n",
    "        revals.append(float(np.mean([float(torch.norm(f_flat(x_flat + NOISE_SIGMA * torch.randn_like(x_flat).to(DEVICE)) - f_orig).item()) for __ in range(int(NUM_NOISE_SAMPLES/2) or 1)])))\n",
    "    stability_relerr = abs(stability_val - float(np.mean(revals))) / (abs(float(np.mean(revals))) + 1e-12)\n",
    "\n",
    "    # collect per-sample record\n",
    "    rec = {\n",
    "        \"idx\": idx,\n",
    "        \"label\": int(data.y.item()),\n",
    "        \"jac_fro\": jac_fro,\n",
    "        \"fd_rel_jac\": fd_rel_err_jac,\n",
    "        \"sigma_max\": sigma_max,\n",
    "        \"fd_rel_lip\": fd_rel_err_lip,\n",
    "        \"lambda_proxy\": lambda_proxy,\n",
    "        \"fd_rel_hess\": fd_rel_err_hess,\n",
    "        \"margin\": margin_val,\n",
    "        \"fd_rel_margin\": fd_rel_err_margin,\n",
    "        \"adv_radius\": adv_radius_est,\n",
    "        \"adv_radius_relerr\": adv_radius_relerr,\n",
    "        \"stability\": stability_val,\n",
    "        \"stability_relerr\": stability_relerr,\n",
    "        \"orig_pred\": orig_preds[idx],\n",
    "        \"adv_pred\": adv_preds[idx]\n",
    "    }\n",
    "    per_sample_records.append(rec)\n",
    "\n",
    "    if (i+1) % 10 == 0 or (i+1) == len(selected_idxs):\n",
    "        print(f\"  computed metrics for {i+1}/{len(selected_idxs)} samples\")\n",
    "\n",
    "# ---------------------- Aggregate & print per-class stats ----------------------\n",
    "import math\n",
    "def mean_std(arr):\n",
    "    if len(arr)==0:\n",
    "        return (0.0, 0.0)\n",
    "    a = np.array(arr, dtype=float)\n",
    "    return (float(a.mean()), float(a.std()))\n",
    "\n",
    "records = per_sample_records\n",
    "if not records:\n",
    "    raise RuntimeError(\"No per-sample records were computed.\")\n",
    "\n",
    "# group by label\n",
    "records_by_label = {0: [], 1: []}\n",
    "for r in records:\n",
    "    records_by_label[int(r[\"label\"])].append(r)\n",
    "\n",
    "print(\"\\n=== Aggregated metrics on PERTURBED selected samples (mean ± std) ===\")\n",
    "metrics_to_print = [\n",
    "    (\"jac_fro\", \"Jacobian Frobenius norm\"),\n",
    "    (\"fd_rel_jac\", \"Jacobian FD relative error\"),\n",
    "    (\"sigma_max\", \"Local Lipschitz (spectral)\"),\n",
    "    (\"fd_rel_lip\", \"Lipschitz FD rel err\"),\n",
    "    (\"lambda_proxy\", \"Hessian curvature proxy (||grad logp||^2)\"),\n",
    "    (\"fd_rel_hess\", \"Hessian FD rel err\"),\n",
    "    (\"margin\", \"Prediction margin (logit diff)\"),\n",
    "    (\"fd_rel_margin\", \"Margin FD rel err\"),\n",
    "    (\"adv_radius\", \"Adversarial Robustness Radius (est)\"),\n",
    "    (\"adv_radius_relerr\", \"ARR rel err\"),\n",
    "    (\"stability\", \"Stability under input noise\"),\n",
    "    (\"stability_relerr\", \"Stability rel err\"),\n",
    "]\n",
    "\n",
    "for cls in sorted(records_by_label.keys()):\n",
    "    recs = records_by_label[cls]\n",
    "    print(f\"\\nClass {cls} (n={len(recs)})\")\n",
    "    for key, pretty in metrics_to_print:\n",
    "        vals = [r[key] for r in recs if not (isinstance(r[key], float) and (math.isinf(r[key]) or math.isnan(r[key])))]\n",
    "        m, s = mean_std(vals) if vals else (float('nan'), float('nan'))\n",
    "        print(f\"  {pretty:40s}: {m:.4e} ± {s:.4e}\")\n",
    "\n",
    "# preview first 6 per-sample entries\n",
    "print(\"\\nSample preview (first 6 records):\")\n",
    "for r in records[:6]:\n",
    "    print(r)\n",
    "\n",
    "# ---------------------- Evaluate model on PERTURBED samples only ----------------------\n",
    "y_true_sel = np.array([int(dataset[int(idx)].y.item()) for idx in selected_idxs])\n",
    "y_pred_sel = np.array([int(per[\"adv_pred\"]) for per in per_sample_records])\n",
    "\n",
    "acc_sel = accuracy_score(y_true_sel, y_pred_sel)\n",
    "prec_sel, rec_sel, f1_sel, _ = precision_recall_fscore_support(y_true_sel, y_pred_sel, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n=== Evaluation on PERTURBED samples only ===\")\n",
    "print(f\"Selected perturbed samples: {len(selected_idxs)}\")\n",
    "print(f\"Accuracy: {acc_sel*100:.2f}%\")\n",
    "print(f\"Precision: {prec_sel:.4f}, Recall: {rec_sel:.4f}, F1: {f1_sel:.4f}\\n\")\n",
    "print(\"Classification report (perturbed samples):\")\n",
    "print(classification_report(y_true_sel, y_pred_sel, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix (perturbed samples):\")\n",
    "print(confusion_matrix(y_true_sel, y_pred_sel, labels=[0,1]))\n",
    "\n",
    "# perturbation success (flips) breakdown by class\n",
    "orig = np.array([orig_preds[int(i)] for i in selected_idxs])\n",
    "adv  = np.array([adv_preds[int(i)] for i in selected_idxs])\n",
    "flips_total = (orig != adv).sum()\n",
    "print(f\"\\nPerturbation success (flips): {flips_total}/{len(selected_idxs)} = {100.0*flips_total/len(selected_idxs):.2f}%\")\n",
    "for cls in [0,1]:\n",
    "    idxs_cls = [j for j,r in enumerate(selected_idxs) if labels_all[r]==cls]\n",
    "    if len(idxs_cls)==0:\n",
    "        continue\n",
    "    flips_cls = (orig[idxs_cls] != adv[idxs_cls]).sum()\n",
    "    print(f\"  class {cls}: {flips_cls}/{len(idxs_cls)} = {100.0*flips_cls/len(idxs_cls):.2f}%\")\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa346fa-16b7-4c3a-aeea-8f1a96a9114a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
