{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfa6ce9e-9a74-4424-a211-23c117d27959",
   "metadata": {},
   "source": [
    "#### Training Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79de5491-1d0a-4061-a85c-bb3bdf26c81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(\n",
      "/home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "Building subgraphs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 674/674 [00:17<00:00, 39.46it/s]\n",
      "/home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 674 subgraphs (usable)\n",
      "Train: 471, Val: 101, Test: 102\n",
      "Epoch 001 | Loss 0.7464 | Val 0.2673\n",
      "Epoch 005 | Loss 0.6193 | Val 0.6238\n",
      "Epoch 010 | Loss 0.5896 | Val 0.5941\n",
      "Epoch 015 | Loss 0.5101 | Val 0.6832\n",
      "Epoch 020 | Loss 0.3784 | Val 0.8020\n",
      "Epoch 025 | Loss 0.2963 | Val 0.8317\n",
      "Epoch 030 | Loss 0.2182 | Val 0.8812\n",
      "Epoch 035 | Loss 0.1549 | Val 0.9208\n",
      "Epoch 040 | Loss 0.1265 | Val 0.9208\n",
      "Epoch 045 | Loss 0.1028 | Val 0.9208\n",
      "Epoch 050 | Loss 0.0897 | Val 0.9208\n",
      "Epoch 055 | Loss 0.0840 | Val 0.9208\n",
      "Epoch 060 | Loss 0.0851 | Val 0.9307\n",
      "Epoch 065 | Loss 0.0641 | Val 0.9307\n",
      "Epoch 070 | Loss 0.0713 | Val 0.9604\n",
      "Epoch 075 | Loss 0.0604 | Val 0.9604\n",
      "Epoch 080 | Loss 0.0645 | Val 0.9604\n",
      "\n",
      "Final Evaluation (Subgraph-Level)\n",
      "=================================\n",
      "Test Accuracy: 0.9902\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9167    1.0000    0.9565        11\n",
      "           1     1.0000    0.9890    0.9945        91\n",
      "\n",
      "    accuracy                         0.9902       102\n",
      "   macro avg     0.9583    0.9945    0.9755       102\n",
      "weighted avg     0.9910    0.9902    0.9904       102\n",
      "\n",
      "Confusion Matrix:\n",
      "[[11  0]\n",
      " [ 1 90]]\n"
     ]
    }
   ],
   "source": [
    "# train_subgraph_gnn_fixed.py\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 80\n",
    "LR = 1e-3\n",
    "HID_DIM = 64\n",
    "\n",
    "# -----------------------\n",
    "# Load node features\n",
    "# -----------------------\n",
    "nodes_df = pd.read_csv(\"GNNDatasets/node.csv\")\n",
    "nodes_df[\"uid\"] = nodes_df[\"circuit_name\"].astype(str) + \"::\" + nodes_df[\"node\"].astype(str)\n",
    "\n",
    "# one-hot gate_type\n",
    "if \"gate_type\" in nodes_df.columns:\n",
    "    gate_ohe = pd.get_dummies(nodes_df[\"gate_type\"], prefix=\"gt\")\n",
    "    nodes_feat_df = pd.concat([nodes_df.drop(columns=[\"gate_type\"]), gate_ohe], axis=1)\n",
    "else:\n",
    "    nodes_feat_df = nodes_df.copy()\n",
    "\n",
    "meta_cols = {\"uid\",\"node\",\"circuit_name\",\"label\",\"label_node\",\"label_graph\",\"label_subgraph\",\"folder\"}\n",
    "num_cols = [c for c in nodes_feat_df.columns if c not in meta_cols and pd.api.types.is_numeric_dtype(nodes_feat_df[c])]\n",
    "\n",
    "uid_to_feat = {}\n",
    "for _, r in nodes_feat_df.iterrows():\n",
    "    uid_to_feat[r[\"uid\"]] = r[num_cols].astype(float).values\n",
    "\n",
    "scaler = StandardScaler().fit(np.stack(list(uid_to_feat.values())))\n",
    "for k in list(uid_to_feat.keys()):\n",
    "    uid_to_feat[k] = scaler.transform(uid_to_feat[k].reshape(1,-1)).reshape(-1)\n",
    "\n",
    "feat_dim = len(uid_to_feat[list(uid_to_feat.keys())[0]])\n",
    "\n",
    "# -----------------------\n",
    "# Merge edge CSVs\n",
    "# -----------------------\n",
    "edge_files = [\n",
    "    \"GNNDatasets/node_edges.csv\",\n",
    "    \"GNNDatasets/subgraph_edges_andxor.csv\",\n",
    "    \"GNNDatasets/subgraph_edges_countermux.csv\",\n",
    "    \"GNNDatasets/subgraph_edges_fsmor.csv\",\n",
    "]\n",
    "\n",
    "edges_by_circuit = defaultdict(list)\n",
    "for ef in edge_files:\n",
    "    df = pd.read_csv(ef)\n",
    "    for _, r in df.iterrows():\n",
    "        edges_by_circuit[r[\"circuit_name\"]].append((r[\"src\"], r[\"dst\"]))\n",
    "\n",
    "# -----------------------\n",
    "# Build dataset\n",
    "# -----------------------\n",
    "sub_df = pd.read_csv(\"GNNDatasets/subgraph.csv\")\n",
    "data_list, labels = [], []\n",
    "\n",
    "for idx, row in tqdm(sub_df.iterrows(), total=len(sub_df), desc=\"Building subgraphs\"):\n",
    "    ckt = row[\"circuit_name\"]\n",
    "    lbl = int(row.get(\"label_subgraph\", row.get(\"label\", 0)))\n",
    "    \n",
    "    if ckt not in edges_by_circuit:\n",
    "        continue\n",
    "    \n",
    "    # collect node uids from node.csv that belong to this circuit\n",
    "    sub_nodes = nodes_df[nodes_df[\"circuit_name\"]==ckt][\"node\"].tolist()\n",
    "    if not sub_nodes: \n",
    "        continue\n",
    "    \n",
    "    uid_map = {n:i for i,n in enumerate(sub_nodes)}\n",
    "    x_list = []\n",
    "    for n in sub_nodes:\n",
    "        uid = f\"{ckt}::{n}\"\n",
    "        if uid in uid_to_feat:\n",
    "            x_list.append(uid_to_feat[uid])\n",
    "        else:\n",
    "            x_list.append(np.zeros(feat_dim))\n",
    "    x = torch.tensor(np.vstack(x_list), dtype=torch.float)\n",
    "    \n",
    "    # build edge_index\n",
    "    edge_idx = [[], []]\n",
    "    for u,v in edges_by_circuit[ckt]:\n",
    "        if u in uid_map and v in uid_map:\n",
    "            edge_idx[0].append(uid_map[u]); edge_idx[1].append(uid_map[v])\n",
    "            edge_idx[0].append(uid_map[v]); edge_idx[1].append(uid_map[u])\n",
    "    if not edge_idx[0]:\n",
    "        continue\n",
    "    edge_index = torch.tensor(edge_idx, dtype=torch.long)\n",
    "    \n",
    "    data = Data(x=x, edge_index=edge_index, y=torch.tensor([lbl], dtype=torch.long))\n",
    "    data.circuit_name = ckt\n",
    "    data_list.append(data)\n",
    "    labels.append(lbl)\n",
    "\n",
    "print(f\"Built {len(data_list)} subgraphs (usable)\")\n",
    "\n",
    "# -----------------------\n",
    "# Split\n",
    "# -----------------------\n",
    "labels = np.array(labels)\n",
    "idxs = np.arange(len(data_list))\n",
    "train_idx, temp_idx, y_train, y_temp = train_test_split(idxs, labels, test_size=0.3, \n",
    "                                                        stratify=labels, random_state=RANDOM_SEED)\n",
    "val_idx, test_idx, y_val, y_test = train_test_split(temp_idx, y_temp, test_size=0.5,\n",
    "                                                    stratify=y_temp, random_state=RANDOM_SEED)\n",
    "\n",
    "train_loader = DataLoader([data_list[i] for i in train_idx], batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader([data_list[i] for i in val_idx], batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader([data_list[i] for i in test_idx], batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_idx)}, Val: {len(val_idx)}, Test: {len(test_idx)}\")\n",
    "\n",
    "# -----------------------\n",
    "# Model\n",
    "# -----------------------\n",
    "class SubgraphClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim=HID_DIM, out_dim=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_dim, hid_dim)\n",
    "        self.conv2 = SAGEConv(hid_dim, hid_dim)\n",
    "        self.lin = nn.Linear(hid_dim, out_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.4, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.lin(x)\n",
    "\n",
    "model = SubgraphClassifier(feat_dim).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=5e-4)\n",
    "\n",
    "# class weights\n",
    "cls_counts = np.bincount(labels)\n",
    "w = torch.tensor([cls_counts.sum()/c for c in cls_counts], dtype=torch.float32).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(weight=w)\n",
    "\n",
    "# -----------------------\n",
    "# Training loop\n",
    "# -----------------------\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    ys, preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for b in loader:\n",
    "            b = b.to(DEVICE)\n",
    "            out = model(b.x, b.edge_index, b.batch)\n",
    "            p = out.argmax(dim=1).cpu().numpy()\n",
    "            ys.extend(b.y.cpu().numpy())\n",
    "            preds.extend(p)\n",
    "    return np.array(ys), np.array(preds)\n",
    "\n",
    "best_val, best_state = -1, None\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss=0\n",
    "    for b in train_loader:\n",
    "        b = b.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(b.x, b.edge_index, b.batch)\n",
    "        loss = criterion(out, b.y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if epoch%5==0 or epoch==1:\n",
    "        yv,pv = evaluate(val_loader)\n",
    "        acc = accuracy_score(yv,pv)\n",
    "        print(f\"Epoch {epoch:03d} | Loss {total_loss/len(train_loader):.4f} | Val {acc:.4f}\")\n",
    "        if acc>best_val: \n",
    "            best_val=acc; best_state=model.state_dict().copy()\n",
    "\n",
    "# load best\n",
    "if best_state: model.load_state_dict(best_state)\n",
    "\n",
    "# -----------------------\n",
    "# Final test\n",
    "# -----------------------\n",
    "yt,pt = evaluate(test_loader)\n",
    "print(\"\\nFinal Evaluation (Subgraph-Level)\")\n",
    "print(\"=================================\")\n",
    "print(f\"Test Accuracy: {accuracy_score(yt,pt):.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(yt,pt,digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(yt,pt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d73614-3893-45e8-ae2f-c68d2240a89f",
   "metadata": {},
   "source": [
    "#### Jacobain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8bcf656-c8f3-4ec7-a6db-0bfd7b8512a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test subgraphs: 102; class counts: [11 91]\n",
      "Selected counts: {0: 11, 1: 20}\n",
      "\n",
      "Running PGD perturbation on selected subgraphs (this may take a while)...\n",
      "? PGD perturbation finished for selected subgraphs.\n",
      "\n",
      "============= Robustness Evaluation (Full Test Set: perturbed selected + rest original) =============\n",
      "Accuracy: 96.08%\n",
      "Precision: 0.9651, Recall: 0.9608, F1: 0.9622\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.7692    0.9091    0.8333        11\n",
      "      trojan     0.9888    0.9670    0.9778        91\n",
      "\n",
      "    accuracy                         0.9608       102\n",
      "   macro avg     0.8790    0.9381    0.9056       102\n",
      "weighted avg     0.9651    0.9608    0.9622       102\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  1]\n",
      " [ 3 88]]\n",
      "\n",
      "Selected subgraphs: 31. Flipped after attack: 3 (9.68%).\n",
      "\n",
      "Computing Jacobian norms & FD relative error on the PERTURBED selected subgraphs...\n",
      "\n",
      "Jacobian norms & FD relative errors (aggregated):\n",
      " Clean subgraphs:  avg_norm=0.4876 ± 0.1973, avg_FDrel=2.7351e-02 ± 5.7933e-02\n",
      " Trojan subgraphs: avg_norm=0.9912 ± 2.6177, avg_FDrel=7.6477e-01 ± 2.4422e+00\n",
      "\n",
      "Sample preview (first 6): (idx,label,jacobian_frob,FD_rel_err)\n",
      "(5, 1, 0.5232011079788208, 0.006874935235828161)\n",
      "(7, 1, 12.308995246887207, 0.01924426294863224)\n",
      "(12, 0, 0.1714828461408615, 0.01224440336227417)\n",
      "(14, 0, 0.3758105933666229, 0.009414240717887878)\n",
      "(15, 1, 0.36891114711761475, 0.001470681163482368)\n",
      "(18, 0, 0.9355684518814087, 0.01225760206580162)\n",
      "\n",
      "Done. (Order: PGD perturbation -> full-test evaluation -> Jacobian computed at perturbed inputs.)\n"
     ]
    }
   ],
   "source": [
    "# Subgraph-level: PGD-first ? evaluation ? Jacobian + FD relative error\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# ---------------------- PARAMETERS ----------------------\n",
    "PER_CLASS = 20        # # subgraphs per class to perturb (adjust)\n",
    "EPSILON = 4.0         # L2 radius for PGD perturbation (on flattened subgraph features)\n",
    "ALPHA = 1.0           # PGD step size (normalized)\n",
    "NUM_ITERS = 30        # PGD iterations\n",
    "FD_EPS = 1e-3         # finite-difference epsilon for Jacobian check\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# ---------------------- Sanity check ----------------------\n",
    "required = [\"model\", \"test_loader\", \"DEVICE\"]\n",
    "for v in required:\n",
    "    if v not in globals():\n",
    "        raise RuntimeError(f\"Required variable '{v}' not found in the environment.\")\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# ---------------------- Get test dataset as list ----------------------\n",
    "test_data_list = list(test_loader.dataset)   # preserve the same order used by DataLoader\n",
    "test_labels = np.array([int(d.y.item()) for d in test_data_list])\n",
    "n_test = len(test_data_list)\n",
    "print(f\"Test subgraphs: {n_test}; class counts: {np.bincount(test_labels)}\")\n",
    "\n",
    "# ---------------------- Select subgraphs to perturb (PER_CLASS per class) ----------------------\n",
    "rng = np.random.default_rng(SEED)\n",
    "selected_idxs = []\n",
    "for cls in [0, 1]:\n",
    "    idxs = np.where(test_labels == cls)[0]\n",
    "    if len(idxs) == 0:\n",
    "        continue\n",
    "    k = min(PER_CLASS, len(idxs))\n",
    "    chosen = rng.choice(idxs, size=k, replace=False)\n",
    "    selected_idxs.extend(chosen.tolist())\n",
    "selected_idxs = np.array(sorted(selected_idxs), dtype=np.int64)\n",
    "print(\"Selected counts:\", {0:int((test_labels[selected_idxs]==0).sum()), 1:int((test_labels[selected_idxs]==1).sum())})\n",
    "\n",
    "# ---------------------- PGD perturbation for selected subgraphs ----------------------\n",
    "perturbed_map = {}  # idx -> perturbed x tensor (on DEVICE)\n",
    "print(\"\\nRunning PGD perturbation on selected subgraphs (this may take a while)...\")\n",
    "\n",
    "for idx in selected_idxs:\n",
    "    data = test_data_list[int(idx)]\n",
    "    x_orig = data.x.detach().to(DEVICE)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    n_nodes, feat_dim = x_orig.shape\n",
    "\n",
    "    # initialize adv example (random direction scaled to EPSILON)\n",
    "    delta = torch.randn_like(x_orig, device=DEVICE)\n",
    "    delta = delta * (EPSILON / (delta.view(-1).norm() + 1e-12))\n",
    "    x_adv = (x_orig + delta).detach().clone().requires_grad_(True)\n",
    "\n",
    "    # batch vector for single-graph forward\n",
    "    batch_zero = torch.zeros(n_nodes, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    y_true = torch.tensor([int(data.y.item())], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    for it in range(NUM_ITERS):\n",
    "        # forward\n",
    "        out = model(x_adv, edge_index, batch_zero)            # shape [1, C]\n",
    "        loss = F.cross_entropy(out, y_true)\n",
    "        # gradient wrt inputs\n",
    "        grad_x = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "        gnorm = grad_x.view(-1).norm().item()\n",
    "        if gnorm == 0:\n",
    "            break\n",
    "        step = (ALPHA * grad_x) / (gnorm + 1e-12)\n",
    "        x_adv = (x_adv + step).detach()\n",
    "        # project to L2 ball around x_orig\n",
    "        delta = x_adv - x_orig\n",
    "        dnorm = delta.view(-1).norm().item()\n",
    "        if dnorm > EPSILON:\n",
    "            delta = delta * (EPSILON / (dnorm + 1e-12))\n",
    "            x_adv = (x_orig + delta).detach()\n",
    "        x_adv = x_adv.requires_grad_(True)\n",
    "\n",
    "    perturbed_map[int(idx)] = x_adv.detach().clone()\n",
    "\n",
    "print(\"? PGD perturbation finished for selected subgraphs.\")\n",
    "\n",
    "# ---------------------- Evaluate model on full test set (perturbed selected + originals) ----------------------\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_data_list):\n",
    "        x_in = perturbed_map[i] if i in perturbed_map else data.x.to(DEVICE)\n",
    "        edge_index = data.edge_index.to(DEVICE)\n",
    "        batch_zero = torch.zeros(x_in.size(0), dtype=torch.long, device=DEVICE)\n",
    "        out = model(x_in, edge_index, batch_zero)         # [1, C]\n",
    "        pred = int(out.argmax(dim=1).item())\n",
    "        y_pred_list.append(pred)\n",
    "        y_true_list.append(int(data.y.item()))\n",
    "\n",
    "y_true_arr = np.array(y_true_list)\n",
    "y_pred_arr = np.array(y_pred_list)\n",
    "\n",
    "print(\"\\n============= Robustness Evaluation (Full Test Set: perturbed selected + rest original) =============\")\n",
    "acc = (y_true_arr == y_pred_arr).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true_arr, y_pred_arr, average='weighted', zero_division=0)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_true_arr, y_pred_arr, labels=[0,1], target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true_arr, y_pred_arr, labels=[0,1]))\n",
    "\n",
    "# how many selected flipped?\n",
    "orig_preds = []\n",
    "adv_preds = []\n",
    "with torch.no_grad():\n",
    "    for idx in selected_idxs:\n",
    "        data = test_data_list[int(idx)]\n",
    "        edge_index = data.edge_index.to(DEVICE)\n",
    "        batch_zero = torch.zeros(data.x.size(0), dtype=torch.long, device=DEVICE)\n",
    "        # original\n",
    "        out_orig = model(data.x.to(DEVICE), edge_index, batch_zero)\n",
    "        orig_preds.append(int(out_orig.argmax(dim=1).item()))\n",
    "        # adv\n",
    "        out_adv = model(perturbed_map[int(idx)], edge_index, batch_zero)\n",
    "        adv_preds.append(int(out_adv.argmax(dim=1).item()))\n",
    "orig_preds = np.array(orig_preds); adv_preds = np.array(adv_preds)\n",
    "num_flips = int((orig_preds != adv_preds).sum())\n",
    "print(f\"\\nSelected subgraphs: {len(selected_idxs)}. Flipped after attack: {num_flips} ({100.0*num_flips/len(selected_idxs):.2f}%).\")\n",
    "\n",
    "# ---------------------- Jacobian & finite-difference relative error (computed AT the PERTURBED input) ----------------------\n",
    "print(\"\\nComputing Jacobian norms & FD relative error on the PERTURBED selected subgraphs...\")\n",
    "per_sample_info = []   # tuples: (idx, label, jacobian_fro_norm, fd_rel_error)\n",
    "for idx in selected_idxs:\n",
    "    data = test_data_list[int(idx)]\n",
    "    x_adv = perturbed_map[int(idx)].detach().clone().to(DEVICE).requires_grad_(True)  # perturbed input\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    n_nodes, feat_dim = x_adv.shape\n",
    "    batch_zero = torch.zeros(n_nodes, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    # flatten input\n",
    "    x_flat = x_adv.view(-1).detach().clone().requires_grad_(True)\n",
    "\n",
    "    def f_flat(x_flat_input):\n",
    "        x_mat = x_flat_input.view_as(x_adv)\n",
    "        out = model(x_mat, edge_index, batch_zero)   # [1, C]\n",
    "        return out.squeeze(0)                        # (C,)\n",
    "\n",
    "    # Jacobian: shape (C, D) where D = n_nodes * feat_dim\n",
    "    try:\n",
    "        J = torch.autograd.functional.jacobian(f_flat, x_flat)    # (C, D)\n",
    "    except RuntimeError:\n",
    "        # fallback: compute per-output jacobian rows to avoid memory blowup (slower)\n",
    "        C = int(model(x_adv, edge_index, batch_zero).shape[1])\n",
    "        rows = []\n",
    "        for out_i in range(C):\n",
    "            def scalar_f(z, i=out_i):\n",
    "                return f_flat(z)[i]\n",
    "            r = torch.autograd.functional.jacobian(scalar_f, x_flat)\n",
    "            rows.append(r.unsqueeze(0))\n",
    "        J = torch.cat(rows, dim=0)\n",
    "\n",
    "    J = J.detach()\n",
    "    jac_frob = float(torch.norm(J, p='fro').item())\n",
    "\n",
    "    # finite-difference relative error\n",
    "    delta_fd = FD_EPS * torch.randn_like(x_flat).to(DEVICE)\n",
    "    pred_change = J @ delta_fd                          # (C,)\n",
    "    f0 = f_flat(x_flat).detach()\n",
    "    f0p = f_flat(x_flat + delta_fd).detach()\n",
    "    actual_change = f0p - f0\n",
    "    rel_err = float((torch.norm(pred_change - actual_change) / (torch.norm(actual_change) + 1e-8)).item())\n",
    "\n",
    "    per_sample_info.append((int(idx), int(data.y.item()), jac_frob, rel_err))\n",
    "\n",
    "# ---------------------- Aggregate & print summary ----------------------\n",
    "arr = np.array([[i,l,j,r] for (i,l,j,r) in per_sample_info], dtype=object)\n",
    "if arr.size:\n",
    "    clean_vals = arr[arr[:,1]==0][:,2].astype(float) if (arr[:,1]==0).any() else np.array([])\n",
    "    troj_vals  = arr[arr[:,1]==1][:,2].astype(float) if (arr[:,1]==1).any() else np.array([])\n",
    "    clean_errs = arr[arr[:,1]==0][:,3].astype(float) if (arr[:,1]==0).any() else np.array([])\n",
    "    troj_errs  = arr[arr[:,1]==1][:,3].astype(float) if (arr[:,1]==1).any() else np.array([])\n",
    "\n",
    "    def mean_std(a): return (a.mean(), a.std()) if len(a)>0 else (0.0,0.0)\n",
    "\n",
    "    c_mean, c_std = mean_std(clean_vals)\n",
    "    t_mean, t_std = mean_std(troj_vals)\n",
    "    ce_mean, ce_std = mean_std(clean_errs)\n",
    "    te_mean, te_std = mean_std(troj_errs)\n",
    "\n",
    "    print(\"\\nJacobian norms & FD relative errors (aggregated):\")\n",
    "    print(f\" Clean subgraphs:  avg_norm={c_mean:.4f} ± {c_std:.4f}, avg_FDrel={ce_mean:.4e} ± {ce_std:.4e}\")\n",
    "    print(f\" Trojan subgraphs: avg_norm={t_mean:.4f} ± {t_std:.4f}, avg_FDrel={te_mean:.4e} ± {te_std:.4e}\")\n",
    "\n",
    "    print(\"\\nSample preview (first 6): (idx,label,jacobian_frob,FD_rel_err)\")\n",
    "    for t in per_sample_info[:6]:\n",
    "        print(t)\n",
    "else:\n",
    "    print(\"No Jacobian samples computed (selected set empty).\")\n",
    "\n",
    "print(\"\\nDone. (Order: PGD perturbation -> full-test evaluation -> Jacobian computed at perturbed inputs.)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7087063-000b-40cf-a18c-d0914dc4195c",
   "metadata": {},
   "source": [
    "#### Local Lipschitz Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04efee09-a3d9-4711-adc0-0c6aabf08af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected perturbation pool: {0: 11, 1: 20}\n",
      "\n",
      "Running Lipschitz-directed PGD for selected subgraphs (this may take a while)...\n",
      "? Finished perturbations.\n",
      "\n",
      "============= Robustness Evaluation (Full Test Set) =============\n",
      "Accuracy: 96.08%\n",
      "Precision: 0.9651, Recall: 0.9608, F1: 0.9622\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.7692    0.9091    0.8333        11\n",
      "      trojan     0.9888    0.9670    0.9778        91\n",
      "\n",
      "    accuracy                         0.9608       102\n",
      "   macro avg     0.8790    0.9381    0.9056       102\n",
      "weighted avg     0.9651    0.9608    0.9622       102\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  1]\n",
      " [ 3 88]]\n",
      "\n",
      "Selected subgraphs: 31. Flipped after attack: 3 (9.68%).\n",
      "\n",
      "Computing Local Lipschitz constants + FD relative errors (on perturbed subgraphs)...\n",
      "\n",
      "--- Local Lipschitz Constants (on perturbed subgraphs) ---\n",
      " Clean:  avg_L=0.4934 ± 0.2302, avg_FDrel=1.4172e-02 ± 1.3608e-02\n",
      " Trojan: avg_L=1.0035 ± 2.6309, avg_FDrel=7.5908e-01 ± 2.5349e+00\n",
      "\n",
      "Sample preview (first 6): (idx,label,L,FD_rel_err)\n",
      "(14, 0, 0.4797338545322418, 0.005441294517368078)\n",
      "(33, 0, 0.7513017654418945, 0.0013163184048607945)\n",
      "(63, 0, 0.34226641058921814, 0.039065077900886536)\n",
      "(12, 0, 0.18972018361091614, 0.0031769643537700176)\n",
      "(18, 0, 0.9597011208534241, 0.002831539139151573)\n",
      "(36, 0, 0.6635523438453674, 0.004098290577530861)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- Local Lipschitz (Subgraph-Level) -----------------------\n",
    "import torch, numpy as np, torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# ----- parameters (tune if needed) -----\n",
    "PER_CLASS = 20      # up to this many per class from test set (min with available)\n",
    "FD_EPS = 1e-3\n",
    "EPSILON = 5.0       # L2 budget for PGD (feature units)\n",
    "ALPHA = 1.0         # PGD step size\n",
    "NUM_ITERS = 30      # PGD iters\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# ----- quick sanity -----\n",
    "if 'model' not in globals() or 'test_loader' not in globals():\n",
    "    raise RuntimeError(\"Required variables `model` and `test_loader` must exist in the notebook.\")\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# ----- get dataset (robust to DataLoader type) -----\n",
    "dataset = test_loader.dataset\n",
    "n_test = len(dataset)\n",
    "\n",
    "# extract labels array\n",
    "labels_np = np.array([int(d.y.item() if hasattr(d.y, 'item') else d.y[0].item()) for d in dataset])\n",
    "\n",
    "# ----- select indices (PER_CLASS per class) -----\n",
    "rng = np.random.default_rng(SEED)\n",
    "selected = []\n",
    "for cls in [0, 1]:\n",
    "    idxs = np.where(labels_np == cls)[0].tolist()\n",
    "    if len(idxs) == 0:\n",
    "        continue\n",
    "    k = min(PER_CLASS, len(idxs))\n",
    "    chosen = rng.choice(idxs, size=k, replace=False).tolist()\n",
    "    selected.extend(chosen)\n",
    "selected = np.array(selected, dtype=np.int64)\n",
    "print(\"Selected perturbation pool:\", {0:int((labels_np[selected]==0).sum()), 1:int((labels_np[selected]==1).sum())})\n",
    "\n",
    "# ----- perturb each selected subgraph using top-right singular vector init + PGD -----\n",
    "perturbed_map = {}   # idx -> perturbed_x (on DEVICE)\n",
    "orig_preds_list = []\n",
    "adv_preds_list = []\n",
    "\n",
    "print(\"\\nRunning Lipschitz-directed PGD for selected subgraphs (this may take a while)...\")\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x_orig = data.x.detach().clone().to(DEVICE)            # (num_nodes, feat_dim)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    y_true = torch.tensor([int(data.y.item())], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    # helper: produce batch vector of zeros for single graph\n",
    "    def batch_for(x):\n",
    "        return torch.zeros(x.size(0), dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    # define f_local that accepts x (num_nodes,feat) and returns logits (num_classes,)\n",
    "    def f_local(x):\n",
    "        return model(x, edge_index, batch_for(x)).squeeze(0)\n",
    "\n",
    "    # Compute Jacobian at x_orig (shape: (num_classes, num_nodes, feat_dim))\n",
    "    # NOTE: we compute Jacobian once per graph to get singular vector init\n",
    "    try:\n",
    "        J = torch.autograd.functional.jacobian(f_local, x_orig)    # (C, N, F)\n",
    "    except RuntimeError:\n",
    "        # if autograd fails due to graph size, compute per-output jac manually (slower)\n",
    "        logits0 = f_local(x_orig).detach()\n",
    "        C = logits0.shape[0]\n",
    "        rows = []\n",
    "        for c in range(C):\n",
    "            def scalar_f(x, cidx=c):\n",
    "                return f_local(x)[cidx]\n",
    "            row = torch.autograd.functional.jacobian(scalar_f, x_orig)  # (N, F)\n",
    "            rows.append(row.unsqueeze(0))\n",
    "        J = torch.cat(rows, dim=0)  # (C, N, F)\n",
    "\n",
    "    # flatten J to shape (C, d) where d = N * F\n",
    "    C = J.shape[0]\n",
    "    d = int(J.shape[1] * J.shape[2])\n",
    "    J_flat = J.reshape(C, d)\n",
    "\n",
    "    # get top-right singular vector v (length d)\n",
    "    try:\n",
    "        _, S, Vh = torch.linalg.svd(J_flat, full_matrices=False)\n",
    "        v = Vh[0, :].detach().to(DEVICE)   # (d,)\n",
    "    except RuntimeError:\n",
    "        # fallback random direction\n",
    "        v = torch.randn(d, device=DEVICE)\n",
    "    if v.norm().item() > 0:\n",
    "        v = v / (v.norm() + 1e-12)\n",
    "    else:\n",
    "        v = torch.randn_like(v).to(DEVICE); v = v / (v.norm() + 1e-12)\n",
    "\n",
    "    # initialize adversarial x_adv (reshape v -> (N,F))\n",
    "    v_mat = v.view(x_orig.shape[0], x_orig.shape[1])\n",
    "    x_adv = (x_orig + 0.5 * EPSILON * v_mat).detach().clone().requires_grad_(True)\n",
    "\n",
    "    # PGD loop maximize CE loss (untargeted)\n",
    "    for it in range(NUM_ITERS):\n",
    "        logits = model(x_adv, edge_index, batch_for(x_adv))\n",
    "        loss = F.cross_entropy(logits, y_true)\n",
    "        grad = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "        gn = grad.view(-1)\n",
    "        gnorm = gn.norm().item()\n",
    "        if gnorm == 0:\n",
    "            break\n",
    "        step = ALPHA * (grad / (gnorm + 1e-12))\n",
    "        x_adv = (x_adv + step).detach()\n",
    "        # project to L2-ball around x_orig\n",
    "        delta = (x_adv - x_orig).view(-1)\n",
    "        dnorm = delta.norm().item()\n",
    "        if dnorm > EPSILON:\n",
    "            delta = delta * (EPSILON / (dnorm + 1e-12))\n",
    "            x_adv = (x_orig + delta.view_as(x_orig)).detach()\n",
    "        x_adv = x_adv.requires_grad_(True)\n",
    "\n",
    "    # finalize\n",
    "    x_adv_final = x_adv.detach()\n",
    "    perturbed_map[int(idx)] = x_adv_final\n",
    "\n",
    "    # store preds for flip statistics\n",
    "    with torch.no_grad():\n",
    "        p_orig = f_local(x_orig).argmax().item()\n",
    "        p_adv  = f_local(x_adv_final).argmax().item()\n",
    "    orig_preds_list.append(p_orig)\n",
    "    adv_preds_list.append(p_adv)\n",
    "\n",
    "print(\"? Finished perturbations.\")\n",
    "\n",
    "# ----- Evaluate full test set using perturbed subgraphs for selected indices -----\n",
    "print(\"\\n============= Robustness Evaluation (Full Test Set) =============\")\n",
    "preds_all = []\n",
    "labels_all = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dataset):\n",
    "        x = data.x.detach().clone().to(DEVICE)\n",
    "        edge_index = data.edge_index.to(DEVICE)\n",
    "        lab = int(data.y.item())\n",
    "        if int(i) in perturbed_map:\n",
    "            x_eval = perturbed_map[int(i)]\n",
    "        else:\n",
    "            x_eval = x\n",
    "        logits = model(x_eval, edge_index, batch_for(x_eval))\n",
    "        preds_all.append(int(logits.argmax(dim=1).item()))\n",
    "        labels_all.append(lab)\n",
    "\n",
    "preds_all = np.array(preds_all)\n",
    "labels_all = np.array(labels_all)\n",
    "\n",
    "acc = (preds_all == labels_all).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_all, preds_all, average='weighted', zero_division=0)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(labels_all, preds_all, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "\n",
    "# flip statistics\n",
    "num_flips = int((np.array(orig_preds_list) != np.array(adv_preds_list)).sum())\n",
    "print(f\"\\nSelected subgraphs: {len(selected)}. Flipped after attack: {num_flips} ({100.0*num_flips/len(selected):.2f}%).\")\n",
    "\n",
    "# ----- Now compute Local Lipschitz constants and FD relative error ON THE PERTURBED SUBGRAPHS -----\n",
    "print(\"\\nComputing Local Lipschitz constants + FD relative errors (on perturbed subgraphs)...\")\n",
    "per_sample_info = []   # tuples (dataset_idx, label, sigma_max, fd_rel_err)\n",
    "for i, idx in enumerate(selected):\n",
    "    data = dataset[int(idx)]\n",
    "    x_adv = perturbed_map[int(idx)].detach().clone().to(DEVICE).requires_grad_(True)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    label = int(data.y.item())\n",
    "\n",
    "    # define f_local on perturbed input\n",
    "    def f_local_pert(x):\n",
    "        return model(x, edge_index, batch_for(x)).squeeze(0)\n",
    "\n",
    "    # jacobian shape (C, N, F)\n",
    "    try:\n",
    "        J = torch.autograd.functional.jacobian(f_local_pert, x_adv).detach()   # (C, N, F)\n",
    "    except RuntimeError:\n",
    "        # fallback per-output jac (slower)\n",
    "        logits0 = f_local_pert(x_adv).detach()\n",
    "        C = logits0.shape[0]\n",
    "        rows = []\n",
    "        for c in range(C):\n",
    "            def scalar_f(x, cidx=c):\n",
    "                return f_local_pert(x)[cidx]\n",
    "            row = torch.autograd.functional.jacobian(scalar_f, x_adv)\n",
    "            rows.append(row.unsqueeze(0))\n",
    "        J = torch.cat(rows, dim=0)\n",
    "\n",
    "    C = J.shape[0]\n",
    "    d = int(J.shape[1] * J.shape[2])\n",
    "    J_flat = J.reshape(C, d)\n",
    "\n",
    "    # spectral norm via SVD (largest singular value)\n",
    "    try:\n",
    "        _, S, _ = torch.linalg.svd(J_flat, full_matrices=False)\n",
    "        sigma_max = float(S[0].item())\n",
    "    except RuntimeError:\n",
    "        # fallback via eigen on JJT\n",
    "        JJT = (J_flat @ J_flat.T).cpu().numpy()\n",
    "        eigvals = np.linalg.eigvalsh(JJT)\n",
    "        sigma_max = float(np.sqrt(max(eigvals.max(), 0.0)))\n",
    "\n",
    "    # finite-difference relative error\n",
    "    delta_fd = FD_EPS * torch.randn_like(x_adv).to(DEVICE).view(-1)   # length d\n",
    "    pred_change = (J_flat @ delta_fd)                 # (C,)\n",
    "    f0 = f_local_pert(x_adv).detach()\n",
    "    f0p = f_local_pert((x_adv + delta_fd.view_as(x_adv))).detach()\n",
    "    actual_change = f0p - f0\n",
    "    fd_rel_err = (torch.norm(pred_change - actual_change) / (torch.norm(actual_change) + 1e-8)).item()\n",
    "\n",
    "    per_sample_info.append((int(idx), label, float(sigma_max), float(fd_rel_err)))\n",
    "\n",
    "# aggregate and print\n",
    "clean_stats = [p for p in per_sample_info if p[1] == 0]\n",
    "troj_stats  = [p for p in per_sample_info if p[1] == 1]\n",
    "\n",
    "def aggs(stats):\n",
    "    if not stats:\n",
    "        return (0.0, 0.0, 0.0, 0.0)\n",
    "    Ls = np.array([s[2] for s in stats])\n",
    "    Es = np.array([s[3] for s in stats])\n",
    "    return (Ls.mean(), Ls.std(), Es.mean(), Es.std())\n",
    "\n",
    "cL_mean, cL_std, cE_mean, cE_std = aggs(clean_stats)\n",
    "tL_mean, tL_std, tE_mean, tE_std = aggs(troj_stats)\n",
    "\n",
    "print(\"\\n--- Local Lipschitz Constants (on perturbed subgraphs) ---\")\n",
    "print(f\" Clean:  avg_L={cL_mean:.4f} ± {cL_std:.4f}, avg_FDrel={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_L={tL_mean:.4f} ± {tL_std:.4f}, avg_FDrel={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "\n",
    "print(\"\\nSample preview (first 6): (idx,label,L,FD_rel_err)\")\n",
    "for p in per_sample_info[:6]:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9afa21a-41a6-4a09-8013-5d6ca81afa37",
   "metadata": {},
   "source": [
    "#### Hessian-based Curvature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea548c07-f25d-43c9-b2fb-7b8a216ab4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected pool: clean=11, trojan=20\n",
      "\n",
      "Computing Hessian curvature proxies on selected subgraphs...\n",
      "\n",
      "Constructing Hessian-aligned perturbations...\n",
      "\n",
      "================ Robustness Evaluation (Full Test Set: perturbed+clean) ===============\n",
      "Accuracy: 93.14%\n",
      "Precision: 0.9289, Recall: 0.9314, F1: 0.9299\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.7000    0.6364    0.6667        11\n",
      "      trojan     0.9565    0.9670    0.9617        91\n",
      "\n",
      "    accuracy                         0.9314       102\n",
      "   macro avg     0.8283    0.8017    0.8142       102\n",
      "weighted avg     0.9289    0.9314    0.9299       102\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  4]\n",
      " [ 3 88]]\n",
      "\n",
      "Selected subgraphs: 31. Flipped after perturbation: 6 (19.35%).\n",
      "\n",
      "--- Hessian Curvature Stats (grad outer-product proxy) ---\n",
      " Clean:  avg_lambda=0.0001 ± 0.0003, avg_FDrel=9.4980e-01 ± 3.6951e-02\n",
      " Trojan: avg_lambda=0.0001 ± 0.0003, avg_FDrel=5.0204e-01 ± 4.5488e-01\n",
      "\n",
      "Sample preview (first 6): (idx,label,lambda,FD_rel_err)\n",
      "(14, 0, 3.5693579686088897e-06, 0.9636353130872353)\n",
      "(33, 0, 1.0263525662213891e-06, 0.939115960334291)\n",
      "(63, 0, 1.4761330133378008e-05, 0.9360671887854106)\n",
      "(12, 0, 3.841061847433136e-08, 0.9755780132860312)\n",
      "(18, 0, 0.0009466093951016365, 1.001560334008069)\n",
      "(36, 0, 6.211273803136792e-06, 0.9296848185655465)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- Hessian-Based Curvature (Subgraph-Level) -----------------------\n",
    "import torch, numpy as np, torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# ----- parameters -----\n",
    "PER_CLASS = 20        # subgraphs per class\n",
    "FD_EPS = 5e-3         # finite diff epsilon\n",
    "TRIALS_PER_GRAPH = 5  # #trials for FD error\n",
    "PERT_P = 10.0          # L2 magnitude for Hessian-aligned perturbation\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "if 'model' not in globals() or 'test_loader' not in globals():\n",
    "    raise RuntimeError(\"Need `model` and `test_loader` in environment.\")\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "dataset = test_loader.dataset\n",
    "n_test = len(dataset)\n",
    "labels_np = np.array([int(d.y.item()) for d in dataset])\n",
    "\n",
    "# ----- select PER_CLASS subgraphs per class -----\n",
    "rng = np.random.default_rng(SEED)\n",
    "selected = []\n",
    "for cls in [0, 1]:\n",
    "    idxs = np.where(labels_np == cls)[0].tolist()\n",
    "    k = min(PER_CLASS, len(idxs))\n",
    "    chosen = rng.choice(idxs, size=k, replace=False).tolist()\n",
    "    selected.extend(chosen)\n",
    "selected = np.array(selected, dtype=np.int64)\n",
    "print(f\"Selected pool: clean={int((labels_np[selected]==0).sum())}, trojan={int((labels_np[selected]==1).sum())}\")\n",
    "\n",
    "# ----- base predictions -----\n",
    "def batch_for(x): return torch.zeros(x.size(0), dtype=torch.long, device=DEVICE)\n",
    "with torch.no_grad():\n",
    "    base_preds = []\n",
    "    for data in dataset:\n",
    "        logits = model(data.x.to(DEVICE), data.edge_index.to(DEVICE), batch_for(data.x.to(DEVICE)))\n",
    "        base_preds.append(int(logits.argmax()))\n",
    "base_preds = np.array(base_preds)\n",
    "\n",
    "# ----- compute gradient norms + FD relative errors -----\n",
    "per_sample_info = []  # (idx, label, lambda_max, avg_rel_err)\n",
    "\n",
    "print(\"\\nComputing Hessian curvature proxies on selected subgraphs...\")\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x0 = data.x.detach().clone().to(DEVICE).requires_grad_(True)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "\n",
    "    # predicted class at x0\n",
    "    with torch.no_grad():\n",
    "        logits = model(x0, edge_index, batch_for(x0))\n",
    "    pred_class = int(logits.argmax().item())\n",
    "\n",
    "    def h(x):\n",
    "        return F.log_softmax(model(x, edge_index, batch_for(x)).squeeze(0), dim=0)[pred_class]\n",
    "\n",
    "    h0 = h(x0)\n",
    "    g = torch.autograd.grad(h0, x0, retain_graph=False, create_graph=False)[0].detach()\n",
    "\n",
    "    lambda_max = float(g.norm(p=2).item() ** 2)\n",
    "\n",
    "    # FD relative error\n",
    "    errs = []\n",
    "    for _ in range(TRIALS_PER_GRAPH):\n",
    "        delta = FD_EPS * torch.randn_like(x0).to(DEVICE)\n",
    "        gt_delta = float((g * delta).sum().item())\n",
    "        pred_second = 0.5 * (gt_delta ** 2)\n",
    "        actual_second = float((h(x0 + delta) - h0 - (g * delta).sum()).item())\n",
    "        rel_err = abs(pred_second - actual_second) / (abs(actual_second) + 1e-8)\n",
    "        errs.append(rel_err)\n",
    "    avg_rel_err = float(np.mean(errs))\n",
    "\n",
    "    per_sample_info.append((int(idx), int(data.y.item()), lambda_max, avg_rel_err))\n",
    "\n",
    "# ----- build Hessian-aligned perturbations -----\n",
    "print(\"\\nConstructing Hessian-aligned perturbations...\")\n",
    "perturbed_map = {}\n",
    "for (idx, label, lambda_val, avg_rel_err) in per_sample_info:\n",
    "    data = dataset[int(idx)]\n",
    "    x0 = data.x.detach().clone().to(DEVICE).requires_grad_(True)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "\n",
    "    def h(x):\n",
    "        return F.log_softmax(model(x, edge_index, batch_for(x)).squeeze(0), dim=0)[int(data.y.item())]\n",
    "\n",
    "    g = torch.autograd.grad(h(x0), x0, retain_graph=False, create_graph=False)[0].detach()\n",
    "    gnorm = g.norm().item()\n",
    "    if gnorm < 1e-12:\n",
    "        dir_vec = torch.randn_like(x0).to(DEVICE)\n",
    "    else:\n",
    "        dir_vec = - g / (gnorm + 1e-12)\n",
    "\n",
    "    delta = (PERT_P * dir_vec).detach()\n",
    "    perturbed_map[int(idx)] = (x0 + delta).detach()\n",
    "\n",
    "# ----- evaluate on full test set -----\n",
    "print(\"\\n================ Robustness Evaluation (Full Test Set: perturbed+clean) ===============\")\n",
    "preds_all, labels_all = [], []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dataset):\n",
    "        x = data.x.to(DEVICE)\n",
    "        if int(i) in perturbed_map:\n",
    "            x_eval = perturbed_map[int(i)]\n",
    "        else:\n",
    "            x_eval = x\n",
    "        logits = model(x_eval, data.edge_index.to(DEVICE), batch_for(x_eval))\n",
    "        preds_all.append(int(logits.argmax()))\n",
    "        labels_all.append(int(data.y.item()))\n",
    "\n",
    "preds_all = np.array(preds_all)\n",
    "labels_all = np.array(labels_all)\n",
    "\n",
    "acc = (preds_all == labels_all).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_all, preds_all, average='weighted', zero_division=0)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(labels_all, preds_all, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "\n",
    "# ----- flip stats -----\n",
    "orig_sel_preds = base_preds[selected]\n",
    "adv_sel_preds = np.array([preds_all[i] for i in selected])\n",
    "num_flips = int((orig_sel_preds != adv_sel_preds).sum())\n",
    "print(f\"\\nSelected subgraphs: {len(selected)}. Flipped after perturbation: {num_flips} ({100.0*num_flips/len(selected):.2f}%).\")\n",
    "\n",
    "# ----- aggregate curvature stats -----\n",
    "clean_stats = [p for p in per_sample_info if p[1] == 0]\n",
    "troj_stats  = [p for p in per_sample_info if p[1] == 1]\n",
    "\n",
    "def summarize(stats):\n",
    "    if not stats: return (0.0,0.0,0.0,0.0)\n",
    "    Ls = np.array([s[2] for s in stats])\n",
    "    Es = np.array([s[3] for s in stats])\n",
    "    return (Ls.mean(), Ls.std(), Es.mean(), Es.std())\n",
    "\n",
    "cL_mean, cL_std, cE_mean, cE_std = summarize(clean_stats)\n",
    "tL_mean, tL_std, tE_mean, tE_std = summarize(troj_stats)\n",
    "\n",
    "print(\"\\n--- Hessian Curvature Stats (grad outer-product proxy) ---\")\n",
    "print(f\" Clean:  avg_lambda={cL_mean:.4f} ± {cL_std:.4f}, avg_FDrel={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_lambda={tL_mean:.4f} ± {tL_std:.4f}, avg_FDrel={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "\n",
    "print(\"\\nSample preview (first 6): (idx,label,lambda,FD_rel_err)\")\n",
    "for p in per_sample_info[:6]:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc7cd75-26a8-4c6f-a206-0ba4c88cf505",
   "metadata": {},
   "source": [
    "#### Prediction Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c0ca400-e1dc-455c-be9a-4a0a56fb5f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected pool: clean=11, trojan=20\n",
      "\n",
      "Running PGD perturbations on selected subgraphs...\n",
      "? Finished perturbations.\n",
      "\n",
      "================ Robustness Evaluation (Full Test Set: perturbed+clean) ===============\n",
      "Accuracy: 96.08%\n",
      "Precision: 0.9651, Recall: 0.9608, F1: 0.9622\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.7692    0.9091    0.8333        11\n",
      "      trojan     0.9888    0.9670    0.9778        91\n",
      "\n",
      "    accuracy                         0.9608       102\n",
      "   macro avg     0.8790    0.9381    0.9056       102\n",
      "weighted avg     0.9651    0.9608    0.9622       102\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  1]\n",
      " [ 3 88]]\n",
      "\n",
      "Selected subgraphs: 31. Flipped after perturbation: 3 (9.68%).\n",
      "\n",
      "--- Prediction Margin Stats (on perturbed subgraphs) ---\n",
      " Clean:  avg_margin=2.8802 ± 0.9243, avg_FDrel=2.6496e-04 ± 4.0346e-04\n",
      " Trojan: avg_margin=88.2754 ± 267.9658, avg_FDrel=6.3873e-05 ± 8.6440e-05\n",
      "\n",
      "Sample preview (first 6): (idx,label,margin,FD_rel_err)\n",
      "(14, 0, 3.277017593383789, 0.00011118161021237533)\n",
      "(33, 0, 3.455471992492676, 8.099638524306989e-05)\n",
      "(63, 0, 2.385219097137451, 9.291836594227597e-05)\n",
      "(12, 0, 4.832814931869507, 3.1079865486335743e-06)\n",
      "(18, 0, 1.8277963995933533, 0.0008943469939265855)\n",
      "(36, 0, 1.3633912205696106, 0.0013017762824476388)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- Prediction Margin (Subgraph-Level) -----------------------\n",
    "import torch, numpy as np, torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# ----- parameters -----\n",
    "PER_CLASS = 20        # subgraphs per class\n",
    "EPSILON = 5.0         # perturbation budget (strong)\n",
    "ALPHA = 0.4           # PGD step size\n",
    "NUM_ITERS = 15        # PGD iterations\n",
    "FD_EPS = 1e-3         # finite-difference perturbation\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "if 'model' not in globals() or 'test_loader' not in globals():\n",
    "    raise RuntimeError(\"Need `model` and `test_loader` in environment.\")\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "dataset = test_loader.dataset\n",
    "n_test = len(dataset)\n",
    "labels_np = np.array([int(d.y.item()) for d in dataset])\n",
    "\n",
    "# ----- select PER_CLASS subgraphs per class -----\n",
    "rng = np.random.default_rng(SEED)\n",
    "selected = []\n",
    "for cls in [0, 1]:\n",
    "    idxs = np.where(labels_np == cls)[0].tolist()\n",
    "    k = min(PER_CLASS, len(idxs))\n",
    "    chosen = rng.choice(idxs, size=k, replace=False).tolist()\n",
    "    selected.extend(chosen)\n",
    "selected = np.array(selected, dtype=np.int64)\n",
    "print(f\"Selected pool: clean={int((labels_np[selected]==0).sum())}, trojan={int((labels_np[selected]==1).sum())}\")\n",
    "\n",
    "# helper for batching\n",
    "def batch_for(x): \n",
    "    return torch.zeros(x.size(0), dtype=torch.long, device=DEVICE)\n",
    "\n",
    "# ----- base predictions -----\n",
    "with torch.no_grad():\n",
    "    base_preds = []\n",
    "    for data in dataset:\n",
    "        logits = model(data.x.to(DEVICE), data.edge_index.to(DEVICE), batch_for(data.x.to(DEVICE)))\n",
    "        base_preds.append(int(logits.argmax()))\n",
    "base_preds = np.array(base_preds)\n",
    "\n",
    "# ----- adversarial perturbations (PGD) -----\n",
    "perturbed_map = {}\n",
    "\n",
    "print(\"\\nRunning PGD perturbations on selected subgraphs...\")\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x_orig = data.x.detach().clone().to(DEVICE)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    y_scalar = int(data.y.item())\n",
    "    target = torch.tensor([y_scalar], dtype=torch.long, device=DEVICE)  # shape (1,)\n",
    "\n",
    "    # random init inside epsilon-ball\n",
    "    delta = torch.randn_like(x_orig).to(DEVICE)\n",
    "    delta = EPSILON * delta / (delta.norm() + 1e-12)\n",
    "    x_adv = (x_orig + delta).detach().clone().requires_grad_(True)\n",
    "\n",
    "    for it in range(NUM_ITERS):\n",
    "        logits = model(x_adv, edge_index, batch_for(x_adv))  # shape (1, C)\n",
    "        loss = F.cross_entropy(logits, target)               # target shape (1,)\n",
    "        grad = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "\n",
    "        step = ALPHA * grad / (grad.norm() + 1e-12)\n",
    "        x_adv = (x_adv + step).detach()\n",
    "        delta = x_adv - x_orig\n",
    "        if delta.norm() > EPSILON:\n",
    "            delta = delta * (EPSILON / (delta.norm() + 1e-12))\n",
    "            x_adv = (x_orig + delta).detach()\n",
    "        x_adv = x_adv.requires_grad_(True)\n",
    "\n",
    "    perturbed_map[int(idx)] = x_adv.detach()\n",
    "\n",
    "print(\"? Finished perturbations.\")\n",
    "\n",
    "# ----- evaluate on full test set (perturbed + clean) -----\n",
    "print(\"\\n================ Robustness Evaluation (Full Test Set: perturbed+clean) ===============\")\n",
    "preds_all, labels_all = [], []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(dataset):\n",
    "        x = data.x.to(DEVICE)\n",
    "        if int(i) in perturbed_map:\n",
    "            x_eval = perturbed_map[int(i)]\n",
    "        else:\n",
    "            x_eval = x\n",
    "        logits = model(x_eval, data.edge_index.to(DEVICE), batch_for(x_eval))\n",
    "        preds_all.append(int(logits.argmax()))\n",
    "        labels_all.append(int(data.y.item()))\n",
    "\n",
    "preds_all = np.array(preds_all)\n",
    "labels_all = np.array(labels_all)\n",
    "\n",
    "acc = (preds_all == labels_all).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_all, preds_all, average='weighted', zero_division=0)\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(labels_all, preds_all, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "\n",
    "# ----- flip stats -----\n",
    "orig_sel_preds = base_preds[selected]\n",
    "adv_sel_preds = np.array([preds_all[i] for i in selected])\n",
    "num_flips = int((orig_sel_preds != adv_sel_preds).sum())\n",
    "print(f\"\\nSelected subgraphs: {len(selected)}. Flipped after perturbation: {num_flips} ({100.0*num_flips/len(selected):.2f}%).\")\n",
    "\n",
    "# ----- compute prediction margin + FD relative error -----\n",
    "per_sample_info = []  # (idx, label, margin, FD_rel_err)\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x_eval = perturbed_map[int(idx)]\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x_eval, edge_index, batch_for(x_eval)).squeeze(0)\n",
    "    pred_class = int(logits.argmax().item())\n",
    "    pred_logit = logits[pred_class].item()\n",
    "    other_logits = logits.clone()\n",
    "    other_logits[pred_class] = -float('inf')\n",
    "    second_max = other_logits.max().item()\n",
    "    margin = pred_logit - second_max\n",
    "\n",
    "    # finite difference check\n",
    "    delta = FD_EPS * torch.randn_like(x_eval).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits_p = model(x_eval + delta, edge_index, batch_for(x_eval)).squeeze(0)\n",
    "    pred_logit_p = logits_p[pred_class].item()\n",
    "    other_logits_p = logits_p.clone()\n",
    "    other_logits_p[pred_class] = -float('inf')\n",
    "    second_max_p = other_logits_p.max().item()\n",
    "    margin_p = pred_logit_p - second_max_p\n",
    "\n",
    "    rel_err = abs(margin - margin_p) / (abs(margin_p) + 1e-12)\n",
    "    per_sample_info.append((int(idx), int(data.y.item()), float(margin), float(rel_err)))\n",
    "\n",
    "# ----- aggregate stats -----\n",
    "clean_stats = [p for p in per_sample_info if p[1] == 0]\n",
    "troj_stats  = [p for p in per_sample_info if p[1] == 1]\n",
    "\n",
    "def summarize(stats):\n",
    "    if not stats: return (0.0,0.0,0.0,0.0)\n",
    "    Ms = np.array([s[2] for s in stats])\n",
    "    Es = np.array([s[3] for s in stats])\n",
    "    return (Ms.mean(), Ms.std(), Es.mean(), Es.std())\n",
    "\n",
    "cM_mean, cM_std, cE_mean, cE_std = summarize(clean_stats)\n",
    "tM_mean, tM_std, tE_mean, tE_std = summarize(troj_stats)\n",
    "\n",
    "print(\"\\n--- Prediction Margin Stats (on perturbed subgraphs) ---\")\n",
    "print(f\" Clean:  avg_margin={cM_mean:.4f} ± {cM_std:.4f}, avg_FDrel={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_margin={tM_mean:.4f} ± {tM_std:.4f}, avg_FDrel={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "\n",
    "print(\"\\nSample preview (first 6): (idx,label,margin,FD_rel_err)\")\n",
    "for p in per_sample_info[:6]:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18752b3f-6403-4881-8d1e-adf2d3e03f33",
   "metadata": {},
   "source": [
    "#### Adversarial Robustness Radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6561ddc0-ac9e-4751-bed6-4b7c65cdb85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing Adversarial Robustness Radius (ARR) for selected perturbed subgraphs...\n",
      "  processed 20/31 subgraphs...\n",
      "? Done ARR computation. Time elapsed: 23.6s\n",
      "\n",
      "--- Adversarial Robustness Radius (ARR) Stats ---\n",
      "Class      Avg Radius ± Std   Avg Rel. Error ± Std\n",
      "----------------------------------------------------\n",
      "clean      20.0000 ± 0.0000      0.0000e+00 ± 0.0000e+00\n",
      "trojan     20.0000 ± 0.0000      0.0000e+00 ± 0.0000e+00\n",
      "\n",
      "Overall ARR: Avg Radius: 20.0000 ± 0.0000\n",
      "Overall ARR: Avg Relative Error: 0.0000e+00 ± 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- Adversarial Robustness Radius (Subgraph-Level) -----------------------\n",
    "import time\n",
    "\n",
    "# ----- helpers -----\n",
    "def f_for_subgraph(x_tensor, data):\n",
    "    \"\"\"Return logits for given subgraph with node features replaced by x_tensor.\"\"\"\n",
    "    x_tensor = x_tensor.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        out = model(x_tensor, data.edge_index.to(DEVICE), batch_for(x_tensor))\n",
    "    return out.squeeze(0)\n",
    "\n",
    "def adversarial_radius_for_subgraph(data, x0, initial_epsilon=1e-3, growth_factor=1.25,\n",
    "                                    max_epsilon=20.0, bs_iters=10, num_trials=6):\n",
    "    \"\"\"Estimate minimal perturbation radius that flips prediction (around perturbed point).\"\"\"\n",
    "    with torch.no_grad():\n",
    "        base_out = model(x0, data.edge_index.to(DEVICE), batch_for(x0))\n",
    "        y0 = int(base_out.argmax().item())\n",
    "\n",
    "    def is_same(x):\n",
    "        out = f_for_subgraph(x, data)\n",
    "        return int(out.argmax().item()) == y0\n",
    "\n",
    "    radii = []\n",
    "    for _ in range(num_trials):\n",
    "        d = torch.randn_like(x0)\n",
    "        d = d / (d.norm() + 1e-12)\n",
    "\n",
    "        eps = initial_epsilon\n",
    "        while eps < max_epsilon and is_same(x0 + eps * d):\n",
    "            eps *= growth_factor\n",
    "\n",
    "        if eps >= max_epsilon:\n",
    "            candidate = max_epsilon\n",
    "        else:\n",
    "            low, high = eps / growth_factor, eps\n",
    "            for _ in range(bs_iters):\n",
    "                mid = 0.5 * (low + high)\n",
    "                if is_same(x0 + mid * d):\n",
    "                    low = mid\n",
    "                else:\n",
    "                    high = mid\n",
    "            candidate = float(high)\n",
    "        radii.append(candidate)\n",
    "    return float(min(radii))\n",
    "\n",
    "def adversarial_radius_relerr(data, x0):\n",
    "    r1 = adversarial_radius_for_subgraph(data, x0, growth_factor=2.25, bs_iters=10, num_trials=6)\n",
    "    r2 = adversarial_radius_for_subgraph(data, x0, growth_factor=1.4, bs_iters=12, num_trials=6)\n",
    "    rel_err = abs(r1 - r2) / (abs(r2) + 1e-12)\n",
    "    return r1, rel_err\n",
    "\n",
    "# ----- ARR computation on selected perturbed subgraphs -----\n",
    "class_names = ['clean', 'trojan']\n",
    "class_adv_radius = {cn: [] for cn in class_names}\n",
    "class_rel_errors = {cn: [] for cn in class_names}\n",
    "all_radii, all_rel_errs = [], []\n",
    "\n",
    "t0 = time.time()\n",
    "print(\"\\nComputing Adversarial Robustness Radius (ARR) for selected perturbed subgraphs...\")\n",
    "for i, idx in enumerate(selected):\n",
    "    idx = int(idx)\n",
    "    data = dataset[idx]\n",
    "    label = int(data.y.item())\n",
    "    cn = class_names[label]\n",
    "\n",
    "    x0 = perturbed_map[idx].clone().detach().to(DEVICE)  # start from perturbed features\n",
    "    r, rel = adversarial_radius_relerr(data, x0)\n",
    "\n",
    "    class_adv_radius[cn].append(r)\n",
    "    class_rel_errors[cn].append(rel)\n",
    "    all_radii.append(r)\n",
    "    all_rel_errs.append(rel)\n",
    "\n",
    "    if (i+1) % 20 == 0:\n",
    "        print(f\"  processed {i+1}/{len(selected)} subgraphs...\")\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"? Done ARR computation. Time elapsed: {t1-t0:.1f}s\")\n",
    "\n",
    "# ----- Reporting ARR aggregates -----\n",
    "print(\"\\n--- Adversarial Robustness Radius (ARR) Stats ---\")\n",
    "print(\"{:<10s} {:>14s} {:>22s}\".format(\"Class\", \"Avg Radius ± Std\", \"Avg Rel. Error ± Std\"))\n",
    "print(\"-\"*52)\n",
    "for cn in class_names:\n",
    "    if class_adv_radius[cn]:\n",
    "        print(\"{:<10s} {:>7.4f} ± {:<7.4f} {:>14.4e} ± {:<10.4e}\".format(\n",
    "            cn, np.mean(class_adv_radius[cn]), np.std(class_adv_radius[cn]),\n",
    "            np.mean(class_rel_errors[cn]), np.std(class_rel_errors[cn])\n",
    "        ))\n",
    "    else:\n",
    "        print(\"{:<10s} {:>10s}\".format(cn, \"-\"))\n",
    "\n",
    "print(\"\\nOverall ARR: Avg Radius: {:.4f} ± {:.4f}\".format(np.mean(all_radii), np.std(all_radii)))\n",
    "print(\"Overall ARR: Avg Relative Error: {:.4e} ± {:.4e}\".format(np.mean(all_rel_errs), np.std(all_rel_errs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b64808f7-be8e-4001-be6d-6fcc06b888fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Robustness Evaluation (Full Test Set: perturbed selected subgraphs + others unperturbed) =============\n",
      "Accuracy: 96.08%\n",
      "Precision: 0.9651, Recall: 0.9608, F1: 0.9622\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.7692    0.9091    0.8333        11\n",
      "      trojan     0.9888    0.9670    0.9778        91\n",
      "\n",
      "    accuracy                         0.9608       102\n",
      "   macro avg     0.8790    0.9381    0.9056       102\n",
      "weighted avg     0.9651    0.9608    0.9622       102\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  1]\n",
      " [ 3 88]]\n",
      "\n",
      "Selected subgraphs: 31. Flipped after perturbation: 3 (9.68%).\n"
     ]
    }
   ],
   "source": [
    "# ------------------ Evaluate model on full test set (200 perturbed + rest unperturbed) ------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    for i, data in enumerate(dataset):\n",
    "        x_in = perturbed_map[i].to(DEVICE) if i in perturbed_map else data.x.to(DEVICE)\n",
    "        logits = model(x_in, data.edge_index.to(DEVICE), batch_for(x_in))\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_labels.append(int(data.y.item()))\n",
    "\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    preds_all = all_logits.argmax(dim=1).numpy()\n",
    "    labels_all = np.array(all_labels)\n",
    "\n",
    "acc = (preds_all == labels_all).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_all, preds_all, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n============= Robustness Evaluation (Full Test Set: perturbed selected subgraphs + others unperturbed) =============\")\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(labels_all, preds_all, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "\n",
    "# ------------------ Flip statistics for selected subgraphs ------------------\n",
    "with torch.no_grad():\n",
    "    orig_preds = []\n",
    "    for data in dataset:\n",
    "        x_in = data.x.to(DEVICE)\n",
    "        logits = model(x_in, data.edge_index.to(DEVICE), batch_for(x_in))\n",
    "        orig_preds.append(logits.cpu())\n",
    "    orig_preds = torch.cat(orig_preds, dim=0).argmax(dim=1).numpy()\n",
    "\n",
    "adv_sel_preds = preds_all[selected]\n",
    "num_flips = int((orig_preds[selected] != adv_sel_preds).sum())\n",
    "print(f\"\\nSelected subgraphs: {len(selected)}. Flipped after perturbation: {num_flips} ({100.0 * num_flips/len(selected):.2f}%).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898d06a3-8f20-42de-9ae8-2cdbb6cd60ca",
   "metadata": {},
   "source": [
    "#### Stability Under Input Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b6abf18-a02e-4155-a9a1-27db8381fab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Stability Under Input Noise (PGD-first, then metric) ---\n",
      "Selected subgraphs: clean=11, trojan=20\n",
      "\n",
      "============= Robustness Evaluation (Full Test Set: perturbed selected + others unperturbed) =============\n",
      "Accuracy: 96.08%\n",
      "Precision: 0.9651, Recall: 0.9608, F1: 0.9622\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.7692    0.9091    0.8333        11\n",
      "      trojan     0.9888    0.9670    0.9778        91\n",
      "\n",
      "    accuracy                         0.9608       102\n",
      "   macro avg     0.8790    0.9381    0.9056       102\n",
      "weighted avg     0.9651    0.9608    0.9622       102\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  1]\n",
      " [ 3 88]]\n",
      "\n",
      "Selected subgraphs: 31. Flipped after perturbation: 3 (9.68%).\n",
      "\n",
      "Computing Stability Under Input Noise (this may take a while)...\n",
      "  processed 10/31 subgraphs...\n",
      "  processed 20/31 subgraphs...\n",
      "  processed 30/31 subgraphs...\n",
      "Done SUIN computation. Time elapsed: 17.2s\n",
      "\n",
      "--- Stability Under Input Noise (on perturbed subgraphs) ---\n",
      " Clean:  avg_stability=4.4768 ± 1.8360, avg_relerr=2.5896e-02 ± 1.7661e-02\n",
      " Trojan: avg_stability=5.4528 ± 4.0126, avg_relerr=3.6409e-02 ± 6.5924e-02\n",
      "\n",
      "Sample preview (first 6): (idx, label, stability, rel_err)\n",
      "(14, 0, 4.613297688961029, 0.017762431029235415)\n",
      "(33, 0, 1.6698134571313858, 0.00504185254342345)\n",
      "(63, 0, 5.987209582328797, 0.006015780281168827)\n",
      "(12, 0, 7.554403066635132, 0.004729043223996363)\n",
      "(18, 0, 6.4326952457427975, 0.006646189204557296)\n",
      "(36, 0, 3.977954363822937, 0.04340885478066942)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Stability Under Input Noise (SUIN) - Subgraph classification\n",
    "# ============================================================\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import time\n",
    "\n",
    "# --- Parameters ---\n",
    "NOISE_SIGMA        = 0.5   # Gaussian noise stddev for stability metric\n",
    "NUM_NOISE_SAMPLES  = 20     # Monte Carlo samples per subgraph\n",
    "RELERR_RESAMPLES   = 5      # repeats to estimate relative error\n",
    "\n",
    "print(\"\\n--- Stability Under Input Noise (PGD-first, then metric) ---\")\n",
    "print(f\"Selected subgraphs: clean={(labels_np[selected]==0).sum()}, trojan={(labels_np[selected]==1).sum()}\")\n",
    "\n",
    "# ============================================================\n",
    "# Step 1: Evaluate model on full dataset (perturbed + original)\n",
    "# ============================================================\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    all_logits, all_labels = [], []\n",
    "    for i, data in enumerate(dataset):\n",
    "        x_in = perturbed_map[i].to(DEVICE) if i in perturbed_map else data.x.to(DEVICE)\n",
    "        logits = model(x_in, data.edge_index.to(DEVICE), batch_for(x_in))\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_labels.append(int(data.y.item()))\n",
    "\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    preds_all  = all_logits.argmax(dim=1).numpy()\n",
    "    labels_all = np.array(all_labels)\n",
    "\n",
    "acc = (preds_all == labels_all).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_all, preds_all, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"\\n============= Robustness Evaluation (Full Test Set: perturbed selected + others unperturbed) =============\")\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\\n\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(labels_all, preds_all, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels_all, preds_all, labels=[0,1]))\n",
    "\n",
    "# Flip statistics for selected subgraphs\n",
    "with torch.no_grad():\n",
    "    orig_preds = []\n",
    "    for data in dataset:\n",
    "        x_in = data.x.to(DEVICE)\n",
    "        logits = model(x_in, data.edge_index.to(DEVICE), batch_for(x_in))\n",
    "        orig_preds.append(logits.cpu())\n",
    "    orig_preds = torch.cat(orig_preds, dim=0).argmax(dim=1).numpy()\n",
    "\n",
    "adv_sel_preds = preds_all[selected]\n",
    "num_flips = int((orig_preds[selected] != adv_sel_preds).sum())\n",
    "print(f\"\\nSelected subgraphs: {len(selected)}. Flipped after perturbation: {num_flips} ({100.0*num_flips/len(selected):.2f}%).\")\n",
    "\n",
    "# ============================================================\n",
    "# Step 2: Stability Under Input Noise (on perturbed subgraphs)\n",
    "# ============================================================\n",
    "def stability_for_subgraph(idx, sigma, num_samples):\n",
    "    \"\"\"Compute avg L2 change in logits for noisy perturbations around perturbed subgraph.\"\"\"\n",
    "    data = dataset[idx]\n",
    "    base_x = perturbed_map[idx].to(DEVICE)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    batch = batch_for(base_x)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        f_orig = model(base_x, edge_index, batch).squeeze()\n",
    "\n",
    "    diffs = []\n",
    "    for _ in range(num_samples):\n",
    "        noise = sigma * torch.randn_like(base_x).to(DEVICE)\n",
    "        f_noisy = model(base_x + noise, edge_index, batch).squeeze()\n",
    "        diffs.append(torch.norm(f_noisy - f_orig).item())\n",
    "    return float(np.mean(diffs))\n",
    "\n",
    "print(\"\\nComputing Stability Under Input Noise (this may take a while)...\")\n",
    "t0 = time.time()\n",
    "per_sample_info = []  # (idx, label, stability, rel_err)\n",
    "for i, idx in enumerate(selected):\n",
    "    s_val = stability_for_subgraph(idx, NOISE_SIGMA, NUM_NOISE_SAMPLES)\n",
    "    re_vals = [stability_for_subgraph(idx, NOISE_SIGMA, NUM_NOISE_SAMPLES) for _ in range(RELERR_RESAMPLES)]\n",
    "    s_ref = float(np.mean(re_vals))\n",
    "    rel_err = abs(s_val - s_ref) / (abs(s_ref) + 1e-12)\n",
    "    per_sample_info.append((int(idx), int(labels_np[idx]), s_val, rel_err))\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\"  processed {i+1}/{len(selected)} subgraphs...\")\n",
    "t1 = time.time()\n",
    "print(f\"Done SUIN computation. Time elapsed: {t1-t0:.1f}s\")\n",
    "\n",
    "# ============================================================\n",
    "# Step 3: Aggregate and report\n",
    "# ============================================================\n",
    "clean_stats = [(i, s, e) for (i, l, s, e) in per_sample_info if l == 0]\n",
    "troj_stats  = [(i, s, e) for (i, l, s, e) in per_sample_info if l == 1]\n",
    "\n",
    "def aggs(stats):\n",
    "    if not stats:\n",
    "        return (0.0, 0.0, 0.0, 0.0)\n",
    "    Ss = np.array([s for (_, s, _) in stats])\n",
    "    Es = np.array([e for (_, _, e) in stats])\n",
    "    return (Ss.mean(), Ss.std(), Es.mean(), Es.std())\n",
    "\n",
    "cS_mean, cS_std, cE_mean, cE_std = aggs(clean_stats)\n",
    "tS_mean, tS_std, tE_mean, tE_std = aggs(troj_stats)\n",
    "\n",
    "print(\"\\n--- Stability Under Input Noise (on perturbed subgraphs) ---\")\n",
    "print(f\" Clean:  avg_stability={cS_mean:.4f} ± {cS_std:.4f}, avg_relerr={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_stability={tS_mean:.4f} ± {tS_std:.4f}, avg_relerr={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "\n",
    "print(\"\\nSample preview (first 6): (idx, label, stability, rel_err)\")\n",
    "for p in per_sample_info[:6]:\n",
    "    print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283f8365-b671-488a-a20a-03156a14745d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
