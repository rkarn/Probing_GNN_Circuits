{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfa6ce9e-9a74-4424-a211-23c117d27959",
   "metadata": {},
   "source": [
    "#### Training Evaluation with HW2VEC taken from https://github.com/AICPS/hw2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79de5491-1d0a-4061-a85c-bb3bdf26c81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(\n",
      "/home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "Building subgraphs: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 674/674 [00:33<00:00, 19.98it/s]\n",
      "/home/rrk307/anaconda3/envs/gnn_circuits/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 674 subgraphs (usable)\n",
      "Train: 471, Val: 101, Test: 102\n",
      "Epoch 001 | Loss 0.8773 | Val 0.3861\n",
      "Epoch 005 | Loss 0.6591 | Val 0.6238\n",
      "Epoch 010 | Loss 0.6547 | Val 0.3762\n",
      "Epoch 015 | Loss 0.6205 | Val 0.4356\n",
      "Epoch 020 | Loss 0.5790 | Val 0.6139\n",
      "Epoch 025 | Loss 0.5428 | Val 0.6337\n",
      "Epoch 030 | Loss 0.5144 | Val 0.6337\n",
      "Epoch 035 | Loss 0.4601 | Val 0.6535\n",
      "Epoch 040 | Loss 0.4255 | Val 0.7129\n",
      "Epoch 045 | Loss 0.4230 | Val 0.7426\n",
      "Epoch 050 | Loss 0.3813 | Val 0.7030\n",
      "Epoch 055 | Loss 0.3525 | Val 0.8614\n",
      "Epoch 060 | Loss 0.3503 | Val 0.8515\n",
      "Epoch 065 | Loss 0.3179 | Val 0.8614\n",
      "Epoch 070 | Loss 0.2979 | Val 0.9010\n",
      "Epoch 075 | Loss 0.2914 | Val 0.9010\n",
      "Epoch 080 | Loss 0.2619 | Val 0.9208\n",
      "\n",
      "Final Evaluation (Subgraph-Level)\n",
      "=================================\n",
      "Test Accuracy: 0.9510\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7143    0.9091    0.8000        11\n",
      "           1     0.9886    0.9560    0.9721        91\n",
      "\n",
      "    accuracy                         0.9510       102\n",
      "   macro avg     0.8515    0.9326    0.8860       102\n",
      "weighted avg     0.9590    0.9510    0.9535       102\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  1]\n",
      " [ 4 87]]\n"
     ]
    }
   ],
   "source": [
    "# train_subgraph_gnn_fixed_hw2vec.py\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GINConv, global_mean_pool  # NOTE: switched to HW2VEC-style GIN\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 80\n",
    "LR = 1e-3\n",
    "HID_DIM = 64\n",
    "\n",
    "# -----------------------\n",
    "# Load node features\n",
    "# -----------------------\n",
    "nodes_df = pd.read_csv(\"GNNDatasets/node.csv\")\n",
    "nodes_df[\"uid\"] = nodes_df[\"circuit_name\"].astype(str) + \"::\" + nodes_df[\"node\"].astype(str)\n",
    "\n",
    "# one-hot gate_type\n",
    "if \"gate_type\" in nodes_df.columns:\n",
    "    gate_ohe = pd.get_dummies(nodes_df[\"gate_type\"], prefix=\"gt\")\n",
    "    nodes_feat_df = pd.concat([nodes_df.drop(columns=[\"gate_type\"]), gate_ohe], axis=1)\n",
    "else:\n",
    "    nodes_feat_df = nodes_df.copy()\n",
    "\n",
    "meta_cols = {\"uid\",\"node\",\"circuit_name\",\"label\",\"label_node\",\"label_graph\",\"label_subgraph\",\"folder\"}\n",
    "num_cols = [c for c in nodes_feat_df.columns if c not in meta_cols and pd.api.types.is_numeric_dtype(nodes_feat_df[c])]\n",
    "\n",
    "uid_to_feat = {}\n",
    "for _, r in nodes_feat_df.iterrows():\n",
    "    uid_to_feat[r[\"uid\"]] = r[num_cols].astype(float).values\n",
    "\n",
    "scaler = StandardScaler().fit(np.stack(list(uid_to_feat.values())))\n",
    "for k in list(uid_to_feat.keys()):\n",
    "    uid_to_feat[k] = scaler.transform(uid_to_feat[k].reshape(1,-1)).reshape(-1)\n",
    "\n",
    "feat_dim = len(uid_to_feat[list(uid_to_feat.keys())[0]])\n",
    "\n",
    "# -----------------------\n",
    "# Merge edge CSVs\n",
    "# -----------------------\n",
    "edge_files = [\n",
    "    \"GNNDatasets/node_edges.csv\",\n",
    "    \"GNNDatasets/subgraph_edges_andxor.csv\",\n",
    "    \"GNNDatasets/subgraph_edges_countermux.csv\",\n",
    "    \"GNNDatasets/subgraph_edges_fsmor.csv\",\n",
    "]\n",
    "\n",
    "edges_by_circuit = defaultdict(list)\n",
    "for ef in edge_files:\n",
    "    df = pd.read_csv(ef)\n",
    "    for _, r in df.iterrows():\n",
    "        edges_by_circuit[r[\"circuit_name\"]].append((r[\"src\"], r[\"dst\"]))\n",
    "\n",
    "# -----------------------\n",
    "# Build dataset\n",
    "# -----------------------\n",
    "sub_df = pd.read_csv(\"GNNDatasets/subgraph.csv\")\n",
    "data_list, labels = [], []\n",
    "\n",
    "for idx, row in tqdm(sub_df.iterrows(), total=len(sub_df), desc=\"Building subgraphs\"):\n",
    "    ckt = row[\"circuit_name\"]\n",
    "    lbl = int(row.get(\"label_subgraph\", row.get(\"label\", 0)))\n",
    "    \n",
    "    if ckt not in edges_by_circuit:\n",
    "        continue\n",
    "    \n",
    "    # collect node uids from node.csv that belong to this circuit\n",
    "    sub_nodes = nodes_df[nodes_df[\"circuit_name\"]==ckt][\"node\"].tolist()\n",
    "    if not sub_nodes: \n",
    "        continue\n",
    "    \n",
    "    uid_map = {n:i for i,n in enumerate(sub_nodes)}\n",
    "    x_list = []\n",
    "    for n in sub_nodes:\n",
    "        uid = f\"{ckt}::{n}\"\n",
    "        if uid in uid_to_feat:\n",
    "            x_list.append(uid_to_feat[uid])\n",
    "        else:\n",
    "            x_list.append(np.zeros(feat_dim))\n",
    "    x = torch.tensor(np.vstack(x_list), dtype=torch.float)\n",
    "    \n",
    "    # build edge_index\n",
    "    edge_idx = [[], []]\n",
    "    for u,v in edges_by_circuit[ckt]:\n",
    "        if u in uid_map and v in uid_map:\n",
    "            edge_idx[0].append(uid_map[u]); edge_idx[1].append(uid_map[v])\n",
    "            edge_idx[0].append(uid_map[v]); edge_idx[1].append(uid_map[u])\n",
    "    if not edge_idx[0]:\n",
    "        continue\n",
    "    edge_index = torch.tensor(edge_idx, dtype=torch.long)\n",
    "    \n",
    "    data = Data(x=x, edge_index=edge_index, y=torch.tensor([lbl], dtype=torch.long))\n",
    "    data.circuit_name = ckt\n",
    "    data_list.append(data)\n",
    "    labels.append(lbl)\n",
    "\n",
    "print(f\"Built {len(data_list)} subgraphs (usable)\")\n",
    "\n",
    "# -----------------------\n",
    "# Split\n",
    "# -----------------------\n",
    "labels = np.array(labels)\n",
    "idxs = np.arange(len(data_list))\n",
    "train_idx, temp_idx, y_train, y_temp = train_test_split(idxs, labels, test_size=0.3, \n",
    "                                                        stratify=labels, random_state=RANDOM_SEED)\n",
    "val_idx, test_idx, y_val, y_test = train_test_split(temp_idx, y_temp, test_size=0.5,\n",
    "                                                    stratify=y_temp, random_state=RANDOM_SEED)\n",
    "\n",
    "train_loader = DataLoader([data_list[i] for i in train_idx], batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader([data_list[i] for i in val_idx], batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader([data_list[i] for i in test_idx], batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_idx)}, Val: {len(val_idx)}, Test: {len(test_idx)}\")\n",
    "\n",
    "# -----------------------\n",
    "# Model (HW2VEC-style GIN)\n",
    "# -----------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hid_dim, bias=True),\n",
    "            nn.BatchNorm1d(hid_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hid_dim, hid_dim, bias=True),\n",
    "        )\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class HW2VEC_GIN_Subgraph(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim=HID_DIM, out_dim=2, dropout=0.4):\n",
    "        super().__init__()\n",
    "        # Two GINConv layers with MLPs, BatchNorm, ReLU, and dropout (HW2VEC style)\n",
    "        self.mlp1 = MLP(in_dim, hid_dim)\n",
    "        self.conv1 = GINConv(self.mlp1, train_eps=True)\n",
    "        self.bn1 = nn.BatchNorm1d(hid_dim)\n",
    "\n",
    "        self.mlp2 = MLP(hid_dim, hid_dim)\n",
    "        self.conv2 = GINConv(self.mlp2, train_eps=True)\n",
    "        self.bn2 = nn.BatchNorm1d(hid_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.head = nn.Linear(hid_dim, out_dim)\n",
    "        nn.init.xavier_uniform_(self.head.weight)\n",
    "        if self.head.bias is not None:\n",
    "            nn.init.zeros_(self.head.bias)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.head(x)\n",
    "\n",
    "model = HW2VEC_GIN_Subgraph(feat_dim, hid_dim=HID_DIM, out_dim=2, dropout=0.4).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=5e-4)\n",
    "\n",
    "# class weights\n",
    "cls_counts = np.bincount(labels)\n",
    "w = torch.tensor([cls_counts.sum()/c for c in cls_counts], dtype=torch.float32).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss(weight=w)\n",
    "\n",
    "# -----------------------\n",
    "# Training loop\n",
    "# -----------------------\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    ys, preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for b in loader:\n",
    "            b = b.to(DEVICE)\n",
    "            out = model(b.x, b.edge_index, b.batch)\n",
    "            p = out.argmax(dim=1).cpu().numpy()\n",
    "            ys.extend(b.y.cpu().numpy())\n",
    "            preds.extend(p)\n",
    "    return np.array(ys), np.array(preds)\n",
    "\n",
    "best_val, best_state = -1, None\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    total_loss=0\n",
    "    for b in train_loader:\n",
    "        b = b.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(b.x, b.edge_index, b.batch)\n",
    "        loss = criterion(out, b.y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if epoch%5==0 or epoch==1:\n",
    "        yv,pv = evaluate(val_loader)\n",
    "        acc = accuracy_score(yv,pv)\n",
    "        print(f\"Epoch {epoch:03d} | Loss {total_loss/len(train_loader):.4f} | Val {acc:.4f}\")\n",
    "        if acc>best_val: \n",
    "            best_val=acc; best_state=model.state_dict().copy()\n",
    "\n",
    "# load best\n",
    "if best_state: model.load_state_dict(best_state)\n",
    "\n",
    "# -----------------------\n",
    "# Final test\n",
    "# -----------------------\n",
    "yt,pt = evaluate(test_loader)\n",
    "print(\"\\nFinal Evaluation (Subgraph-Level)\")\n",
    "print(\"=================================\")\n",
    "print(f\"Test Accuracy: {accuracy_score(yt,pt):.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(yt,pt,digits=4))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(yt,pt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ef087-787a-4619-9821-37653ff3fb50",
   "metadata": {},
   "source": [
    "#### All in One, same perturbation across all metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "283f8365-b671-488a-a20a-03156a14745d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test subgraphs: 102; class counts: [11 91]\n",
      "Selected perturbation pool counts: {0: 11, 1: 20}\n",
      "\n",
      "--- Step A: Creating shared PGD perturbations for selected subgraphs ---\n",
      "? PGD perturbations done. Time: 101.2s\n",
      "Selected subgraphs: 31. Flipped after PGD: 2 (6.45%).\n",
      "\n",
      "Classification on PERTURBED samples only (selected set):\n",
      "Accuracy (perturbed selected): 83.87%\n",
      "Precision: 0.8369, Recall: 0.8387, F1: 0.8368\n",
      "Classification report (perturbed selected):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.8000    0.7273    0.7619        11\n",
      "      trojan     0.8571    0.9000    0.8780        20\n",
      "\n",
      "    accuracy                         0.8387        31\n",
      "   macro avg     0.8286    0.8136    0.8200        31\n",
      "weighted avg     0.8369    0.8387    0.8368        31\n",
      "\n",
      "Confusion matrix (perturbed selected):\n",
      "[[ 8  3]\n",
      " [ 2 18]]\n",
      "\n",
      "\n",
      "================ Metric: Jacobian Frobenius Norm + FD Relative Error (on perturbed inputs) ================\n",
      "\n",
      "Jacobian Frobenius norms & FD relative errors (aggregated) ON PERTURBED SAMPLES:\n",
      " Clean subgraphs:  avg_norm=0.5544 ± 1.2676, avg_FDrel=1.2866e-01 ± 1.5905e-01\n",
      " Trojan subgraphs: avg_norm=0.1483 ± 0.3466, avg_FDrel=2.3230e-01 ± 3.9583e-01\n",
      "\n",
      "Sample preview (first 6): (idx,label,jacobian_frob,FD_rel_err)\n",
      "(5, 1, 0.09416399151086807, 0.18725116142550322)\n",
      "(7, 1, 1.6468446254730225, 0.037606444871267096)\n",
      "(12, 0, 0.016753070056438446, 0.3821759375779835)\n",
      "(14, 0, 0.04942736029624939, 0.3632005814440342)\n",
      "(15, 1, 0.05669104680418968, 0.006043519515765648)\n",
      "(18, 0, 0.09592229127883911, 0.08145968775406497)\n",
      "\n",
      "Classification (perturbed selected) - Jacobian stage (re-used perturbed set):\n",
      "Accuracy: 83.87%\n",
      "Precision: 0.8369, Recall: 0.8387, F1: 0.8368\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.8000    0.7273    0.7619        11\n",
      "      trojan     0.8571    0.9000    0.8780        20\n",
      "\n",
      "    accuracy                         0.8387        31\n",
      "   macro avg     0.8286    0.8136    0.8200        31\n",
      "weighted avg     0.8369    0.8387    0.8368        31\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 8  3]\n",
      " [ 2 18]]\n",
      "\n",
      "\n",
      "================ Metric: Local Lipschitz (spectral norm) + FD Relative Error ================\n",
      "\n",
      "Local Lipschitz (spectral) & FD relative errors (on PERTURBED samples):\n",
      " Clean:  avg_L=0.5534 ± 1.2680, avg_FDrel=9.0170e-02 ± 8.9879e-02\n",
      " Trojan: avg_L=0.1471 ± 0.3468, avg_FDrel=2.4871e-01 ± 5.8272e-01\n",
      "\n",
      "Sample preview (first 6): (idx,label,sigma_max,fd_rel_err)\n",
      "(5, 1, 0.09280360490083694, 0.035107275656497974)\n",
      "(7, 1, 1.6464556455612183, 0.008959055374952321)\n",
      "(12, 0, 0.015674879774451256, 0.14195588200884546)\n",
      "(14, 0, 0.04885534942150116, 0.16468995631378844)\n",
      "(15, 1, 0.055380843579769135, 0.009070437679125652)\n",
      "(18, 0, 0.09508742392063141, 0.10506314766240105)\n",
      "\n",
      "Classification (perturbed selected) - Local Lipschitz stage:\n",
      "Accuracy: 83.87% | Precision: 0.8369, Recall: 0.8387, F1: 0.8368\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.8000    0.7273    0.7619        11\n",
      "      trojan     0.8571    0.9000    0.8780        20\n",
      "\n",
      "    accuracy                         0.8387        31\n",
      "   macro avg     0.8286    0.8136    0.8200        31\n",
      "weighted avg     0.8369    0.8387    0.8368        31\n",
      "\n",
      "[[ 8  3]\n",
      " [ 2 18]]\n",
      "\n",
      "\n",
      "================ Metric: Hessian curvature proxy (||g||^2) + FD Relative Error ================\n",
      "\n",
      "Hessian-curvature proxy (||g||^2) & FD relative errors (on PERTURBED samples):\n",
      " Clean:  avg_lambda=0.0251 ± 0.0572, avg_FDrel=9.1918e-01 ± 1.1300e-01\n",
      " Trojan: avg_lambda=0.0002 ± 0.0003, avg_FDrel=7.4362e-01 ± 3.3881e-01\n",
      "\n",
      "Sample preview (first 6): (idx,label,lambda,FD_rel_err)\n",
      "(5, 1, 2.522577772631429e-06, 0.6498033052276551)\n",
      "(7, 1, 0.0, 0.0)\n",
      "(12, 0, 4.31690880007031e-05, 0.9716669279196166)\n",
      "(14, 0, 4.4362304679503896e-05, 0.9739066980704401)\n",
      "(15, 1, 0.00012810855114153696, 0.7021079536867948)\n",
      "(18, 0, 0.0027913556295594, 0.9914898360924091)\n",
      "\n",
      "Classification (perturbed selected) - Hessian stage:\n",
      "Accuracy: 83.87% | Precision: 0.8369, Recall: 0.8387, F1: 0.8368\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.8000    0.7273    0.7619        11\n",
      "      trojan     0.8571    0.9000    0.8780        20\n",
      "\n",
      "    accuracy                         0.8387        31\n",
      "   macro avg     0.8286    0.8136    0.8200        31\n",
      "weighted avg     0.8369    0.8387    0.8368        31\n",
      "\n",
      "[[ 8  3]\n",
      " [ 2 18]]\n",
      "\n",
      "\n",
      "================ Metric: Prediction Margin + FD Relative Error ================\n",
      "\n",
      "Prediction Margin stats (on PERTURBED samples):\n",
      " Clean:  avg_margin=1.7126 ± 1.0485, avg_FDrel=5.0123e-04 ± 8.9218e-04\n",
      " Trojan: avg_margin=10.4101 ± 32.1215, avg_FDrel=1.7342e-04 ± 4.4812e-04\n",
      "\n",
      "Sample preview (first 6): (idx,label,margin,fd_rel_err)\n",
      "(5, 1, 4.400561332702637, 1.782525109899853e-05)\n",
      "(7, 1, 149.2738800048828, 2.069913923779418e-05)\n",
      "(12, 0, 0.8505366146564484, 2.0498489629211832e-05)\n",
      "(14, 0, 2.21149742603302, 4.258460293844771e-06)\n",
      "(15, 1, 1.777936041355133, 3.030534546399182e-05)\n",
      "(18, 0, 0.43261106312274933, 0.0007073742960321972)\n",
      "\n",
      "Classification (perturbed selected) - Prediction Margin stage:\n",
      "Accuracy: 83.87% | Precision: 0.8369, Recall: 0.8387, F1: 0.8368\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.8000    0.7273    0.7619        11\n",
      "      trojan     0.8571    0.9000    0.8780        20\n",
      "\n",
      "    accuracy                         0.8387        31\n",
      "   macro avg     0.8286    0.8136    0.8200        31\n",
      "weighted avg     0.8369    0.8387    0.8368        31\n",
      "\n",
      "[[ 8  3]\n",
      " [ 2 18]]\n",
      "\n",
      "\n",
      "================ Metric: Adversarial Robustness Radius (ARR) ================\n",
      " processed 10/31 ...\n",
      " processed 20/31 ...\n",
      " processed 30/31 ...\n",
      "? ARR computation done. Time elapsed: 977.1s\n",
      "\n",
      "ARR (Adversarial Robustness Radius) Stats (on perturbed selected samples):\n",
      " clean : avg_radius=20.0000 ± 0.0000, avg_relerr=0.0000e+00 ± 0.0000e+00\n",
      " trojan: avg_radius=20.0000 ± 0.0000, avg_relerr=0.0000e+00 ± 0.0000e+00\n",
      " Overall: avg_radius=20.0000 ± 0.0000; avg_relerr=0.0000e+00 ± 0.0000e+00\n",
      "\n",
      "Classification (perturbed selected) - ARR stage:\n",
      "Accuracy: 83.87% | Precision: 0.8369, Recall: 0.8387, F1: 0.8368\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.8000    0.7273    0.7619        11\n",
      "      trojan     0.8571    0.9000    0.8780        20\n",
      "\n",
      "    accuracy                         0.8387        31\n",
      "   macro avg     0.8286    0.8136    0.8200        31\n",
      "weighted avg     0.8369    0.8387    0.8368        31\n",
      "\n",
      "[[ 8  3]\n",
      " [ 2 18]]\n",
      "\n",
      "\n",
      "================ Metric: Stability Under Input Noise (SUIN) ================\n",
      " processed 10/31 ...\n",
      " processed 20/31 ...\n",
      " processed 30/31 ...\n",
      "? SUIN done. Time elapsed: 285.4s\n",
      "\n",
      "Stability Under Input Noise (on perturbed selected samples):\n",
      " Clean: avg_stability=1.7740 ± 1.3450, avg_relerr=6.5917e-02 ± 6.7153e-02\n",
      " Trojan:avg_stability=3.2398 ± 3.0790, avg_relerr=1.2999e-01 ± 2.0376e-01\n",
      "\n",
      "Sample preview (first 6): (idx,label,stability,rel_err)\n",
      "(5, 1, 1.802435028553009, 0.011698477228243052)\n",
      "(7, 1, 0.5528695352375508, 0.21446365828217606)\n",
      "(12, 0, 0.11786173619329929, 0.02125938526228557)\n",
      "(14, 0, 2.1323076128959655, 0.04645763406893693)\n",
      "(15, 1, 0.024960545008070767, 0.47540932083673465)\n",
      "(18, 0, 2.5719880402088164, 0.035257587774353484)\n",
      "\n",
      "Classification (perturbed selected) - SUIN stage:\n",
      "Accuracy: 83.87% | Precision: 0.8369, Recall: 0.8387, F1: 0.8368\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean     0.8000    0.7273    0.7619        11\n",
      "      trojan     0.8571    0.9000    0.8780        20\n",
      "\n",
      "    accuracy                         0.8387        31\n",
      "   macro avg     0.8286    0.8136    0.8200        31\n",
      "weighted avg     0.8369    0.8387    0.8368        31\n",
      "\n",
      "[[ 8  3]\n",
      " [ 2 18]]\n",
      "\n",
      "\n",
      "All metrics computed on the SAME selected subgraphs and the SAME PGD perturbations (perturbed_map).\n",
      "You can adjust PER_CLASS, EPSILON_PGD, ALPHA_PGD, NUM_ITERS_PGD to change attack strength.\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# Subgraph-level: unified end-to-end robustness evaluation reusing one PGD\n",
    "# =====================================================================\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# -------------------------\n",
    "# Parameters (tweak here)\n",
    "# -------------------------\n",
    "PER_CLASS        = 20        # number of subgraphs per class to perturb\n",
    "EPSILON_PGD      = 4.0       # L2 radius for the PGD perturbation applied once and reused\n",
    "ALPHA_PGD        = 1.0       # PGD step size\n",
    "NUM_ITERS_PGD    = 30        # PGD iterations\n",
    "FD_EPS           = 1e-3      # finite-difference epsilon\n",
    "ARR_INITIAL_EPS  = 1e-3      # initial epsilon for ARR search\n",
    "ARR_GROW1        = 1.25\n",
    "ARR_GROW2        = 1.4\n",
    "ARR_MAX_EPS      = 20.0\n",
    "ARR_BS_ITERS     = 10\n",
    "ARR_TRIALS       = 6\n",
    "STAB_SIGMA       = 0.5       # stability noise sigma\n",
    "STAB_SAMPLES     = 20\n",
    "STAB_RELERR_RPTS = 5\n",
    "SEED             = 42\n",
    "\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# -------------------------\n",
    "# Sanity\n",
    "# -------------------------\n",
    "required = [\"model\", \"test_loader\", \"DEVICE\"]\n",
    "for r in required:\n",
    "    if r not in globals():\n",
    "        raise RuntimeError(f\"Required variable '{r}' not found in the environment (must be defined earlier).\")\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# -------------------------\n",
    "# Extract test dataset list & labels (preserve loader order)\n",
    "# -------------------------\n",
    "dataset = list(test_loader.dataset) if hasattr(test_loader, \"dataset\") else list(test_loader)\n",
    "n_test = len(dataset)\n",
    "labels_all = np.array([int(d.y.item()) for d in dataset])\n",
    "print(f\"Total test subgraphs: {n_test}; class counts: {np.bincount(labels_all)}\")\n",
    "\n",
    "# -------------------------\n",
    "# Select indices (same pool for all metrics)\n",
    "# -------------------------\n",
    "rng = np.random.default_rng(SEED)\n",
    "selected = []\n",
    "for cls in [0,1]:\n",
    "    idxs = np.where(labels_all == cls)[0]\n",
    "    if len(idxs)==0:\n",
    "        continue\n",
    "    k = min(PER_CLASS, len(idxs))\n",
    "    chosen = rng.choice(idxs, size=k, replace=False)\n",
    "    selected.extend(chosen.tolist())\n",
    "selected = np.array(sorted(selected), dtype=np.int64)\n",
    "print(\"Selected perturbation pool counts:\", {0:int((labels_all[selected]==0).sum()), 1:int((labels_all[selected]==1).sum())})\n",
    "\n",
    "# small helper for single-graph batch vectors\n",
    "def batch_for(x):\n",
    "    return torch.zeros(x.size(0), dtype=torch.long, device=DEVICE)\n",
    "\n",
    "# -------------------------\n",
    "# Build one shared PGD perturbation map (perturbed_map)\n",
    "# - perturb each selected subgraph's node features (x) via PGD (L2 constrained)\n",
    "# - store perturbed_map[idx] -> perturbed x (on DEVICE)\n",
    "# -------------------------\n",
    "perturbed_map = {}\n",
    "orig_preds_selected = []\n",
    "adv_preds_selected = []\n",
    "\n",
    "print(\"\\n--- Step A: Creating shared PGD perturbations for selected subgraphs ---\")\n",
    "t0 = time.time()\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x_orig = data.x.detach().clone().to(DEVICE)    # (N_nodes, feat_dim)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    n_nodes, feat_dim = x_orig.shape\n",
    "    y_true = torch.tensor([int(data.y.item())], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    # random initialization inside L2-ball (on flattened features)\n",
    "    delta = torch.randn_like(x_orig, device=DEVICE)\n",
    "    delta = delta * (EPSILON_PGD / (delta.view(-1).norm() + 1e-12))\n",
    "    x_adv = (x_orig + delta).detach().clone().requires_grad_(True)\n",
    "\n",
    "    # PGD loop (maximize CE loss to cause misclassification)\n",
    "    for it in range(NUM_ITERS_PGD):\n",
    "        out = model(x_adv, edge_index, batch_for(x_adv))           # [1, C]\n",
    "        loss = F.cross_entropy(out, y_true)\n",
    "        grad_x = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "        gnorm = grad_x.view(-1).norm().item()\n",
    "        if gnorm == 0:\n",
    "            break\n",
    "        step = (ALPHA_PGD * grad_x) / (gnorm + 1e-12)\n",
    "        x_adv = (x_adv + step).detach()\n",
    "        # project back to L2 ball (flattened)\n",
    "        delta = x_adv - x_orig\n",
    "        dnorm = delta.view(-1).norm().item()\n",
    "        if dnorm > EPSILON_PGD:\n",
    "            delta = delta * (EPSILON_PGD / (dnorm + 1e-12))\n",
    "            x_adv = (x_orig + delta).detach()\n",
    "        x_adv = x_adv.requires_grad_(True)\n",
    "\n",
    "    x_adv_final = x_adv.detach().clone()\n",
    "    perturbed_map[int(idx)] = x_adv_final\n",
    "\n",
    "    # store flip stats\n",
    "    with torch.no_grad():\n",
    "        out_orig = model(x_orig, edge_index, batch_for(x_orig))\n",
    "        out_adv  = model(x_adv_final, edge_index, batch_for(x_adv_final))\n",
    "        orig_preds_selected.append(int(out_orig.argmax(dim=1).item()))\n",
    "        adv_preds_selected.append(int(out_adv.argmax(dim=1).item()))\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"? PGD perturbations done. Time: {t1-t0:.1f}s\")\n",
    "orig_preds_selected = np.array(orig_preds_selected)\n",
    "adv_preds_selected  = np.array(adv_preds_selected)\n",
    "num_flips = int((orig_preds_selected != adv_preds_selected).sum())\n",
    "print(f\"Selected subgraphs: {len(selected)}. Flipped after PGD: {num_flips} ({100.0 * num_flips / len(selected):.2f}%).\")\n",
    "\n",
    "# Also compute and show perturbed-only classifier behavior (for selected set)\n",
    "with torch.no_grad():\n",
    "    labels_sel = labels_all[selected]\n",
    "    preds_perturbed = []\n",
    "    for idx in selected:\n",
    "        data = dataset[int(idx)]\n",
    "        logits = model(perturbed_map[int(idx)], data.edge_index.to(DEVICE), batch_for(perturbed_map[int(idx)]))\n",
    "        preds_perturbed.append(int(logits.argmax(dim=1).item()))\n",
    "    preds_perturbed = np.array(preds_perturbed)\n",
    "\n",
    "print(\"\\nClassification on PERTURBED samples only (selected set):\")\n",
    "acc_sel = (preds_perturbed == labels_sel).mean()\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(labels_sel, preds_perturbed, average='weighted', zero_division=0)\n",
    "print(f\"Accuracy (perturbed selected): {acc_sel*100:.2f}%\")\n",
    "print(f\"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\")\n",
    "print(\"Classification report (perturbed selected):\")\n",
    "print(classification_report(labels_sel, preds_perturbed, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion matrix (perturbed selected):\")\n",
    "print(confusion_matrix(labels_sel, preds_perturbed, labels=[0,1]))\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Utility: evaluate on perturbed selected set only (used by metrics to print)\n",
    "# -------------------------------------------------------------------------\n",
    "def eval_perturbed_selected(perturbed_map, selected_idxs):\n",
    "    with torch.no_grad():\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for idx in selected_idxs:\n",
    "            data = dataset[int(idx)]\n",
    "            lab = int(data.y.item())\n",
    "            x_eval = perturbed_map[int(idx)]\n",
    "            logits = model(x_eval, data.edge_index.to(DEVICE), batch_for(x_eval))\n",
    "            y_true.append(lab)\n",
    "            y_pred.append(int(logits.argmax(dim=1).item()))\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    acc = (y_true == y_pred).mean()\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    return y_true, y_pred, acc, prec, rec, f1\n",
    "\n",
    "# -------------------------\n",
    "# Metric 1: Jacobian Frobenius norm + FD relative error\n",
    "# (computed at the perturbed inputs; flattened features)\n",
    "# -------------------------\n",
    "print(\"\\n\\n================ Metric: Jacobian Frobenius Norm + FD Relative Error (on perturbed inputs) ================\")\n",
    "per_sample_jac = []   # (idx,label, jac_frob, fd_rel_err)\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x_adv = perturbed_map[int(idx)].detach().clone().to(DEVICE).requires_grad_(True)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    n_nodes, feat_dim = x_adv.shape\n",
    "    d = n_nodes * feat_dim\n",
    "\n",
    "    # flatten\n",
    "    x_flat = x_adv.view(-1).detach().clone().requires_grad_(True)\n",
    "\n",
    "    def f_flat(x_in):\n",
    "        x_mat = x_in.view_as(x_adv)\n",
    "        out = model(x_mat, edge_index, batch_for(x_mat))   # [1, C]\n",
    "        return out.squeeze(0)                              # (C,)\n",
    "\n",
    "    # Jacobian: shape (C, d)\n",
    "    try:\n",
    "        J = torch.autograd.functional.jacobian(f_flat, x_flat)   # (C, d)\n",
    "    except RuntimeError:\n",
    "        # fallback: compute per-output jac rows\n",
    "        logits0 = f_flat(x_flat).detach()\n",
    "        C = logits0.shape[0]\n",
    "        rows = []\n",
    "        for c in range(C):\n",
    "            def scalar_f(z, cidx=c):\n",
    "                return f_flat(z)[cidx]\n",
    "            r = torch.autograd.functional.jacobian(scalar_f, x_flat)\n",
    "            rows.append(r.unsqueeze(0))\n",
    "        J = torch.cat(rows, dim=0)\n",
    "\n",
    "    J = J.detach()\n",
    "    jac_frob = float(torch.norm(J, p='fro').item())\n",
    "\n",
    "    # FD relative error\n",
    "    delta_fd = FD_EPS * torch.randn(d, device=DEVICE)\n",
    "    pred_change = (J @ delta_fd)                      # (C,)\n",
    "    f0 = f_flat(x_flat).detach()\n",
    "    f0p = f_flat((x_flat + delta_fd)).detach()\n",
    "    actual_change = f0p - f0\n",
    "    if torch.norm(actual_change).item() == 0:\n",
    "        rel_err = 0.0\n",
    "    else:\n",
    "        rel_err = float(torch.norm(pred_change - actual_change).item() / (torch.norm(actual_change).item() + 1e-8))\n",
    "\n",
    "    per_sample_jac.append((int(idx), int(data.y.item()), jac_frob, rel_err))\n",
    "\n",
    "# aggregate & print\n",
    "arr = np.array([[i,l,j,r] for (i,l,j,r) in per_sample_jac], dtype=object)\n",
    "if arr.size:\n",
    "    clean_vals = arr[arr[:,1]==0][:,2].astype(float) if (arr[:,1]==0).any() else np.array([])\n",
    "    troj_vals  = arr[arr[:,1]==1][:,2].astype(float) if (arr[:,1]==1).any() else np.array([])\n",
    "    clean_errs = arr[arr[:,1]==0][:,3].astype(float) if (arr[:,1]==0).any() else np.array([])\n",
    "    troj_errs  = arr[arr[:,1]==1][:,3].astype(float) if (arr[:,1]==1).any() else np.array([])\n",
    "\n",
    "    def mean_std(a): return (a.mean(), a.std()) if len(a)>0 else (0.0,0.0)\n",
    "\n",
    "    c_mean, c_std = mean_std(clean_vals)\n",
    "    t_mean, t_std = mean_std(troj_vals)\n",
    "    ce_mean, ce_std = mean_std(clean_errs)\n",
    "    te_mean, te_std = mean_std(troj_errs)\n",
    "\n",
    "    print(\"\\nJacobian Frobenius norms & FD relative errors (aggregated) ON PERTURBED SAMPLES:\")\n",
    "    print(f\" Clean subgraphs:  avg_norm={c_mean:.4f} ± {c_std:.4f}, avg_FDrel={ce_mean:.4e} ± {ce_std:.4e}\")\n",
    "    print(f\" Trojan subgraphs: avg_norm={t_mean:.4f} ± {t_std:.4f}, avg_FDrel={te_mean:.4e} ± {te_std:.4e}\")\n",
    "    print(\"\\nSample preview (first 6): (idx,label,jacobian_frob,FD_rel_err)\")\n",
    "    for t in per_sample_jac[:6]:\n",
    "        print(t)\n",
    "else:\n",
    "    print(\"No Jacobian samples computed.\")\n",
    "\n",
    "# Print classification performance on perturbed selected set only\n",
    "y_true_sel, y_pred_sel, acc_sel, prec_sel, rec_sel, f1_sel = (*eval_perturbed_selected(perturbed_map, selected),)\n",
    "print(\"\\nClassification (perturbed selected) - Jacobian stage (re-used perturbed set):\")\n",
    "print(f\"Accuracy: {acc_sel*100:.2f}%\")\n",
    "print(f\"Precision: {prec_sel:.4f}, Recall: {rec_sel:.4f}, F1: {f1_sel:.4f}\")\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_true_sel, y_pred_sel, target_names=['clean','trojan'], digits=4))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_true_sel, y_pred_sel, labels=[0,1]))\n",
    "\n",
    "# -------------------------\n",
    "# Metric 2: Local Lipschitz (spectral norm of Jacobian) + FD relative error\n",
    "# (Compute at perturbed inputs; flatten J to (C,d) and compute top singular value)\n",
    "# -------------------------\n",
    "print(\"\\n\\n================ Metric: Local Lipschitz (spectral norm) + FD Relative Error ================\")\n",
    "per_sample_lip = []  # (idx,label,sigma_max, fd_rel_err)\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x_adv = perturbed_map[int(idx)].detach().clone().to(DEVICE).requires_grad_(True)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    n_nodes, feat_dim = x_adv.shape\n",
    "    d = n_nodes * feat_dim\n",
    "\n",
    "    def f_local(x):\n",
    "        return model(x, edge_index, batch_for(x)).squeeze(0)\n",
    "\n",
    "    # Jacobian shape (C, N, F)\n",
    "    try:\n",
    "        J = torch.autograd.functional.jacobian(f_local, x_adv).detach()   # (C, N, F)\n",
    "    except RuntimeError:\n",
    "        # fallback per-output (slower)\n",
    "        logits0 = f_local(x_adv).detach()\n",
    "        C = logits0.shape[0]\n",
    "        rows = []\n",
    "        for c in range(C):\n",
    "            def scalar_f(z, cidx=c):\n",
    "                return f_local(z)[cidx]\n",
    "            row = torch.autograd.functional.jacobian(scalar_f, x_adv)\n",
    "            rows.append(row.unsqueeze(0))\n",
    "        J = torch.cat(rows, dim=0)\n",
    "\n",
    "    C = J.shape[0]\n",
    "    J_flat = J.reshape(C, d)   # (C, d)\n",
    "\n",
    "    # spectral norm via SVD (largest singular value)\n",
    "    try:\n",
    "        _, S, _ = torch.linalg.svd(J_flat, full_matrices=False)\n",
    "        sigma_max = float(S[0].item())\n",
    "    except RuntimeError:\n",
    "        # fallback via eigen\n",
    "        JJT = (J_flat @ J_flat.T).cpu().numpy()\n",
    "        eigvals = np.linalg.eigvalsh(JJT)\n",
    "        sigma_max = float(np.sqrt(max(eigvals.max(), 0.0)))\n",
    "\n",
    "    # FD relative error\n",
    "    delta_fd = FD_EPS * torch.randn(d, device=DEVICE)\n",
    "    pred_change = (J_flat @ delta_fd)               # (C,)\n",
    "    f0 = f_local(x_adv).detach()\n",
    "    f0p = f_local(x_adv + delta_fd.view_as(x_adv)).detach()\n",
    "    actual_change = f0p - f0\n",
    "    if torch.norm(actual_change).item() == 0:\n",
    "        fd_rel = 0.0\n",
    "    else:\n",
    "        fd_rel = float(torch.norm(pred_change - actual_change).item() / (torch.norm(actual_change).item() + 1e-8))\n",
    "\n",
    "    per_sample_lip.append((int(idx), int(data.y.item()), float(sigma_max), float(fd_rel)))\n",
    "\n",
    "# aggregate & print\n",
    "clean_stats = [p for p in per_sample_lip if p[1]==0]\n",
    "troj_stats  = [p for p in per_sample_lip if p[1]==1]\n",
    "def aggs(stats):\n",
    "    if not stats: return (0.0,0.0,0.0,0.0)\n",
    "    Ls = np.array([s[2] for s in stats]); Es = np.array([s[3] for s in stats])\n",
    "    return (Ls.mean(), Ls.std(), Es.mean(), Es.std())\n",
    "\n",
    "cL_mean, cL_std, cE_mean, cE_std = aggs(clean_stats)\n",
    "tL_mean, tL_std, tE_mean, tE_std = aggs(troj_stats)\n",
    "\n",
    "print(\"\\nLocal Lipschitz (spectral) & FD relative errors (on PERTURBED samples):\")\n",
    "print(f\" Clean:  avg_L={cL_mean:.4f} ± {cL_std:.4f}, avg_FDrel={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_L={tL_mean:.4f} ± {tL_std:.4f}, avg_FDrel={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "print(\"\\nSample preview (first 6): (idx,label,sigma_max,fd_rel_err)\")\n",
    "for p in per_sample_lip[:6]:\n",
    "    print(p)\n",
    "\n",
    "# classification on perturbed selected\n",
    "y_true_sel, y_pred_sel, acc_sel, prec_sel, rec_sel, f1_sel = (*eval_perturbed_selected(perturbed_map, selected),)\n",
    "print(\"\\nClassification (perturbed selected) - Local Lipschitz stage:\")\n",
    "print(f\"Accuracy: {acc_sel*100:.2f}% | Precision: {prec_sel:.4f}, Recall: {rec_sel:.4f}, F1: {f1_sel:.4f}\")\n",
    "print(classification_report(y_true_sel, y_pred_sel, target_names=['clean','trojan'], digits=4))\n",
    "print(confusion_matrix(y_true_sel, y_pred_sel, labels=[0,1]))\n",
    "\n",
    "# -------------------------\n",
    "# Metric 3: Hessian curvature proxy (||g||^2) + FD relative error\n",
    "# (Compute gradient of log-prob for predicted class at perturbed inputs)\n",
    "# -------------------------\n",
    "print(\"\\n\\n================ Metric: Hessian curvature proxy (||g||^2) + FD Relative Error ================\")\n",
    "TRIALS_HESS_FD = 5\n",
    "per_sample_hess = []   # (idx,label, lambda_proxy=||g||^2, avg_fd_rel_err)\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x_adv = perturbed_map[int(idx)].detach().clone().to(DEVICE).requires_grad_(True)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "\n",
    "    # forward & predicted class (allow grad)\n",
    "    logits = model(x_adv, edge_index, batch_for(x_adv)).squeeze(0)\n",
    "    pred_class = int(logits.argmax().item())\n",
    "\n",
    "    # compute log-prob of predicted class\n",
    "    logp = F.log_softmax(logits, dim=0)[pred_class]\n",
    "    # gradient wrt x_adv\n",
    "    g = torch.autograd.grad(logp, x_adv, retain_graph=False, create_graph=False, allow_unused=False)[0].detach()\n",
    "    lambda_proxy = float(g.norm(p=2).item() ** 2)\n",
    "\n",
    "    # FD relative errors (multiple small deltas)\n",
    "    rels = []\n",
    "    for _ in range(TRIALS_HESS_FD):\n",
    "        delta = FD_EPS * torch.randn_like(x_adv).to(DEVICE)\n",
    "        gt_delta = float((g * delta).sum().item())\n",
    "        pred_second = 0.5 * (gt_delta ** 2)\n",
    "        # recompute logp at perturbed input\n",
    "        logits_p = model((x_adv + delta).detach(), edge_index, batch_for(x_adv + delta)).squeeze(0)\n",
    "        logp_p = F.log_softmax(logits_p, dim=0)[pred_class]\n",
    "        actual_second = float((logp_p - F.log_softmax(logits, dim=0)[pred_class]).item() - gt_delta)\n",
    "        rel_err = abs(pred_second - actual_second) / (abs(actual_second) + 1e-8)\n",
    "        rels.append(rel_err)\n",
    "    avg_rel_err = float(np.mean(rels))\n",
    "    per_sample_hess.append((int(idx), int(data.y.item()), lambda_proxy, avg_rel_err))\n",
    "\n",
    "# aggregate & print\n",
    "clean_stats = [t for t in per_sample_hess if t[1]==0]\n",
    "troj_stats  = [t for t in per_sample_hess if t[1]==1]\n",
    "def summarize(stats):\n",
    "    if not stats: return (0.0,0.0,0.0,0.0)\n",
    "    Ls = np.array([s[2] for s in stats]); Es = np.array([s[3] for s in stats])\n",
    "    return (Ls.mean(), Ls.std(), Es.mean(), Es.std())\n",
    "\n",
    "cL_mean, cL_std, cE_mean, cE_std = summarize(clean_stats)\n",
    "tL_mean, tL_std, tE_mean, tE_std = summarize(troj_stats)\n",
    "print(\"\\nHessian-curvature proxy (||g||^2) & FD relative errors (on PERTURBED samples):\")\n",
    "print(f\" Clean:  avg_lambda={cL_mean:.4f} ± {cL_std:.4f}, avg_FDrel={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_lambda={tL_mean:.4f} ± {tL_std:.4f}, avg_FDrel={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "print(\"\\nSample preview (first 6): (idx,label,lambda,FD_rel_err)\")\n",
    "for p in per_sample_hess[:6]:\n",
    "    print(p)\n",
    "\n",
    "# classification on perturbed selected\n",
    "y_true_sel, y_pred_sel, acc_sel, prec_sel, rec_sel, f1_sel = (*eval_perturbed_selected(perturbed_map, selected),)\n",
    "print(\"\\nClassification (perturbed selected) - Hessian stage:\")\n",
    "print(f\"Accuracy: {acc_sel*100:.2f}% | Precision: {prec_sel:.4f}, Recall: {rec_sel:.4f}, F1: {f1_sel:.4f}\")\n",
    "print(classification_report(y_true_sel, y_pred_sel, target_names=['clean','trojan'], digits=4))\n",
    "print(confusion_matrix(y_true_sel, y_pred_sel, labels=[0,1]))\n",
    "\n",
    "# -------------------------\n",
    "# Metric 4: Prediction Margin + FD relative error (on perturbed inputs)\n",
    "# -------------------------\n",
    "print(\"\\n\\n================ Metric: Prediction Margin + FD Relative Error ================\")\n",
    "per_sample_margin = []   # (idx,label, margin, fd_rel_err)\n",
    "for idx in selected:\n",
    "    data = dataset[int(idx)]\n",
    "    x_adv = perturbed_map[int(idx)].detach().clone().to(DEVICE)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x_adv, edge_index, batch_for(x_adv)).squeeze(0)\n",
    "    pred_class = int(logits.argmax().item())\n",
    "    pred_logit = float(logits[pred_class].item())\n",
    "    other_logits = logits.clone()\n",
    "    other_logits[pred_class] = -float('inf')\n",
    "    second_max = float(other_logits.max().item())\n",
    "    margin = pred_logit - second_max\n",
    "\n",
    "    # FD check\n",
    "    delta = FD_EPS * torch.randn_like(x_adv).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits_p = model(x_adv + delta, edge_index, batch_for(x_adv)).squeeze(0)\n",
    "    pred_logit_p = float(logits_p[pred_class].item())\n",
    "    other_logits_p = logits_p.clone()\n",
    "    other_logits_p[pred_class] = -float('inf')\n",
    "    second_max_p = float(other_logits_p.max().item())\n",
    "    margin_p = pred_logit_p - second_max_p\n",
    "    rel_err = abs(margin - margin_p) / (abs(margin_p) + 1e-12)\n",
    "    per_sample_margin.append((int(idx), int(data.y.item()), float(margin), float(rel_err)))\n",
    "\n",
    "# aggregate & print\n",
    "clean_stats = [p for p in per_sample_margin if p[1]==0]\n",
    "troj_stats  = [p for p in per_sample_margin if p[1]==1]\n",
    "def aggs_m(stats):\n",
    "    if not stats: return (0.0,0.0,0.0,0.0)\n",
    "    Ms = np.array([s[2] for s in stats]); Es = np.array([s[3] for s in stats])\n",
    "    return (Ms.mean(), Ms.std(), Es.mean(), Es.std())\n",
    "\n",
    "cM_mean, cM_std, cE_mean, cE_std = aggs_m(clean_stats)\n",
    "tM_mean, tM_std, tE_mean, tE_std = aggs_m(troj_stats)\n",
    "print(\"\\nPrediction Margin stats (on PERTURBED samples):\")\n",
    "print(f\" Clean:  avg_margin={cM_mean:.4f} ± {cM_std:.4f}, avg_FDrel={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan: avg_margin={tM_mean:.4f} ± {tM_std:.4f}, avg_FDrel={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "print(\"\\nSample preview (first 6): (idx,label,margin,fd_rel_err)\")\n",
    "for p in per_sample_margin[:6]:\n",
    "    print(p)\n",
    "\n",
    "# classification on perturbed selected\n",
    "y_true_sel, y_pred_sel, acc_sel, prec_sel, rec_sel, f1_sel = (*eval_perturbed_selected(perturbed_map, selected),)\n",
    "print(\"\\nClassification (perturbed selected) - Prediction Margin stage:\")\n",
    "print(f\"Accuracy: {acc_sel*100:.2f}% | Precision: {prec_sel:.4f}, Recall: {rec_sel:.4f}, F1: {f1_sel:.4f}\")\n",
    "print(classification_report(y_true_sel, y_pred_sel, target_names=['clean','trojan'], digits=4))\n",
    "print(confusion_matrix(y_true_sel, y_pred_sel, labels=[0,1]))\n",
    "\n",
    "# -------------------------\n",
    "# Metric 5: Adversarial Robustness Radius (ARR) around perturbed points\n",
    "# -------------------------\n",
    "print(\"\\n\\n================ Metric: Adversarial Robustness Radius (ARR) ================\")\n",
    "def f_for_subgraph(x_tensor, data):\n",
    "    with torch.no_grad():\n",
    "        out = model(x_tensor, data.edge_index.to(DEVICE), batch_for(x_tensor))\n",
    "    return out.squeeze(0)\n",
    "\n",
    "def adversarial_radius_for_subgraph(data, x0, initial_epsilon=ARR_INITIAL_EPS, growth_factor=ARR_GROW1,\n",
    "                                    max_epsilon=ARR_MAX_EPS, bs_iters=ARR_BS_ITERS, num_trials=ARR_TRIALS):\n",
    "    \"\"\"Estimate minimal L2 norm that flips prediction around x0.\"\"\"\n",
    "    x0 = x0.clone().detach().to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        base_out = model(x0, data.edge_index.to(DEVICE), batch_for(x0))\n",
    "        y0 = int(base_out.argmax().item())\n",
    "\n",
    "    def is_same(x):\n",
    "        out = f_for_subgraph(x, data)\n",
    "        return int(out.argmax().item()) == y0\n",
    "\n",
    "    radii = []\n",
    "    for _ in range(num_trials):\n",
    "        d = torch.randn_like(x0).to(DEVICE)\n",
    "        d = d / (d.view(-1).norm() + 1e-12)\n",
    "        eps = initial_epsilon\n",
    "        while eps < max_epsilon and is_same(x0 + eps * d):\n",
    "            eps *= growth_factor\n",
    "        if eps >= max_epsilon:\n",
    "            radii.append(float(max_epsilon))\n",
    "            continue\n",
    "        low, high = eps / growth_factor, eps\n",
    "        for _ in range(bs_iters):\n",
    "            mid = 0.5 * (low + high)\n",
    "            if is_same(x0 + mid * d):\n",
    "                low = mid\n",
    "            else:\n",
    "                high = mid\n",
    "        radii.append(float(high))\n",
    "    return float(min(radii))\n",
    "\n",
    "def adversarial_radius_relerr(data, x0):\n",
    "    r1 = adversarial_radius_for_subgraph(data, x0, growth_factor=ARR_GROW1, num_trials=ARR_TRIALS)\n",
    "    r2 = adversarial_radius_for_subgraph(data, x0, growth_factor=ARR_GROW2, num_trials=ARR_TRIALS)\n",
    "    rel_err = abs(r1 - r2) / (abs(r2) + 1e-12)\n",
    "    return r1, rel_err\n",
    "\n",
    "class_names = ['clean','trojan']\n",
    "class_adv_radius = {cn: [] for cn in class_names}\n",
    "class_rel_errors = {cn: [] for cn in class_names}\n",
    "all_rads = []; all_relerrs = []\n",
    "\n",
    "t0 = time.time()\n",
    "for i, idx in enumerate(selected):\n",
    "    data = dataset[int(idx)]\n",
    "    x0 = perturbed_map[int(idx)].clone().detach().to(DEVICE)\n",
    "    r, rel = adversarial_radius_relerr(data, x0)\n",
    "    lab = int(data.y.item())\n",
    "    class_adv_radius[class_names[lab]].append(r)\n",
    "    class_rel_errors[class_names[lab]].append(rel)\n",
    "    all_rads.append(r); all_relerrs.append(rel)\n",
    "    if (i+1)%10 == 0:\n",
    "        print(f\" processed {i+1}/{len(selected)} ...\")\n",
    "t1 = time.time()\n",
    "print(f\"? ARR computation done. Time elapsed: {t1-t0:.1f}s\")\n",
    "\n",
    "# reporting ARR\n",
    "print(\"\\nARR (Adversarial Robustness Radius) Stats (on perturbed selected samples):\")\n",
    "for cn in class_names:\n",
    "    vals = class_adv_radius[cn]\n",
    "    errs = class_rel_errors[cn]\n",
    "    if vals:\n",
    "        print(f\" {cn:6s}: avg_radius={np.mean(vals):.4f} ± {np.std(vals):.4f}, avg_relerr={np.mean(errs):.4e} ± {np.std(errs):.4e}\")\n",
    "    else:\n",
    "        print(f\" {cn:6s}: -\")\n",
    "print(f\" Overall: avg_radius={np.mean(all_rads):.4f} ± {np.std(all_rads):.4f}; avg_relerr={np.mean(all_relerrs):.4e} ± {np.std(all_relerrs):.4e}\")\n",
    "\n",
    "# classification on perturbed selected\n",
    "y_true_sel, y_pred_sel, acc_sel, prec_sel, rec_sel, f1_sel = (*eval_perturbed_selected(perturbed_map, selected),)\n",
    "print(\"\\nClassification (perturbed selected) - ARR stage:\")\n",
    "print(f\"Accuracy: {acc_sel*100:.2f}% | Precision: {prec_sel:.4f}, Recall: {rec_sel:.4f}, F1: {f1_sel:.4f}\")\n",
    "print(classification_report(y_true_sel, y_pred_sel, target_names=['clean','trojan'], digits=4))\n",
    "print(confusion_matrix(y_true_sel, y_pred_sel, labels=[0,1]))\n",
    "\n",
    "# -------------------------\n",
    "# Metric 6: Stability Under Input Noise (SUIN) on perturbed subgraphs\n",
    "# -------------------------\n",
    "print(\"\\n\\n================ Metric: Stability Under Input Noise (SUIN) ================\")\n",
    "def stability_for_subgraph(idx, sigma, num_samples):\n",
    "    data = dataset[int(idx)]\n",
    "    base_x = perturbed_map[int(idx)].to(DEVICE)\n",
    "    edge_index = data.edge_index.to(DEVICE)\n",
    "    batch = batch_for(base_x)\n",
    "    with torch.no_grad():\n",
    "        f_orig = model(base_x, edge_index, batch).squeeze(0)\n",
    "    diffs = []\n",
    "    for _ in range(num_samples):\n",
    "        noise = sigma * torch.randn_like(base_x).to(DEVICE)\n",
    "        f_noisy = model(base_x + noise, edge_index, batch).squeeze(0)\n",
    "        diffs.append(torch.norm(f_noisy - f_orig).item())\n",
    "    return float(np.mean(diffs))\n",
    "\n",
    "t0 = time.time()\n",
    "per_sample_stab = []  # (idx,label, stability, rel_err)\n",
    "for i, idx in enumerate(selected):\n",
    "    s_val = stability_for_subgraph(idx, STAB_SIGMA, STAB_SAMPLES)\n",
    "    # relative error by repeating\n",
    "    re_vals = [stability_for_subgraph(idx, STAB_SIGMA, STAB_SAMPLES) for _ in range(STAB_RELERR_RPTS)]\n",
    "    s_ref = float(np.mean(re_vals))\n",
    "    rel_err = abs(s_val - s_ref) / (abs(s_ref) + 1e-12)\n",
    "    per_sample_stab.append((int(idx), int(labels_all[idx]), float(s_val), float(rel_err)))\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\" processed {i+1}/{len(selected)} ...\")\n",
    "t1 = time.time()\n",
    "print(f\"? SUIN done. Time elapsed: {t1-t0:.1f}s\")\n",
    "\n",
    "# aggregate & print\n",
    "clean_stats = [p for p in per_sample_stab if p[1]==0]\n",
    "troj_stats  = [p for p in per_sample_stab if p[1]==1]\n",
    "def aggs_s(stats):\n",
    "    if not stats: return (0.0,0.0,0.0,0.0)\n",
    "    Ss = np.array([s[2] for s in stats]); Es = np.array([s[3] for s in stats])\n",
    "    return (Ss.mean(), Ss.std(), Es.mean(), Es.std())\n",
    "\n",
    "cS_mean, cS_std, cE_mean, cE_std = aggs_s(clean_stats)\n",
    "tS_mean, tS_std, tE_mean, tE_std = aggs_s(troj_stats)\n",
    "print(\"\\nStability Under Input Noise (on perturbed selected samples):\")\n",
    "print(f\" Clean: avg_stability={cS_mean:.4f} ± {cS_std:.4f}, avg_relerr={cE_mean:.4e} ± {cE_std:.4e}\")\n",
    "print(f\" Trojan:avg_stability={tS_mean:.4f} ± {tS_std:.4f}, avg_relerr={tE_mean:.4e} ± {tE_std:.4e}\")\n",
    "print(\"\\nSample preview (first 6): (idx,label,stability,rel_err)\")\n",
    "for p in per_sample_stab[:6]:\n",
    "    print(p)\n",
    "\n",
    "# classification on perturbed selected\n",
    "y_true_sel, y_pred_sel, acc_sel, prec_sel, rec_sel, f1_sel = (*eval_perturbed_selected(perturbed_map, selected),)\n",
    "print(\"\\nClassification (perturbed selected) - SUIN stage:\")\n",
    "print(f\"Accuracy: {acc_sel*100:.2f}% | Precision: {prec_sel:.4f}, Recall: {rec_sel:.4f}, F1: {f1_sel:.4f}\")\n",
    "print(classification_report(y_true_sel, y_pred_sel, target_names=['clean','trojan'], digits=4))\n",
    "print(confusion_matrix(y_true_sel, y_pred_sel, labels=[0,1]))\n",
    "\n",
    "print(\"\\n\\nAll metrics computed on the SAME selected subgraphs and the SAME PGD perturbations (perturbed_map).\")\n",
    "print(\"You can adjust PER_CLASS, EPSILON_PGD, ALPHA_PGD, NUM_ITERS_PGD to change attack strength.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa346fa-16b7-4c3a-aeea-8f1a96a9114a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
